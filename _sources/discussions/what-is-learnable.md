# Discussion questions

1. The lecture discusses the distinction between the hypothesis ($h$) and learner ($g$). How does the form of one affect the other?

2. According to PAC learning (Valiant 1984), desribed in the article by Fulop & Chater 2013, a problem is "PAC learnable" if it can be fit with a test error below $\delta$ and training error below $\epsilon$, with $\delta \neq \epsilon$. Why is it important to have a different precision criteron for the training and testing evalautions? How does this relate to what we can understand about the relationship between $X$ and $Y$?