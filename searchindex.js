Search.setIndex({"docnames": ["discussions/Fiona-test", "discussions/bayes-factor-accepting-the-null", "discussions/classifiers", "discussions/cross-validation", "discussions/data-as-objects-and-architectures", "discussions/errors-and-inferences", "discussions/limits-of-linear-regression", "discussions/linear-models", "discussions/mediation-and-moderation", "discussions/mixed-effects-models", "discussions/models-as-testable-hypotheses", "discussions/power-analysis-via-simulations", "discussions/principal-component-methods", "discussions/quantitative-epistemology", "discussions/reconsidering-the-p-value", "discussions/regularized-regression", "discussions/resampling-methods", "discussions/selecting-the-best-model", "discussions/statistical-learning-theory", "discussions/techniques-for-data-cleansing", "discussions/telling-your-data-story", "discussions/the-beauty-of-knn", "discussions/the-ordinary-least-squares-solution", "discussions/the-value-of-openness", "discussions/theories-as-social-constructs", "discussions/visualization-as-analysis", "discussions/visualization-through-human-eyes", "discussions/what-is-a-theory", "discussions/what-is-learnable", "exercises/classifiers", "exercises/cross-validation", "exercises/data-as-objects-and-architectures", "exercises/linear-models", "exercises/mediation-and-moderation", "exercises/mixed-effects-models", "exercises/models-as-testable-hypotheses", "exercises/power-analysis-via-simulations", "exercises/principal-component-methods", "exercises/regularized-regression", "exercises/resampling-methods", "exercises/selecting-the-best-model", "exercises/techniques-for-data-cleansing", "exercises/the-beauty-of-knn", "exercises/the-ordinary-least-squares-solution", "exercises/the-value-of-openness", "exercises/visualization-as-analysis", "exercises/visualization-through-human-eyes", "intro", "lectures/art-of-data-investigations", "lectures/bayes-factor-accepting-the-null", "lectures/classifiers", "lectures/constructing-a-testable-hypothesis", "lectures/cross-validation", "lectures/data-as-objects-and-architectures", "lectures/errors-and-inferences", "lectures/limits-of-linear-regression", "lectures/linear-models", "lectures/mediation-and-moderation", "lectures/mixed-effects-models", "lectures/models-as-testable-hypotheses", "lectures/power-analysis-via-simulations", "lectures/principal-component-methods", "lectures/quantitative-epistemology", "lectures/reconsidering-the-p-value", "lectures/regularized-regression", "lectures/resampling-methods", "lectures/selecting-the-best-model", "lectures/statistical-learning-theory", "lectures/techniques-for-data-cleansing", "lectures/telling-your-data-story", "lectures/the-beauty-of-knn", "lectures/the-ordinary-least-squares-solution", "lectures/the-value-of-openness", "lectures/theories-as-social-constructs", "lectures/video-test-1", "lectures/visualization-as-analysis", "lectures/visualization-through-human-eyes", "lectures/what-is-a-theory", "lectures/what-is-learnable", "markdown", "notebooks/01-Introduction-to-data-investigations", "notebooks/art-of-data-investigations", "notebooks/bayes-factor-accepting-the-null", "notebooks/classifiers", "notebooks/cross-validation", "notebooks/data-as-objects-and-architectures", "notebooks/limits-of-linear-regression", "notebooks/linear-models", "notebooks/mediation-and-moderation", "notebooks/mixed-effects-models", "notebooks/models-as-testable-hypotheses", "notebooks/power-analysis-via-simulations", "notebooks/principal-component-methods", "notebooks/quantitative-epistemology", "notebooks/regularized-regression", "notebooks/resampling-methods", "notebooks/selecting-the-best-model", "notebooks/techniques-for-data-cleansing", "notebooks/the-beauty-of-knn", "notebooks/the-ordinary-least-squares-solution", "notebooks/the-value-of-openness", "notebooks/visualization-as-analysis", "notebooks/visualization-through-human-eyes", "notebooks/what-is-learnable", "video1"], "filenames": ["discussions/Fiona-test.md", "discussions/bayes-factor-accepting-the-null.md", "discussions/classifiers.md", "discussions/cross-validation.md", "discussions/data-as-objects-and-architectures.md", "discussions/errors-and-inferences.md", "discussions/limits-of-linear-regression.md", "discussions/linear-models.md", "discussions/mediation-and-moderation.md", "discussions/mixed-effects-models.md", "discussions/models-as-testable-hypotheses.md", "discussions/power-analysis-via-simulations.md", "discussions/principal-component-methods.md", "discussions/quantitative-epistemology.md", "discussions/reconsidering-the-p-value.md", "discussions/regularized-regression.md", "discussions/resampling-methods.md", "discussions/selecting-the-best-model.md", "discussions/statistical-learning-theory.md", "discussions/techniques-for-data-cleansing.md", "discussions/telling-your-data-story.md", "discussions/the-beauty-of-knn.md", "discussions/the-ordinary-least-squares-solution.md", "discussions/the-value-of-openness.md", "discussions/theories-as-social-constructs.md", "discussions/visualization-as-analysis.md", "discussions/visualization-through-human-eyes.md", "discussions/what-is-a-theory.md", "discussions/what-is-learnable.md", "exercises/classifiers.ipynb", "exercises/cross-validation.ipynb", "exercises/data-as-objects-and-architectures.ipynb", "exercises/linear-models.ipynb", "exercises/mediation-and-moderation.ipynb", "exercises/mixed-effects-models.ipynb", "exercises/models-as-testable-hypotheses.ipynb", "exercises/power-analysis-via-simulations.ipynb", "exercises/principal-component-methods.ipynb", "exercises/regularized-regression.ipynb", "exercises/resampling-methods.ipynb", "exercises/selecting-the-best-model.ipynb", "exercises/techniques-for-data-cleansing.ipynb", "exercises/the-beauty-of-knn.ipynb", "exercises/the-ordinary-least-squares-solution.ipynb", "exercises/the-value-of-openness.ipynb", "exercises/visualization-as-analysis.ipynb", "exercises/visualization-through-human-eyes.ipynb", "intro.md", "lectures/art-of-data-investigations.md", "lectures/bayes-factor-accepting-the-null.md", "lectures/classifiers.md", "lectures/constructing-a-testable-hypothesis.md", "lectures/cross-validation.md", "lectures/data-as-objects-and-architectures.md", "lectures/errors-and-inferences.md", "lectures/limits-of-linear-regression.md", "lectures/linear-models.md", "lectures/mediation-and-moderation.md", "lectures/mixed-effects-models.md", "lectures/models-as-testable-hypotheses.md", "lectures/power-analysis-via-simulations.md", "lectures/principal-component-methods.md", "lectures/quantitative-epistemology.md", "lectures/reconsidering-the-p-value.md", "lectures/regularized-regression.md", "lectures/resampling-methods.md", "lectures/selecting-the-best-model.md", "lectures/statistical-learning-theory.md", "lectures/techniques-for-data-cleansing.md", "lectures/telling-your-data-story.md", "lectures/the-beauty-of-knn.md", "lectures/the-ordinary-least-squares-solution.md", "lectures/the-value-of-openness.md", "lectures/theories-as-social-constructs.md", "lectures/video-test-1.ipynb", "lectures/visualization-as-analysis.md", "lectures/visualization-through-human-eyes.md", "lectures/what-is-a-theory.md", "lectures/what-is-learnable.md", "markdown.md", "notebooks/01-Introduction-to-data-investigations.ipynb", "notebooks/art-of-data-investigations.ipynb", "notebooks/bayes-factor-accepting-the-null.ipynb", "notebooks/classifiers.ipynb", "notebooks/cross-validation.ipynb", "notebooks/data-as-objects-and-architectures.ipynb", "notebooks/limits-of-linear-regression.ipynb", "notebooks/linear-models.ipynb", "notebooks/mediation-and-moderation.ipynb", "notebooks/mixed-effects-models.ipynb", "notebooks/models-as-testable-hypotheses.ipynb", "notebooks/power-analysis-via-simulations.ipynb", "notebooks/principal-component-methods.ipynb", "notebooks/quantitative-epistemology.ipynb", "notebooks/regularized-regression.ipynb", "notebooks/resampling-methods.ipynb", "notebooks/selecting-the-best-model.ipynb", "notebooks/techniques-for-data-cleansing.ipynb", "notebooks/the-beauty-of-knn.ipynb", "notebooks/the-ordinary-least-squares-solution.ipynb", "notebooks/the-value-of-openness.ipynb", "notebooks/visualization-as-analysis.ipynb", "notebooks/visualization-through-human-eyes.ipynb", "notebooks/what-is-learnable.ipynb", "video1.md"], "titles": ["Fiona Test MD", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Exercise 10: Classification", "Exercise 12: Cross Validation", "Exercise 3: Data objects", "Exercise 7:  Linear models", "Exercise 14: Mediation", "Exercise 9: Mixed effects", "Exercise 2: Coding Habits &amp; Functions", "Exercise 15: Power Analyses", "Exercise 18: Principal component methods", "Exercise 17: Regularized regression", "Exercise 13:  Resampling methods", "Exercise 16: Model selection", "Exercise 4: Data tables and manipulation", "Exercise 11: The Beauty of kNN", "Exercise 8:  Linear models, continued", "Exercise 1: Github &amp; Jupyter", "Exercise 5: Using ggplot", "Exercise 6: More plotting options", "Data explorations", "Art of data investigations", "Bayes factor", "Classifiers", "Constructing a testable hypothesis", "Cross validation", "Data as objects and architectures", "Errors and inferences", "Limits and variations of linear regression", "Linear models", "Mediation and moderation", "Mixed effects models", "Models as testable hypotheses", "Power analysis via simulations", "Principal component methods", "Quantitative epsitemology", "Reconsidering the p-value", "Regularized regression", "Resampling methods", "Selecting the best model", "The bias-variance tradeoff", "Techniques for data cleansing", "Telling your data story", "The beauty of kNN", "The ordinary least squares solution", "The value of openness", "Theories as social constructs", "&lt;no title&gt;", "Visualization as analysis", "Visualization through human eyes", "What is a theory?", "What is learnable?", "Markdown Files", "The art of \u201cdata poetry\u201d", "Tutorial: Getting started", "Tutorial: Estimating Bayes factors", "Tutorial: Basics classifiers", "Tutorial: Implementing cross validation", "Tutorial: Data as Objects and Tidy Data", "Tutorial: More on linear models", "Tutorial: Refresher on working with matrices", "Tutorial: Running mediation and moderation models", "Tutorial: Running linear mixed effects models", "Tutorial: Introduction to R, functions, and good coding habits", "Tutorial: Running basic power analyses", "Tutorial: Basic PCA approaches", "Tutorial: Getting started", "Tutorial: Basic ridge and LASSO models", "Tutorial: Boostrap and permutation tests", "Tutorial: Model selection", "Tutorial: Data Cleansing and the Tidyverse", "Tutorial: Running kNN models", "Tutorial: Refresher for solving oridinary least squares", "Tutorial: Repositories and version control", "Tutorial: Basics of plotting", "Tutorial: More advanced plotting", "Tutorial: Fitting and prediction", "Video test 1"], "terms": {"consid": [1, 4, 6, 8, 14, 43, 80, 90, 92, 94, 101, 102], "situat": [1, 36, 82, 86, 100], "where": [1, 2, 4, 9, 11, 17, 20, 21, 24, 25, 26, 27, 30, 31, 32, 34, 35, 38, 40, 41, 42, 44, 45, 46, 80, 83, 84, 85, 86, 87, 88, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103], "you": [1, 2, 5, 8, 16, 17, 19, 21, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "have": [1, 2, 11, 21, 22, 25, 28, 29, 30, 31, 36, 37, 38, 39, 42, 46, 80, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103], "uniform": 1, "prior": [1, 46, 82, 83, 87, 91, 92, 97, 100], "your": [1, 3, 4, 10, 11, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 103], "model": [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 21, 22, 30, 33, 36, 37, 39, 42, 45, 53, 57, 60, 61, 64, 77, 83, 84, 87, 90, 92, 95, 97, 99, 100, 101, 102], "i": [1, 9, 12, 21, 27, 30, 34, 36, 38, 39, 40, 43, 51, 62, 75, 77, 80, 82, 83, 84, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "e": [1, 2, 9, 10, 12, 21, 26, 27, 30, 34, 36, 38, 39, 40, 43, 45, 49, 53, 59, 72, 77, 80, 83, 84, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102, 103], "an": [1, 3, 4, 7, 10, 11, 13, 16, 20, 21, 23, 25, 27, 30, 33, 34, 35, 36, 37, 38, 40, 46, 47, 50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 75, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 100, 101, 102, 103], "unknown": 1, "thi": [1, 5, 7, 8, 9, 10, 12, 13, 14, 16, 20, 21, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103], "effect": [1, 3, 8, 9, 11, 12, 16, 20, 24, 26, 33, 36, 45, 57, 80, 81, 83, 85, 86, 88, 91, 93, 95, 97, 102, 103], "nullifi": 1, "relev": [1, 22, 97, 99, 102, 103], "distribut": [1, 9, 16, 21, 39, 81, 83, 85, 89, 91, 92, 93, 95, 99, 102, 103], "calcul": [1, 15, 30, 31, 35, 36, 37, 42, 43, 83, 86, 87, 91, 92, 95, 97, 98, 101], "bay": 1, "factor": [1, 29, 39, 42, 83, 84, 85, 86, 87, 88, 89, 91, 97, 99, 102, 103], "turn": [1, 44, 80, 86, 88, 92, 102, 103], "ratio": [1, 46, 82, 86, 91, 102], "likelihood": [1, 22, 82, 91, 99], "now": [1, 29, 30, 31, 34, 36, 37, 38, 39, 41, 42, 43, 45, 46, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "compar": [1, 7, 29, 31, 34, 35, 37, 39, 40, 43, 57, 82, 84, 86, 89, 91, 92, 95, 98, 100, 102], "p": [1, 14, 15, 17, 31, 36, 38, 40, 49, 53, 72, 76, 80, 82, 83, 86, 88, 89, 91, 94, 95, 99, 103], "valu": [1, 14, 15, 29, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 46, 49, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 101, 102, 103], "what": [1, 2, 3, 5, 8, 11, 13, 14, 16, 17, 18, 20, 22, 24, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 42, 43, 45, 72, 76, 80, 83, 84, 85, 86, 88, 89, 90, 92, 94, 95, 96, 97, 98, 101, 102, 103], "kei": [1, 82, 86, 88, 91, 97], "differ": [1, 5, 6, 12, 16, 17, 22, 26, 28, 29, 30, 31, 34, 37, 40, 42, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103], "between": [1, 2, 10, 19, 25, 26, 28, 32, 33, 36, 37, 38, 39, 40, 41, 42, 45, 80, 82, 83, 84, 85, 86, 89, 91, 94, 97, 98, 100, 101, 102, 103], "how": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51, 77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103], "doe": [1, 2, 5, 7, 8, 9, 13, 15, 16, 20, 23, 24, 26, 27, 28, 29, 35, 37, 38, 39, 40, 42, 72, 80, 83, 86, 90, 91, 92, 97, 98, 100, 103], "impact": [1, 3, 6, 8, 11, 19, 23, 42, 82, 88, 89, 91, 94, 97], "interpret": [1, 2, 6, 8, 19, 31, 33, 34, 36, 42, 45, 82, 83, 86, 88, 89, 91, 95, 96, 101, 102], "result": [1, 20, 21, 25, 26, 30, 31, 32, 33, 35, 36, 37, 38, 40, 79, 80, 82, 83, 84, 85, 86, 88, 90, 91, 94, 95, 97, 98, 100, 101, 103], "context": [1, 11, 16, 22, 30, 38, 82, 84, 92, 94, 98, 102], "atom": [1, 14], "approach": [1, 5, 11, 14, 21, 37, 73, 91, 97, 102], "wasserstein": [1, 14, 63], "et": [1, 14, 23, 26, 83], "al": [1, 14, 23, 26, 83], "2019": [1, 9, 62, 63], "lectur": [1, 2, 5, 10, 13, 14, 25, 28, 44, 47, 83, 86, 87, 90, 91, 98, 99], "us": [1, 3, 4, 5, 10, 11, 14, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 60, 80, 82, 83, 85, 86, 88, 89, 91, 92, 94, 95, 96, 97, 101, 102, 103], "need": [1, 14, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 46, 80, 81, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103], "ar": [1, 3, 6, 8, 11, 14, 16, 17, 20, 21, 23, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103], "adopt": [1, 11, 16], "why": [1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 20, 28, 29, 30, 33, 34, 36, 38, 80, 83, 87, 88, 90, 91, 92, 97, 101], "other": [2, 6, 10, 21, 22, 23, 28, 29, 30, 34, 36, 42, 44, 80, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "than": [2, 6, 17, 30, 33, 36, 38, 42, 46, 82, 83, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102], "allow": [2, 43, 45, 46, 79, 80, 81, 83, 86, 93, 95, 96, 97, 98, 100, 102], "classifi": [2, 29, 30], "case": [2, 5, 10, 16, 17, 21, 25, 30, 31, 34, 35, 38, 80, 82, 83, 86, 87, 88, 89, 90, 91, 94, 95, 97, 98, 99, 100, 101, 102, 103], "y": [2, 7, 19, 28, 29, 32, 38, 39, 40, 42, 43, 45, 46, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 99, 101, 102, 103], "ha": [2, 7, 30, 34, 38, 42, 45, 79, 81, 83, 84, 85, 86, 87, 89, 91, 93, 96, 97, 99, 100, 101, 102, 103], "more": [2, 6, 16, 17, 18, 21, 23, 29, 30, 33, 36, 41, 42, 45, 79, 81, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103], "two": [2, 7, 10, 16, 25, 30, 34, 37, 42, 45, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103], "group": [2, 30, 82, 83, 84, 89, 91, 101, 102], "advantag": [2, 11, 45, 83, 84, 95, 97, 101], "do": [2, 5, 25, 29, 30, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 45, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 100, 101, 102, 103], "lda": 2, "qda": 2, "over": [2, 11, 12, 17, 21, 22, 36, 38, 45, 46, 59, 82, 84, 86, 87, 89, 90, 92, 95, 97, 98, 101, 103], "standard": [2, 3, 9, 31, 33, 35, 36, 39, 41, 82, 86, 88, 89, 91, 95, 101, 103], "logist": [2, 21, 30, 100], "regress": [2, 7, 12, 15, 21, 30, 39, 56, 60, 71, 82, 84, 85, 89, 91, 95, 99, 100, 101], "when": [2, 8, 12, 15, 21, 25, 26, 31, 33, 35, 36, 38, 39, 40, 41, 43, 45, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "would": [2, 4, 11, 12, 17, 21, 22, 27, 30, 36, 38, 42, 80, 82, 84, 86, 87, 88, 89, 90, 91, 95, 96, 97, 100, 101, 103], "prefer": [2, 11, 12, 17, 21, 22, 90, 100], "The": [2, 4, 5, 10, 14, 15, 21, 22, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 45, 46, 53, 58, 59, 63, 75, 76, 79, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103], "went": [2, 83, 86, 90, 97, 103], "function": [2, 10, 22, 30, 31, 32, 33, 37, 38, 39, 41, 42, 43, 45, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 98, 101, 102, 103], "defin": [2, 30, 35, 38, 79, 83, 84, 87, 90, 91, 94, 95], "state": [2, 10, 15, 80, 84, 91, 99], "transit": 2, "If": [2, 13, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103], "fit": [2, 6, 17, 22, 28, 30, 31, 37, 42, 43, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 101, 102], "produc": [2, 38, 95], "shallow": 2, "slope": [2, 87, 89, 91, 99, 102, 103], "tell": [2, 37, 41, 80, 81, 83, 84, 85, 86, 88, 93, 97, 99, 100, 101, 103], "about": [2, 3, 24, 28, 29, 30, 31, 34, 37, 42, 45, 46, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103], "relationship": [2, 10, 14, 19, 28, 33, 36, 37, 38, 40, 41, 45, 80, 83, 85, 86, 88, 95, 102, 103], "x": [2, 7, 19, 28, 29, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103], "specif": [2, 11, 16, 17, 19, 22, 24, 45, 46, 79, 82, 84, 85, 87, 89, 90, 95, 97, 98, 103], "predictor": [2, 6, 19, 29, 34, 40, 43, 82, 83, 87, 88, 89, 92, 94, 96, 98], "variabl": [2, 6, 9, 12, 15, 18, 19, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 101, 102, 103], "g": [2, 10, 26, 28, 29, 34, 36, 41, 45, 50, 51, 52, 53, 54, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 77, 80, 83, 84, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "x_1": [2, 87, 99], "cross": [3, 37, 38, 92, 94, 96], "valid": [3, 16, 24, 37, 79, 86, 92, 96, 103], "seen": [3, 102], "gold": 3, "estim": [3, 9, 11, 16, 31, 36, 38, 39, 83, 84, 85, 86, 87, 88, 89, 91, 94, 95, 99, 101, 103], "generaliz": [3, 9, 58], "observ": [3, 10, 15, 29, 30, 31, 38, 39, 40, 41, 42, 83, 84, 85, 86, 87, 89, 91, 92, 94, 95, 96, 97, 98, 99], "wai": [3, 5, 13, 20, 38, 41, 45, 80, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102], "inform": [3, 17, 25, 26, 27, 31, 34, 40, 42, 45, 46, 62, 75, 79, 80, 82, 83, 84, 86, 89, 90, 91, 92, 95, 96, 97, 100, 101, 103], "can": [3, 5, 7, 10, 13, 18, 19, 23, 25, 26, 28, 29, 30, 31, 33, 35, 36, 38, 40, 41, 42, 43, 45, 46, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "leak": 3, "process": [3, 24, 25, 80, 91, 97], "s": [3, 5, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 53, 72, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "risk": [3, 62, 95], "while": [3, 16, 42, 80, 83, 87, 88, 90, 91, 92, 94, 95, 97, 100, 101, 102], "larg": [3, 45, 86, 90, 91, 94, 98], "evalu": [3, 10, 14, 16, 22, 37, 38, 39, 42, 60, 82, 83, 86, 89, 92, 96, 97], "test": [3, 5, 7, 10, 14, 16, 22, 28, 30, 31, 38, 51, 77, 80, 81, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 97, 100], "error": [3, 5, 18, 28, 30, 31, 37, 38, 42, 43, 80, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103], "measur": [3, 17, 21, 30, 32, 37, 39, 43, 82, 84, 85, 89, 91, 92, 96, 97, 98, 102], "predict": [3, 10, 27, 30, 31, 37, 38, 39, 42, 80, 84, 85, 86, 87, 88, 92, 94, 95, 96, 97], "accuraci": [3, 11, 29, 38, 42, 83, 84, 86, 94, 98], "ask": [3, 29, 34, 41, 82, 91, 92, 95, 97, 100], "inferenti": [3, 89, 95], "data": [3, 4, 12, 13, 14, 19, 20, 21, 25, 26, 40, 45, 62, 76, 79, 81, 82, 83, 86, 87, 88, 89, 92, 93, 94, 95, 96, 99, 101, 103], "provid": [4, 5, 7, 10, 19, 20, 21, 22, 23, 24, 26, 27, 29, 31, 32, 33, 34, 37, 39, 41, 42, 43, 84, 89, 90, 92, 97, 100, 102], "2": [4, 22, 44, 67, 70, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103], "hypothet": [4, 10, 19, 23, 25, 31], "exampl": [4, 5, 7, 10, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103], "dirti": 4, "aka": [4, 31, 91, 100], "tidi": [4, 31, 53, 91, 97, 98, 101], "tabl": [4, 19, 37, 42, 80, 83, 86, 96, 98, 103], "could": [4, 9, 11, 23, 31, 34, 38, 80, 83, 87, 88, 91, 92, 96, 97, 99, 101, 102], "hamper": 4, "analysi": [4, 25, 36, 38, 80, 82, 83, 88, 90, 95, 97, 100, 103], "concept": [4, 5, 21, 86, 87, 99, 100, 102], "link": [4, 31, 35, 41, 42, 44, 45, 81, 88, 93, 97, 100, 101, 102], "goal": [4, 24, 25, 36], "done": [4, 16, 81, 86, 88, 93, 96], "give": [4, 5, 17, 25, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 80, 83, 84, 85, 91, 92, 94, 97, 98, 100, 101, 102, 103], "same": [4, 21, 26, 30, 31, 34, 36, 38, 40, 42, 46, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 102], "one": [4, 10, 20, 22, 23, 25, 28, 33, 34, 35, 36, 38, 41, 45, 46, 79, 81, 82, 83, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103], "set": [4, 12, 16, 19, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 80, 81, 82, 83, 85, 86, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 101, 102, 103], "anoth": [4, 27, 35, 45, 79, 82, 83, 89, 90, 97, 100, 102], "vice": 4, "versa": 4, "spreadsheet": 4, "text": [4, 46, 79, 80, 83, 90], "editor": 4, "show": [4, 5, 19, 26, 32, 37, 39, 40, 43, 45, 80, 81, 82, 83, 86, 87, 88, 91, 92, 93, 94, 96, 97, 98, 101, 102, 103], "breast": 5, "cancer": 5, "screen": [5, 100], "read": [5, 14, 25, 30, 32, 33, 36, 37, 39, 41, 43, 46, 47, 80, 84, 87, 90, 91, 96, 97, 99, 100, 102], "evidentiari": 5, "existenti": 5, "method": [5, 7, 11, 12, 17, 21, 22, 29, 34, 36, 40, 41, 45, 46, 52, 57, 60, 68, 80, 84, 87, 88, 89, 92, 95, 98, 99, 102, 103], "arriv": 5, "similar": [5, 21, 34, 79, 82, 84, 87, 91, 92, 95, 97, 101, 103], "conclus": [5, 25, 26, 88], "mayo": [5, 54], "make": [5, 6, 10, 15, 26, 32, 37, 38, 39, 41, 43, 45, 46, 54, 80, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "statist": [5, 7, 8, 10, 11, 13, 14, 16, 31, 37, 38, 41, 50, 52, 53, 54, 55, 56, 61, 64, 65, 66, 67, 70, 71, 81, 82, 83, 84, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 102, 103], "better": [5, 9, 33, 34, 38, 80, 83, 88, 89, 91, 92, 97, 98, 100, 101, 102], "window": [5, 81, 93, 100, 103], "toward": [5, 9, 17, 62, 72, 82], "understand": [5, 14, 22, 24, 25, 28, 37, 43, 73, 80, 83, 84, 87, 88, 90, 91, 92, 94, 99, 102], "bayesian": [5, 40, 82, 88, 91, 96], "studi": [5, 89, 91, 102], "guid": [5, 30, 90], "answer": [5, 7, 19, 24, 31, 43, 80, 82, 88, 91, 95, 97], "sever": [5, 80, 97, 100], "hypothesi": [5, 8, 10, 11, 14, 16, 25, 28, 75, 82, 89, 90, 95, 103], "relat": [5, 14, 28, 36, 37], "popper": [5, 59], "idea": [5, 10, 20, 80, 91, 99, 100, 101, 102], "falsifiabilti": 5, "In": [5, 13, 21, 22, 30, 31, 33, 35, 38, 40, 42, 43, 46, 59, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "thei": [5, 6, 14, 17, 29, 30, 34, 41, 46, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 100, 101, 102], "categor": [6, 29, 83, 97, 102], "4": [6, 7, 44, 50, 70, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 102, 103], "level": [6, 10, 27, 83, 86, 88, 94, 96, 97, 98, 101, 102, 103], "explain": [6, 10, 11, 16, 37, 38, 80, 85, 86, 92, 100, 101], "code": [6, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 96, 97, 100, 101, 102, 103], "3": [6, 44, 53, 55, 56, 57, 71, 75, 76, 78, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 100, 102, 103], "separ": [6, 30, 31, 38, 45, 87, 89, 90, 91, 94, 99, 101, 102, 103], "dummi": [6, 94], "binari": [6, 30, 42, 80, 83, 86, 97, 102], "sens": [6, 15, 82, 83, 84, 87, 88, 92, 97, 99, 101, 102], "singl": [6, 14, 30, 43, 80, 81, 83, 84, 85, 86, 87, 90, 93, 97, 100, 101], "outlier": [6, 38, 86], "high": [6, 10, 30, 37, 38, 51, 77, 83, 88, 98, 103], "leverag": [6, 83, 103], "point": [6, 16, 21, 35, 81, 83, 84, 85, 87, 88, 90, 93, 96, 97, 98, 100, 101, 102, 103], "often": [6, 38, 47, 80, 87, 90, 95, 97, 100, 101, 102], "confus": [6, 29, 42, 83, 95, 98, 100], "each": [6, 7, 11, 14, 19, 22, 23, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 43, 45, 46, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103], "linear": [7, 21, 30, 31, 34, 42, 61, 64, 66, 71, 82, 83, 84, 85, 88, 90, 94, 95, 97, 99, 102], "research": [7, 24, 29, 34, 41, 57, 60, 72, 80], "typic": [7, 87, 88, 91, 97, 98], "reserv": 7, "specialti": 7, "like": [7, 12, 17, 21, 29, 30, 32, 37, 38, 41, 46, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103], "t": [7, 29, 30, 31, 33, 34, 36, 37, 38, 40, 42, 45, 50, 52, 53, 55, 56, 58, 61, 64, 65, 66, 67, 70, 71, 72, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "anova": [7, 91], "For": [7, 38, 41, 44, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103], "pearson": 7, "correl": [7, 12, 32, 39, 82, 83, 86, 88, 89, 92], "coeffici": [7, 15, 30, 31, 32, 38, 40, 43, 82, 83, 85, 86, 88, 89, 91, 94, 95, 97, 99, 103], "form": [7, 8, 13, 22, 27, 28, 33, 36, 43, 80, 81, 83, 87, 90, 91, 93, 95, 97, 99, 101, 102], "r": [7, 22, 29, 30, 31, 34, 35, 36, 40, 41, 43, 50, 51, 52, 53, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 70, 71, 72, 80, 82, 83, 84, 86, 87, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "frac": [7, 31, 35, 82, 84, 87, 90, 99], "cov": [7, 43, 83, 99], "std": [7, 82, 83, 86, 88, 89, 95, 103], "ordinari": [7, 95], "least": [7, 12, 20, 37, 94, 96], "squar": [7, 12, 31, 35, 37, 38, 43, 82, 84, 86, 88, 89, 90, 94, 96, 103], "solut": [7, 15, 38, 43, 49, 91, 99], "hat": [7, 38, 39, 83, 86, 87, 95, 103], "beta": [7, 38, 40, 87, 94, 95, 97, 103], "quantit": [7, 27, 86, 92], "comparison": [7, 86, 89, 102], "explan": [7, 90, 99], "polynomi": [7, 84], "still": [7, 29, 30, 37, 42, 81, 88, 89, 91, 92, 93, 97, 99], "meet": [7, 88], "assumpt": [7, 11, 16, 21, 88, 89, 95, 103], "normal": [7, 85, 87, 89, 91, 92, 99, 103], "justifi": [7, 21, 24], "against": [7, 16, 17, 32, 39, 82, 84, 85], "follow": [8, 31, 38, 44, 46, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 97, 100, 101, 102], "perform": [8, 29, 30, 32, 37, 39, 40, 42, 43, 83, 84, 85, 87, 90, 91, 92, 94, 96, 100], "delai": 8, "discount": 8, "task": [8, 29, 32, 33, 39, 43, 88, 90, 99], "neg": [8, 30, 32, 82, 83, 88, 89, 95, 96, 97, 99], "childhood": 8, "poverti": 8, "onli": [8, 32, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 79, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103], "lack": [8, 24, 89, 91], "commun": [8, 20, 24, 26, 76, 80, 81, 86, 93, 100, 102], "resourc": [8, 43, 90, 100], "evid": [8, 82, 88, 91], "neglect": 8, "home": [8, 99, 100, 102], "influenc": [8, 39, 86], "amount": [8, 33, 36, 45, 80, 82, 83, 89, 92, 97, 102], "fund": 8, "place": [8, 87, 88, 101], "local": [8, 32, 37, 41, 44, 82, 83, 86, 91, 94, 95, 99, 100, 103], "school": 8, "district": 8, "well": [8, 27, 29, 32, 34, 38, 41, 46, 80, 83, 90, 91, 92, 95, 97, 98, 100, 101, 102], "ag": [8, 31, 33, 36, 86, 90, 97, 98, 102], "primari": [8, 45, 80], "caregiv": 8, "graphic": [8, 25, 26, 33, 75, 80, 90, 100, 101, 102], "mediat": [8, 10, 36], "moder": [8, 33], "causal": [8, 88], "exactli": [8, 9, 15, 37, 40, 80, 97, 98], "mean": [8, 30, 31, 32, 34, 35, 37, 41, 42, 43, 72, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102], "both": [8, 12, 29, 36, 37, 40, 41, 45, 79, 80, 81, 82, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 103], "outcom": [8, 16, 30, 83, 91, 96, 98], "infer": [8, 51, 59, 83, 87, 89], "random": [9, 30, 34, 37, 39, 40, 84, 86, 89, 91, 92, 95, 98, 99], "mix": [9, 90], "involv": [9, 35, 87, 97], "varianc": [9, 12, 15, 18, 30, 32, 37, 80, 83, 84, 87, 89, 92, 94, 98, 99], "gener": [9, 10, 29, 30, 33, 36, 38, 40, 45, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 97, 99, 100, 101, 102, 103], "eta": 9, "sim": [9, 86, 88, 91, 95], "n": [9, 15, 31, 35, 38, 40, 63, 72, 78, 83, 84, 86, 87, 91, 99], "0": [9, 29, 30, 33, 35, 36, 38, 39, 41, 42, 63, 74, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 103], "sigma_": [9, 91], "theta": [9, 86, 91], "step": [9, 14, 19, 81, 85, 86, 88, 90, 91, 93, 94, 97, 100, 102, 103], "necessari": [9, 46, 90, 91], "differenti": [9, 39, 42], "from": [9, 12, 15, 21, 24, 25, 26, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 54, 74, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103], "nuisanc": 9, "yarkoni": [9, 58, 72], "argu": [9, 14], "should": [9, 25, 26, 30, 36, 38, 43, 45, 80, 81, 82, 84, 86, 88, 90, 92, 93, 94, 97, 100, 101], "practic": [9, 14, 23, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 46, 49, 60, 83, 84, 85, 88, 89, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103], "increas": [9, 17, 18, 30, 33, 36, 38, 83, 84, 86, 87, 89, 91, 94, 96, 99, 102], "find": [9, 25, 31, 37, 38, 43, 80, 82, 83, 85, 86, 87, 88, 89, 91, 94, 96, 97, 100, 101, 102], "psycholog": [9, 25, 27, 47, 51, 76, 77, 80, 81, 88, 93], "neurosci": [9, 25, 27, 47, 72, 80, 81, 90, 93], "lead": [9, 16, 20, 23, 24, 26, 30, 84, 90], "potenti": [9, 11, 19, 82], "harm": [9, 19], "falsifi": 10, "manner": [10, 14, 80], "unfalsifi": 10, "cannot": [10, 13, 90, 97], "guest": [10, 27, 59, 77], "martin": [10, 27, 59, 77], "act": [10, 84, 87], "theori": [10, 13, 24, 25, 27, 51, 62, 78], "empir": [10, 16, 62, 95], "extend": 10, "distinguis": 10, "mechanist": 10, "system": [10, 30, 32, 41, 81, 87, 91, 92, 93, 100], "descript": [10, 22, 27, 32, 35, 37, 39, 43, 80, 90, 97, 99, 100, 103], "latter": [10, 102], "being": [10, 20, 25, 79, 80, 82, 83, 86, 87, 91, 95, 99, 101], "formal": [10, 33, 80, 83, 90, 99], "former": [10, 102], "less": [10, 30, 42, 79, 82, 83, 88, 91, 95], "abstract": 10, "artifici": [10, 59, 80], "neural": [10, 39, 59], "network": [10, 59], "illustr": [10, 19, 85, 86, 90, 97, 101], "work": [10, 12, 26, 29, 31, 37, 38, 41, 42, 45, 76, 79, 80, 81, 83, 85, 90, 93, 95, 96, 97, 98, 103], "togeth": [10, 21, 37, 45, 81, 86, 87, 90, 91, 92, 93, 97, 99], "scientif": [10, 20, 24, 53, 59, 73, 80, 81, 88, 93], "mont": [11, 36, 60], "carlo": [11, 36, 60], "present": [11, 27, 29, 34, 41, 81, 91, 92, 93, 97, 100, 101], "strategi": [11, 57], "determin": [11, 16, 18, 27, 32, 33, 36, 37, 40, 42, 60, 80, 82, 83, 94, 96], "power": [11, 38, 79, 84, 88, 94], "core": [11, 21, 80], "bia": [11, 15, 17, 25, 32, 37, 84, 89, 91, 94, 95, 96, 98], "either": [11, 40, 44, 83, 86, 87, 89, 97, 100, 102], "recov": [11, 38, 86, 90], "paramet": [11, 15, 17, 31, 36, 38, 43, 83, 86, 87, 90, 91, 94, 95, 102], "With": [11, 38, 91, 94, 97, 98], "clearli": [11, 83, 90, 97, 102], "some": [11, 16, 29, 30, 31, 35, 36, 40, 41, 43, 59, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 100, 101, 102, 103], "tradit": [11, 15, 82], "parametr": [11, 21, 95, 98], "mai": [11, 16, 17, 30, 36, 42, 83, 84, 87, 89, 90, 91, 92, 95, 96, 100, 101, 102], "Be": [11, 17], "princip": [12, 86], "compon": [12, 31, 86, 90, 101, 102], "pcr": [12, 37, 92], "partial": 12, "pl": [12, 37, 92], "reduc": [12, 18, 30, 96, 101], "complex": [12, 17, 25, 38, 79, 82, 84, 89, 90, 96, 97, 102], "account": [12, 17, 44, 89, 91, 96, 100], "across": [12, 36, 37, 86, 89, 91, 92, 97, 102, 103], "ridg": [12, 15, 38], "which": [12, 15, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 79, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "also": [12, 29, 30, 36, 43, 45, 79, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103], "structur": [12, 20, 33, 38, 42, 53, 69, 79, 85, 86, 87, 91, 95, 97, 100, 101], "manag": [12, 80, 90, 100], "subset": [12, 17, 29, 34, 38, 41, 42, 46, 83, 84, 86, 87, 92, 94, 95, 97, 101, 102], "stepwis": [12, 17], "select": [12, 17, 37, 38, 42, 61, 64, 81, 84, 86, 91, 92, 93, 94, 95, 98, 100, 102, 103], "scienc": [13, 23, 24, 47, 51, 53, 54, 58, 62, 72, 76, 77, 78, 80, 81, 93], "correct": [13, 29, 80, 81, 83, 84, 90, 93], "learn": [13, 28, 30, 31, 50, 52, 54, 55, 56, 61, 62, 64, 65, 66, 67, 70, 71, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103], "epistemolog": 13, "basi": 13, "known": [13, 21, 80, 90, 91], "impli": [13, 24], "we": [13, 21, 22, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103], "know": [13, 29, 31, 45, 80, 83, 86, 87, 88, 90, 97, 99, 100], "scientist": [13, 80], "articl": [14, 28], "limit": [14, 31, 38, 81, 84, 90, 93, 95, 96, 101, 102], "whether": [14, 16, 29, 30, 33, 34, 36, 41, 79, 81, 82, 83, 86, 87, 88, 89, 91, 93, 96, 97, 98, 100, 101, 103], "prescrib": 14, "negat": 14, "all": [14, 22, 27, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 43, 44, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103], "four": [14, 85, 92, 96, 97, 98, 101, 102, 103], "common": [14, 29, 34, 80, 90, 92, 97, 98, 100], "poor": [14, 30], "null": [14, 16, 82, 83, 89, 91, 94, 95, 103], "outlin": [14, 91], "problem": [14, 23, 28, 30, 38, 49, 59, 68, 81, 83, 86, 89, 90, 91, 93, 97, 100], "back": [14, 80, 86, 90, 97, 100, 102], "misconcept": 14, "report": [14, 32, 39, 40, 89, 92, 96], "individu": [15, 30, 31, 36, 45, 85, 86, 89, 91, 98, 101], "lasso": 15, "notion": 15, "tradeoff": [15, 32, 37, 89, 94], "number": [15, 17, 30, 31, 34, 35, 37, 38, 40, 41, 80, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 102], "exce": [15, 101], "uniqu": [15, 37, 38, 84, 98, 102], "remov": [15, 32, 34, 37, 39, 43, 80, 83, 86, 101, 102], "resolv": [15, 100], "A": [16, 29, 30, 34, 41, 49, 53, 57, 59, 60, 63, 72, 73, 75, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 98, 100, 102, 103], "sell": 16, "permut": 16, "probabl": [16, 22, 30, 45, 46, 82, 83, 88, 90, 91, 95, 97, 98, 99], "assum": [16, 21, 83, 89, 100, 103], "shape": [16, 86, 87, 94, 96, 97, 98, 101, 102], "accur": [16, 27, 29, 34, 41, 91], "particular": [16, 30, 84, 87, 90, 91, 94, 102, 103], "under": [16, 30, 83, 85, 91, 97, 100, 102], "But": [16, 30, 31, 45, 80, 83, 84, 86, 87, 88, 89, 94, 95, 97, 99, 100, 101, 102, 103], "built": [16, 35, 79, 83, 86, 96, 97, 102, 103], "might": [16, 20, 31, 82, 83, 85, 87, 88, 89, 91, 95, 97, 98, 100], "reli": [16, 80, 86, 95], "resampl": [16, 52, 57, 84, 95], "without": [16, 81, 88, 90, 92, 93, 94, 95, 97, 100, 102, 103], "replac": [16, 31, 87, 91, 94, 95, 97, 100], "bootstrap": [16, 84, 88], "simpl": [16, 36, 45, 69, 72, 80, 83, 86, 88, 89, 91, 92, 94, 95, 99, 100, 102], "confid": [16, 32, 39, 82, 88, 91, 95, 102, 103], "sampl": [16, 35, 38, 60, 82, 84, 86, 88, 92, 94, 95, 97, 98, 101, 103], "full": [17, 32, 37, 39, 43, 82, 83, 84, 86, 91, 92, 96, 97, 100], "featur": [17, 36, 40, 86, 88, 94, 97], "due": [17, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 86, 89, 95, 101], "rel": [17, 74, 79, 81, 82, 84, 88, 91, 93], "lower": [17, 83, 86, 87, 88, 89, 91, 97, 103], "comput": [17, 27, 32, 41, 44, 59, 69, 72, 77, 79, 80, 81, 82, 83, 90, 93, 100], "burden": 17, "dramat": [17, 82], "best": [17, 35, 37, 38, 42, 45, 80, 83, 84, 85, 87, 89, 90, 92, 94, 97, 101, 102], "criterion": [17, 34, 36, 82, 89, 91, 94, 96], "aic": [17, 34, 83, 89, 91], "bic": [17, 40, 82, 91, 96], "meant": [17, 47, 102], "adjust": [17, 40, 42, 81, 82, 84, 86, 88, 89, 93, 96, 103], "good": [17, 21, 31, 80, 86, 91, 92, 98, 100, 101, 102], "aris": [17, 83], "given": [17, 31, 35, 36, 81, 82, 83, 85, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99], "implement": [17, 26, 30, 40, 88, 89, 90, 91, 92, 94, 96, 97, 98, 100, 103], "perfect": [17, 98], "Is": [17, 24, 32, 82, 91, 95], "sort": [17, 86, 96, 101], "favor": [17, 82], "think": [17, 27, 33, 42, 45, 80, 83, 87, 88, 89, 90, 92, 98, 99, 100], "fewer": [17, 84, 91, 101], "fundament": [18, 26, 59, 80, 97], "irreduc": [18, 87], "verbal": [18, 22, 80], "describ": [18, 23, 27, 32, 38, 39, 41, 53, 80, 83, 87, 88, 90, 91, 97, 98, 99, 100, 102], "dimension": [18, 37, 38, 86, 92, 96], "ad": [18, 36, 42, 84, 85, 86, 87, 88, 91, 97, 101, 102], "flexibl": [18, 90, 94, 95, 102], "type": [19, 23, 37, 41, 44, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103], "anomali": [19, 41], "semant": [19, 91], "syntact": 19, "coverag": [19, 36, 91], "respons": [19, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 82, 83, 85, 87, 92, 97, 103], "take": [19, 31, 33, 35, 36, 37, 38, 42, 43, 45, 46, 80, 82, 83, 84, 86, 87, 88, 89, 90, 91, 95, 97, 98, 101, 102, 103], "cleans": 19, "pipelin": [19, 80, 90], "map": [19, 36, 42, 45, 46, 91, 101], "real": [19, 20, 21, 36, 43, 80, 83, 87, 91, 95, 103], "world": [19, 20, 44, 63, 80, 87, 102], "histor": 20, "failur": [20, 24], "import": [20, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 53, 74, 80, 82, 87, 88, 92, 98, 100], "discoveri": [20, 59], "recogn": 20, "get": [20, 29, 30, 31, 33, 36, 38, 39, 41, 43, 44, 45, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 94, 95, 98, 99, 100, 101, 102, 103], "time": [20, 29, 30, 34, 36, 38, 39, 41, 42, 45, 46, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 97, 98, 100, 102], "wa": [20, 36, 83, 84, 85, 88, 89, 91, 94, 96, 97, 98, 99], "made": [20, 25, 35, 44, 89, 94, 99, 100, 101], "central": [20, 100], "principl": [20, 87], "laid": 20, "out": [20, 33, 36, 38, 41, 43, 80, 86, 90, 91, 92, 94, 95, 96, 97, 98, 100, 102], "mensch": 20, "kord": [20, 69], "2017": [20, 69, 72, 80], "ration": 20, "logic": [20, 59, 80, 88, 90, 97], "facilit": [20, 90], "stymi": 20, "knn": [21, 84], "first": [21, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103], "non": [21, 42, 80, 82, 86, 91, 94, 95, 98, 103], "class": [21, 29, 31, 32, 34, 35, 37, 39, 41, 42, 43, 44, 45, 47, 80, 81, 83, 84, 85, 86, 87, 88, 91, 93, 95, 96, 98, 100], "contrast": [21, 83, 86, 88, 94, 97, 100, 102], "befor": [21, 42, 51, 77, 80, 82, 83, 86, 87, 90, 91, 92, 97, 99, 100, 101, 102], "word": [21, 29, 33, 34, 35, 36, 41, 83, 88, 90, 91, 94, 95, 98, 100], "easi": [21, 45, 81, 84, 86, 90, 93, 94, 97, 101, 102], "conceptu": [21, 97], "ideal": [21, 102], "start": [21, 31, 33, 35, 36, 41, 44, 46, 80, 82, 84, 87, 89, 90, 91, 92, 94, 96, 100, 101, 103], "distanc": [21, 42, 83, 98], "closer": [21, 83, 86, 91, 101], "come": [21, 26, 31, 42, 86, 87, 90, 91, 97, 100, 102], "underli": [21, 37, 83, 86, 91], "break": [21, 23, 38, 80, 90, 95], "down": [21, 23, 30, 31, 33, 80, 83, 89, 91, 100, 102], "veri": [22, 30, 42, 79, 80, 83, 84, 85, 86, 90, 91, 94, 97, 98, 100, 101], "plain": [22, 87, 99], "english": [22, 29, 34, 41, 80, 97], "sai": [22, 31, 80, 83, 86, 88, 91, 97, 98, 100], "gone": 22, "three": [22, 23, 34, 41, 82, 87, 89, 90, 91, 92, 97, 98, 99, 103], "metric": [22, 91, 92, 96], "rse": 22, "f": [22, 38, 57, 62, 80, 82, 86, 87, 88, 89, 90, 99, 103], "experi": [23, 33, 36, 53, 80, 89, 91, 95], "reproduc": [23, 72, 81, 93], "breakdown": [23, 91, 102], "open": [23, 44, 80, 81, 82, 90, 93, 97, 100], "propos": [23, 25, 27, 81, 93], "panacea": 23, "sandv": [23, 72], "2013": [23, 28, 50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 78, 83, 84, 86, 92, 94, 95, 96, 98, 103], "hurt": 23, "field": [24, 80, 96], "intelligil": 24, "perfectli": 24, "accept": [24, 79, 83, 91, 103], "broader": 24, "detail": [24, 45, 86, 90, 91, 97, 101, 103], "loss": [24, 89], "theoret": 24, "develop": [24, 33, 80, 81, 90, 93, 100, 102], "contextu": [24, 73, 88], "social": 24, "reliabl": [24, 90], "problemat": [24, 80, 100], "yanai": [25, 75], "lercher": [25, 75], "2020": [25, 27, 75], "narrowli": 25, "focus": [25, 84, 88, 91, 92, 96, 98, 99], "hypothes": [25, 82, 95], "miss": [25, 29, 30, 34, 41, 80, 90, 92, 96, 97, 101], "meaning": [25, 80, 89, 90], "pattern": [25, 37, 39, 79, 80, 95, 97, 102], "reconcil": 25, "driven": [25, 103], "encod": 25, "unstructur": 25, "via": [25, 31, 35, 36, 41, 44, 45, 84, 95, 100], "visual": [25, 26, 41, 45, 46, 53, 80, 81, 82, 86, 88, 91, 92, 93, 97, 98, 99, 101, 103], "knowledg": [25, 26, 62, 80], "extract": [25, 31, 37, 83, 85, 86, 91, 95, 97, 100, 103], "reader": 25, "decod": 25, "paper": [25, 69, 81, 93], "recent": [25, 100], "analyz": [25, 36, 91, 101], "along": [25, 80, 81, 86, 87, 92, 93, 98, 99, 102, 103], "six": [25, 96, 97], "compet": [25, 82], "dimens": [25, 30, 37, 42, 83, 86, 87, 92, 96, 102, 103], "cairo": [25, 26, 75], "intellig": [25, 80], "There": [26, 41, 45, 79, 83, 85, 86, 88, 90, 91, 92, 97, 98, 100, 101, 102], "tension": 26, "most": [26, 42, 79, 80, 83, 87, 88, 90, 91, 92, 96, 97, 98, 99, 100, 102], "constraint": [26, 38], "human": [26, 32, 37, 39, 43], "percept": 26, "franconeri": [26, 76], "conflict": [26, 100], "explicit": [26, 87, 101], "colleagu": [26, 100], "frame": [26, 30, 31, 32, 36, 37, 38, 39, 42, 43, 45, 80, 82, 83, 85, 86, 89, 91, 92, 96, 98, 99, 101, 102, 103], "choic": [26, 40, 89, 91, 96], "highlight": [26, 102], "annot": 26, "scale": [26, 37, 42, 45, 89, 92, 96, 98, 103], "balanc": [26, 31, 80], "plot": [26, 29, 33, 37, 38, 39, 40, 80, 81, 82, 83, 84, 85, 86, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99], "bias": [26, 91], "viewer": 26, "incorrect": [26, 29, 89, 98], "interpet": [26, 86], "pizza": [27, 88], "deal": [27, 87, 88, 96, 97, 100, 101], "scenario": [27, 97], "intuit": [27, 37, 38, 92], "incorrectli": [27, 29, 30, 98], "someth": [27, 32, 41, 80, 83, 86, 90, 97, 99, 102], "van": [27, 51, 77], "rooij": [27, 51, 77], "baggio": [27, 51, 77], "claim": 27, "capac": [27, 37, 86, 88, 101, 103], "definit": [27, 46, 80, 83, 90, 91, 99], "hint": [27, 29, 31, 33, 35, 37, 38, 39, 41, 42, 43, 45, 46], "marr": 27, "analys": [27, 32, 81, 82, 93, 97, 100], "distinct": [28, 102], "h": [28, 29, 34, 41, 53, 68, 73, 87, 99], "learner": [28, 88], "affect": [28, 89, 91, 100], "accord": [28, 40, 83, 86, 96, 99, 101], "pac": 28, "valiant": 28, "1984": 28, "desrib": 28, "fulop": [28, 78], "chater": [28, 78], "learnabl": 28, "below": [28, 29, 30, 31, 33, 35, 36, 38, 40, 42, 43, 44, 45, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 100, 101, 102], "delta": [28, 84, 91], "train": [28, 30, 38, 39, 83, 84, 86, 92, 94, 98, 103], "epsilon": [28, 40, 83, 86, 87, 91], "neq": [28, 99], "precis": [28, 36, 91], "criteron": 28, "evalaut": 28, "homework": [29, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 81, 87, 93, 99], "assign": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 83, 85, 86, 88, 90, 97, 101], "design": [29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 80, 84, 88, 89, 90, 91, 100], "ll": [29, 30, 31, 33, 41, 42, 43, 46, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102], "try": [29, 31, 38, 39, 42, 43, 45, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 102, 103], "respond": [29, 41, 91], "correctli": [29, 30, 82, 91], "dure": [29, 81, 83, 88, 93, 95, 102], "lexic": [29, 91], "decis": [29, 80, 91], "base": [29, 32, 36, 38, 42, 81, 87, 91, 93, 98, 99, 101, 103], "length": [29, 34, 35, 38, 40, 82, 85, 86, 88, 92, 94, 96, 97, 98, 103], "frequenc": [29, 34, 80, 83], "lexicon": [29, 34, 41], "project": [29, 32, 34, 37, 39, 41, 43, 80, 81, 90, 93, 100], "again": [29, 31, 34, 40, 42, 43, 45, 79, 84, 91, 92, 96, 97, 98, 99, 100, 102], "howev": [29, 36, 45, 80, 83, 87, 90, 91, 92, 95, 96, 97, 98, 100, 101], "our": [29, 30, 31, 35, 36, 38, 40, 42, 45, 46, 83, 84, 86, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "depend": [29, 79, 82, 84, 85, 88, 89, 90, 91, 92, 94, 101, 103], "lexicaldata_withincorrect": 29, "csv": [29, 32, 34, 37, 39, 41, 43, 80, 100], "includ": [29, 30, 31, 34, 37, 40, 46, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 93, 94, 95, 96, 97, 98, 100, 101, 102], "trial": [29, 41], "ones": [29, 43, 87, 95, 98], "item": [29, 34, 84, 90, 91], "found": [29, 82, 90, 97], "lexdat": [29, 32, 34, 41], "folder": [29, 32, 34, 37, 39, 41, 43, 80, 97, 100, 102], "github": [29, 31, 32, 34, 35, 37, 39, 40, 41, 43, 45, 90, 97], "repositori": [29, 31, 32, 34, 35, 37, 39, 41, 43, 44, 45], "databas": [29, 32, 34, 37, 39, 41, 43, 97], "It": [29, 32, 33, 34, 37, 39, 41, 42, 43, 45, 46, 79, 80, 82, 83, 86, 87, 90, 91, 92, 97, 98, 100, 101, 102], "reaction": [29, 34, 41, 82, 89, 91], "millisecond": [29, 34, 41], "mani": [29, 33, 34, 36, 37, 41, 42, 79, 80, 82, 84, 87, 90, 91, 94, 96, 97, 98, 100, 101, 102], "subject": [29, 32, 34, 39, 41, 43, 82, 85, 89, 97], "letter": [29, 34, 41, 90, 100], "string": [29, 34, 41, 90, 91, 100], "decid": [29, 34, 41, 80, 82, 100], "quickli": [29, 34, 41, 100, 102], "possibl": [29, 34, 41, 82, 83, 85, 90, 91, 100, 102], "characterist": [29, 34, 103], "name": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 79, 82, 85, 86, 88, 89, 90, 94, 95, 96, 97, 100, 101, 102, 103], "courtesi": [29, 34, 41, 87], "balota": [29, 34, 41], "d": [29, 34, 36, 38, 41, 50, 52, 53, 54, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 73, 79, 80, 82, 83, 84, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 103], "yap": [29, 34, 41], "m": [29, 34, 35, 41, 58, 62, 72, 75, 76, 80, 86, 87, 88, 89, 92, 97, 100, 101], "j": [29, 34, 38, 41, 49, 51, 53, 57, 68, 72, 76, 87], "cortes": [29, 34, 41], "hutchison": [29, 34, 41], "k": [29, 34, 38, 41, 42, 53, 57, 59, 69, 72, 86], "kessler": [29, 34, 41], "b": [29, 33, 34, 37, 38, 39, 40, 41, 43, 69, 72, 86, 87, 89, 90, 92, 100], "lofti": [29, 34, 41], "neeli": [29, 34, 41], "nelson": [29, 34, 41], "l": [29, 34, 41, 63, 76, 99], "simpson": [29, 34, 41], "treiman": [29, 34, 41], "2007": [29, 34, 41, 49], "behavior": [29, 34, 38, 41, 57, 58, 59, 62, 90, 102], "39": [29, 34, 41, 84, 92, 95], "445": [29, 34, 41], "459": [29, 34, 41], "file": [29, 32, 34, 37, 39, 41, 43, 80, 81, 90, 93], "left_join": [29, 34, 97], "add": [29, 30, 34, 35, 36, 42, 44, 45, 46, 79, 80, 81, 85, 87, 88, 91, 93, 97, 98, 99, 100, 101, 102, 103], "log_freq_h": [29, 34], "lexicaldata": [29, 34], "drop_na": [29, 92], "rid": [29, 41, 92, 94, 97], "ani": [29, 31, 33, 34, 36, 37, 38, 40, 79, 85, 87, 90, 91, 94, 95, 96, 97, 98, 100, 101, 103], "Then": [29, 30, 31, 42, 43, 81, 83, 85, 88, 91, 93, 94, 97, 99, 100], "head": [29, 32, 33, 36, 37, 39, 41, 42, 43, 80, 81, 82, 83, 85, 87, 89, 91, 92, 93, 97, 98, 99, 102], "look": [29, 30, 31, 32, 34, 36, 37, 38, 39, 41, 42, 43, 45, 46, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "few": [29, 30, 31, 32, 37, 39, 41, 42, 43, 45, 86, 87, 90, 91, 94, 96, 97, 98, 99], "row": [29, 30, 31, 32, 37, 39, 41, 42, 43, 45, 80, 82, 83, 85, 86, 87, 90, 91, 94, 95, 96, 98, 101, 102, 103], "note": [29, 30, 34, 36, 38, 39, 40, 42, 43, 44, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103], "re": [29, 30, 33, 34, 36, 41, 43, 45, 80, 81, 82, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102], "just": [29, 30, 31, 33, 36, 38, 42, 46, 80, 83, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103], "so": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103], "worri": [29, 34, 85, 96, 97, 103], "reformat": 29, "write": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 79, 80, 81, 86, 89, 93, 95, 97, 99, 101], "here": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103], "versu": [29, 42, 88, 97], "term": [29, 31, 33, 34, 36, 39, 42, 85, 86, 88, 89, 90, 91, 94, 96, 99], "log": [29, 30, 34, 99, 100, 101], "doesn": [29, 40, 79, 81, 83, 87, 89, 90, 92, 93, 97, 98, 99, 100, 102], "too": [29, 80, 83, 84, 86, 90, 91, 92, 98, 101], "cumbersom": [29, 97], "chang": [29, 30, 32, 33, 36, 38, 41, 45, 46, 80, 82, 83, 84, 86, 88, 89, 91, 94, 97, 98, 99, 101], "run": [29, 30, 32, 36, 39, 41, 42, 79, 80, 81, 82, 83, 84, 85, 86, 90, 92, 93, 94, 95, 96, 97, 100], "output": [29, 30, 34, 36, 38, 40, 41, 42, 53, 79, 82, 83, 84, 86, 88, 90, 91, 92, 95, 96, 97, 103], "vrequir": 29, "tidyvers": [29, 30, 32, 33, 37, 38, 39, 42, 43, 46, 82, 84, 85, 86, 88, 90, 91, 92, 96, 98, 99, 101, 102], "packag": [29, 30, 34, 42, 80, 81, 82, 83, 84, 85, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103], "haven": [29, 83, 86, 89, 94, 96], "yet": [29, 83, 96, 97, 100], "fdata": 29, "numer": [29, 41, 83, 85, 86, 90, 97, 99], "cluster": [29, 45, 83, 86, 89, 92, 98, 103], "ggplot": [29, 32, 37, 38, 42, 46, 80, 83, 84, 85, 86, 88, 89, 91, 92, 96, 97, 98, 99, 101, 102, 103], "ae": [29, 45, 46, 80, 83, 84, 85, 86, 87, 88, 89, 91, 92, 96, 97, 98, 99, 101, 102, 103], "round": [29, 85, 88, 97, 101, 103], "col": [29, 80, 86, 90, 92, 96, 97, 98, 101], "geom_point": [29, 45, 80, 83, 84, 88, 89, 91, 92, 96, 97, 98, 101, 102, 103], "posit": [29, 30, 32, 41, 82, 83, 88, 90, 91, 102, 103], "jitter": 29, "alpha": [29, 36, 45, 83, 94, 101, 102], "theme_light": [29, 92, 96], "repons": 29, "interact": [29, 34, 47, 82, 86, 88], "glm": [29, 84, 86, 94], "its": [29, 38, 46, 79, 80, 81, 82, 83, 87, 90, 91, 93, 97, 99, 103], "summari": [29, 32, 33, 34, 37, 40, 41, 82, 83, 86, 88, 89, 91, 92, 95, 96, 97, 101, 103], "conclud": [29, 32, 36], "brief": [29, 87, 90], "gist": 29, "fine": [29, 100], "final": [29, 30, 31, 36, 42, 81, 90, 92, 93, 94, 97, 99, 100, 102], "threshold": [29, 38, 39, 83, 91, 94], "matrix": [29, 36, 37, 38, 42, 82, 83, 86, 91, 92, 94, 95, 96, 98], "overal": [29, 30, 42, 83, 91, 97, 102], "see": [29, 30, 31, 32, 33, 37, 38, 41, 42, 43, 44, 45, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "tutori": [29, 30, 31, 33, 35, 36, 37, 44], "did": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 80, 83, 84, 91, 94, 97, 98, 100, 102], "mass": [29, 83, 86, 88, 103], "librari": [29, 31, 33, 34, 36, 37, 38, 41, 42, 80, 82, 83, 84, 85, 86, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "ran": 29, "actual": [29, 30, 31, 36, 40, 42, 43, 45, 83, 87, 89, 90, 91, 94, 97, 98, 99, 100, 102, 103], "whole": [29, 83, 92, 97, 99, 101], "5pm": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "est": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 91], "march": [29, 30, 34, 39, 42, 43], "20": [29, 38, 40, 46, 82, 83, 84, 86, 90, 91, 94, 96, 99], "2023": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 59, 86], "collabor": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 100], "anyon": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 81, 93], "list": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 82, 83, 84, 85, 86, 90, 91, 96, 100, 103], "someon": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46], "techniqu": [30, 40, 88], "fold": [30, 87, 92, 94], "pimaindiansdiabetes2": 30, "dataset": [30, 31, 32, 40, 42, 45, 46, 80, 82, 83, 84, 85, 86, 88, 91, 92, 94, 95, 96, 97, 98, 101, 102], "medic": 30, "pima": 30, "nativ": [30, 81, 93], "american": [30, 63], "women": 30, "diabet": [30, 42], "part": [30, 33, 36, 40, 42, 43, 80, 83, 86, 96, 97, 98, 100, 102], "mlbench": 30, "person": [30, 88, 97, 100, 101], "histori": 30, "been": [30, 83, 86, 87, 91, 99, 100], "diagnos": 30, "load": [30, 33, 36, 38, 40, 42, 43, 45, 46, 80, 82, 83, 84, 86, 89, 91, 92, 94, 95, 96, 97, 99, 101, 102, 103], "boot": [30, 84, 88, 95], "instal": [30, 31, 34, 37, 45, 80, 82, 83, 84, 86, 88, 89, 91, 92, 94, 95, 96, 97, 98, 100, 102, 103], "drop": [30, 31, 37, 84, 89, 91, 97], "insulin": 30, "column": [30, 31, 37, 42, 80, 82, 83, 85, 86, 87, 90, 91, 94, 96, 98, 102, 103], "lot": [30, 80, 81, 86, 90, 91, 93, 96, 97, 98, 99, 100, 101, 102], "na": [30, 32, 35, 36, 37, 38, 39, 42, 43, 86, 91, 94, 95, 96, 97], "rest": [30, 42, 79, 80, 83, 97, 103], "save": [30, 31, 35, 41, 44, 45, 80, 84, 85, 90, 91, 97, 100], "updat": [30, 42, 47, 80, 86], "new": [30, 32, 35, 37, 39, 40, 41, 42, 43, 44, 50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 75, 80, 81, 83, 85, 86, 88, 91, 92, 93, 94, 95, 96, 98, 101], "print": [30, 33, 36, 40, 42, 79, 83, 84, 85, 87, 89, 90, 91, 94, 95, 96, 97, 98, 100, 103], "line": [30, 32, 38, 41, 42, 43, 45, 46, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 96, 97, 99, 100, 101, 102, 103], "insert": [30, 31, 32, 41, 42, 45, 46, 79, 101], "pedigre": 30, "refer": [30, 46, 79, 81, 87, 93, 97, 99, 100, 101], "famili": [30, 83, 97], "condit": [30, 82, 91], "higher": [30, 38, 82, 83, 84, 88, 92, 101], "greater": [30, 42, 84, 86, 91], "manual": [30, 80, 82, 91, 96, 97, 100, 101], "past": [30, 40, 83, 84, 90, 97, 98], "let": [30, 31, 37, 38, 41, 42, 43, 45, 46, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103], "dichotom": 30, "modifi": [30, 35, 38, 45, 102], "except": [30, 84, 87, 96], "holdout": 30, "rememb": [30, 31, 38, 83, 86, 89, 90, 92, 94, 95, 97, 98, 99, 100, 101, 103], "odd": 30, "50": [30, 33, 36, 38, 42, 83, 91, 92, 94, 97, 98], "abov": [30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 45, 46, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102], "iter": [30, 39, 83, 87, 94, 95, 97], "loocv": 30, "531": [30, 86], "last": [30, 36, 38, 46, 83, 86, 87, 88, 90, 97, 99, 100], "loop": [30, 36, 38, 84, 86, 90, 91, 95, 97], "through": [30, 86, 87, 88, 90, 98, 99, 100, 101], "thing": [30, 36, 41, 43, 80, 81, 82, 84, 85, 86, 87, 91, 92, 93, 96, 97, 98, 100, 101], "creat": [30, 31, 37, 42, 44, 45, 46, 81, 83, 84, 85, 86, 87, 90, 91, 93, 94, 100, 101, 102, 103], "hold": [30, 88, 94, 97], "true": [30, 37, 82, 84, 85, 86, 88, 90, 91, 92, 94, 95, 96, 97, 98, 102], "classif": [30, 50, 70, 83, 98], "fill": [30, 36, 80, 87, 95, 97, 101, 102], "store": [30, 31, 36, 42, 79, 85, 86, 87, 91, 95, 97, 100], "pull": [30, 31, 36, 97, 98, 99], "remain": [30, 90, 92, 97], "po": [30, 102], "datafram": [30, 32, 37, 39, 42, 43, 85, 91, 94, 97, 98, 101, 103], "after": [30, 43, 81, 82, 84, 86, 89, 91, 92, 93, 97, 99, 100, 101], "initi": [30, 36, 42, 84, 87, 97, 100, 101, 102, 103], "nrow": [30, 36, 38, 83, 84, 86, 87, 91, 92, 94, 95, 97, 98, 101], "dat": [30, 33, 36, 85, 91, 92, 97, 98], "don": [30, 31, 36, 37, 42, 83, 84, 85, 86, 87, 89, 90, 91, 92, 95, 96, 97, 98, 100, 102, 103], "forget": [30, 37], "proport": [30, 81, 88, 91, 93], "were": [30, 36, 41, 82, 89, 91, 92, 95, 96, 97, 98, 100, 102], "diagnosi": [30, 42], "becaus": [30, 31, 38, 42, 80, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101], "cost": [30, 42, 84], "argument": [30, 35, 42, 82, 90, 91, 97, 101], "doc": [30, 79], "vector": [30, 31, 35, 36, 38, 40, 81, 83, 84, 85, 86, 91, 92, 93, 94, 95, 96], "specifi": [30, 46, 84, 85, 87, 91, 94, 97, 99, 100, 101, 102], "correspond": [30, 83, 85, 86, 87, 91, 97, 100], "second": [30, 41, 84, 87, 88, 89, 91, 92, 95, 96, 97, 98, 99, 101], "scroll": 30, "bottom": [30, 83, 86, 88, 90, 96, 97, 100], "appropri": [30, 39, 80, 100, 102], "pi": [30, 87, 99], "ab": 30, "5": [30, 35, 38, 44, 49, 52, 65, 72, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103], "technic": [30, 87, 94, 96, 97], "treat": [30, 88, 89, 99, 102], "hood": 30, "thu": [30, 80, 83, 84, 86, 88, 89, 90, 91, 94, 96, 97, 98, 99, 101], "boil": [30, 31, 80, 89, 90, 102], "recal": [30, 38, 97], "drawback": [30, 84], "quit": [30, 89, 91, 92, 97, 98], "10": [30, 31, 33, 35, 36, 40, 53, 72, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 103], "15": [30, 34, 45, 59, 80, 82, 86, 87, 89, 90, 91, 92, 96, 97, 98], "seed": [30, 37, 38, 40, 42, 84, 86, 91, 92, 94, 95, 98], "slightli": [30, 83, 86], "expect": [30, 31, 45, 46, 82, 86, 89, 91, 95], "27": [30, 32, 44, 84, 87, 88, 89, 103], "These": [31, 80, 84, 87, 89, 90, 95, 97, 102, 103], "comfort": [31, 41, 45, 83, 87, 97, 99, 100, 103], "credit": 31, "islr": [31, 83, 84, 86, 92, 94, 95, 96, 98], "simul": [31, 40, 88, 97], "demograph": [31, 98], "000": [31, 40, 42, 101], "custom": [31, 81, 93, 97], "nice": [31, 46, 83, 99], "card": 31, "owner": 31, "rate": [31, 42, 84, 89, 98, 101, 102], "gender": [31, 32, 39, 80], "student": [31, 88, 90], "statu": [31, 91, 100], "cred_lm": 31, "lm": [31, 32, 43, 82, 84, 85, 86, 88, 89, 95, 96, 97, 103], "residu": [31, 82, 83, 85, 86, 88, 89, 97, 103], "sigma": [31, 87, 91, 99], "195": [31, 103], "9": [31, 35, 38, 53, 69, 72, 80, 81, 82, 84, 86, 87, 89, 90, 91, 92, 93, 96, 97, 98, 100, 102, 103], "directli": [31, 79, 80, 82, 83, 96, 97, 100, 101], "sqrt": [31, 35, 97, 99], "sse": 31, "sum": [31, 83, 86, 90, 92, 94, 95, 96, 98, 99], "intercept": [31, 33, 34, 40, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 102, 103], "denomin": [31, 82, 99], "degre": [31, 38, 46, 82, 83, 84, 86, 88, 89, 103], "freedom": [31, 82, 83, 86, 88, 89, 103], "ve": [31, 43, 81, 82, 84, 86, 87, 88, 92, 93, 96, 97, 98, 99, 100], "realli": [31, 86, 90, 94, 97, 100, 101, 102], "oper": [31, 41, 81, 88, 90, 93, 100], "easili": [31, 45, 80, 85, 90, 97, 100, 102, 103], "appli": [31, 37, 80, 82, 87, 92, 97, 99, 101, 102, 103], "element": [31, 40, 45, 87, 90, 91, 101, 102], "combin": [31, 33, 38, 88, 90, 91, 92, 100, 101, 102], "return": [31, 35, 36, 83, 85, 86, 87, 90, 91, 94, 95, 100, 101, 102, 103], "your_funct": 31, "own": [31, 35, 40, 46, 81, 83, 86, 90, 91, 93, 95, 100, 101], "want": [31, 36, 37, 39, 41, 45, 46, 80, 82, 83, 84, 85, 86, 87, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "entir": [31, 79, 86, 88, 98], "mayb": [31, 42, 88], "public": [31, 76, 89], "saw": [31, 97, 98, 101], "str": [31, 82, 85], "won": [31, 33, 36, 38, 40, 84, 87, 88, 97, 103], "That": [31, 41, 80, 85, 87, 97, 99, 100], "itself": [31, 83, 90], "right": [31, 37, 80, 81, 83, 84, 86, 87, 90, 93, 96, 97, 99, 100, 102], "further": [31, 87], "interest": [31, 38, 45, 76, 82, 88, 89, 91, 95, 97, 100], "se": [31, 80, 84, 88, 89, 91, 102, 103], "alter": 31, "minu": [31, 41, 99], "finish": [31, 35, 41, 45, 97, 100], "notebook": [31, 35, 40, 41, 43, 44, 45, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "exercise3": 31, "ipynb": [31, 35, 41, 44, 45, 79], "push": [31, 35, 41, 44, 45, 100], "send": [31, 35, 41, 45, 97], "instructor": [31, 35, 41, 44, 45, 81, 93], "canva": [31, 35, 41, 44, 45], "messag": [31, 35, 80, 90, 91, 100, 101, 102], "click": [31, 35, 43, 100], "inbox": [31, 35], "left": [31, 35, 37, 45, 83, 84, 88, 90, 97, 99, 100, 102], "press": [31, 35], "icon": [31, 35], "pencil": [31, 35], "insid": [31, 35, 79, 87, 90, 99, 100], "feb": [31, 35, 41, 45, 46], "8": [31, 33, 35, 36, 44, 72, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 102, 103], "download": [32, 37, 39, 41, 80, 81, 93, 97, 100, 102], "unrestricted_trimmed_1_7_2020_10_50_44": [32, 37, 39, 43], "hcp_data": [32, 37, 39, 43], "portion": [32, 37, 39, 42, 43, 87], "connectom": [32, 37, 39, 43], "cognit": [32, 37, 39, 43, 72, 78], "brain": [32, 37, 39, 43, 53, 58, 59, 62], "morpholog": [32, 37, 39, 43], "measures": [32, 37, 39], "1206": [32, 37, 39, 43], "particip": [32, 36, 37, 39, 43, 82, 89, 91, 97], "hcp_s1200_datadictionary_april_20_2018": [32, 37, 39, 43], "setwd": [32, 39, 41, 43], "tool": [32, 37, 39, 43, 79, 80, 81, 83, 84, 87, 89, 91, 92, 93, 97, 99, 100, 101, 103], "d1": [32, 37, 39, 43], "inclu": [32, 39, 43], "id": [32, 34, 39, 41, 43, 82, 90, 91, 97, 102], "flanker": [32, 39, 43], "flanker_unadj": [32, 37, 39, 43], "total": [32, 38, 39, 43, 83, 88, 91, 97], "white": [32, 39, 101], "matter": [32, 43, 87, 92, 97, 99], "volum": [32, 37, 39, 43, 83], "fs_tot_wm_vol": [32, 39], "grei": [32, 43], "fs_total_gm_vol": [32, 39, 43], "wet": [32, 41], "workign": [32, 41], "directori": [32, 41, 81, 93, 100], "locat": [32, 41, 45, 86, 88, 90, 97, 103], "harddriv": [32, 41], "uncom": [32, 41, 82, 83, 84, 86, 88, 89, 92, 94, 95, 96, 97, 103], "document": [32, 41, 79, 80, 81, 86, 89, 91, 93, 100], "pittcmu": [32, 41], "g3": [32, 41], "dspn": [32, 41], "datasciencepsychneuro": [32, 41], "colab": [32, 41, 103], "gdown": [32, 41], "1hywrmgdvhbdytrqryl1_bljsq": 32, "t3gjq2": 32, "pair": [32, 82, 85, 95, 103], "pairwis": [32, 83], "scatterplot": [32, 42, 45, 80, 86, 101, 103], "seem": [32, 83, 86, 89, 90, 91, 92, 98, 102], "associ": [32, 39, 40, 79, 81, 86, 89, 91, 93, 95, 97, 102, 103], "y_": [32, 83, 86], "beta_0": [32, 40, 43, 83, 86, 99, 103], "beta_1": [32, 40, 43, 83, 86, 99, 103], "x_": [32, 83, 86, 87, 98], "gm": 32, "coef": [32, 84, 85, 91, 94, 95, 97, 103], "95": [32, 37, 82, 87, 88, 91, 92, 97, 102, 103], "interv": [32, 39, 82, 88, 91, 95, 101, 102, 103], "confint": [32, 103], "significantli": [32, 82, 88, 91], "axi": [32, 39, 45, 46, 80, 101, 102], "regrssion": 32, "qualit": [32, 38, 94, 95, 98], "februari": [32, 88], "instead": [33, 41, 45, 46, 80, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102], "go": [33, 34, 36, 37, 38, 43, 80, 81, 83, 88, 90, 91, 93, 95, 97, 100, 102, 103], "comprehens": [33, 36, 91, 100, 103], "skill": [33, 36, 88], "older": 33, "children": [33, 36, 102], "tend": [33, 88], "isn": [33, 34, 45, 82, 83, 84, 87, 101], "inher": 33, "gain": [33, 42], "oral": 33, "languag": [33, 79, 85, 87, 88, 90, 97, 99, 100], "execut": [33, 81, 86, 90, 93, 97, 103], "though": [33, 81, 82, 83, 86, 87, 88, 89, 90, 93, 99], "simplifi": [33, 43, 87, 92, 99], "direct": [33, 36, 82, 83, 88, 90, 92], "sinc": [33, 34, 36, 82, 83, 84, 87, 88, 89, 90, 92, 95, 96, 97, 98, 99, 101, 103], "improv": [33, 36, 42, 46, 84, 88, 91, 94, 102], "guarante": 33, "beta_": [33, 83, 91], "xa": 33, "x0": 33, "epsilon_": [33, 91], "c": [33, 35, 36, 37, 38, 40, 43, 53, 68, 80, 81, 82, 83, 84, 86, 87, 88, 90, 91, 93, 96, 97, 98, 99, 100, 102, 103], "ca": 33, "cx": [33, 99], "c0": 33, "epsilon_c": [33, 36], "respect": [33, 43, 84, 91, 92, 97, 99], "formula": [33, 35, 43, 82, 83, 84, 85, 86, 87, 88, 89, 91, 96, 102, 103], "gaussian": [33, 36], "nois": [33, 36, 40, 85, 86, 91], "simulate_data": [33, 36, 91], "input": [33, 79, 84, 85, 86, 90, 91, 92, 95, 97, 98, 99, 102, 103], "complet": [33, 87], "those": [33, 40, 79, 84, 86, 87, 88, 89, 90, 92, 94, 96, 97, 98, 99, 100, 101, 103], "runif": [33, 36], "rnorm": [33, 38, 40, 85, 86, 91], "sample_s": [33, 36, 91], "100": [33, 36, 40, 86, 87, 90, 91, 92, 94, 98, 101], "age_lo": [33, 36], "80": [33, 36, 86, 90, 91, 92], "minimum": [33, 36, 37, 91, 96, 99], "month": [33, 36, 90, 102], "age_hi": [33, 36], "200": [33, 36, 91], "maximum": [33, 36, 95, 96, 99, 101], "beta_xa": [33, 36], "beta_x0": [33, 36], "sd_x": [33, 36], "dev": [33, 36, 89, 100], "epsilon_x": [33, 36], "beta_ca": [33, 36], "score": [33, 36, 37, 82, 83, 89, 90, 96, 103], "everi": [33, 36, 46, 86, 87, 91, 92, 96, 97, 98, 99, 101], "unit": [33, 36, 45, 86, 92, 98, 101, 102], "beta_cx": [33, 36], "beta_c0": [33, 36], "sd_c": [33, 36], "85": [33, 36, 47, 86, 92, 103], "yield": [33, 91, 98], "april": [33, 36, 37, 38, 40], "unlik": 34, "previou": [34, 38, 45, 46, 83, 84, 86, 88, 91, 97, 98, 99, 100, 101, 102], "As": [34, 36, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 97, 98, 99, 102, 103], "comma": [34, 41, 97], "convert": [34, 90, 102], "them": [34, 46, 80, 81, 82, 85, 86, 87, 89, 90, 91, 93, 94, 97, 98, 99, 100, 101, 102, 103], "freq_hal": 34, "issu": [34, 81, 84, 86, 93, 97, 101], "fix": [34, 45, 80, 89, 102, 103], "natur": [34, 80, 81, 86, 93, 97, 99], "transform": [34, 53, 94, 98, 99, 101, 103], "d_rt": [34, 41], "lme4": [34, 58, 89, 91], "sub_id": [34, 41], "shift": [34, 42, 97], "rt": [34, 89, 91], "aikek": 34, "control": [34, 36, 38, 45, 74, 80, 86, 90, 91, 97, 102], "discuss": [35, 44, 83, 86, 87, 88, 91, 92, 98, 99, 100], "deviat": [35, 39, 41, 91, 97], "keep": [35, 42, 85, 86, 95, 100], "short": [35, 90, 97], "snake": [35, 90], "multipl": [35, 57, 82, 85, 88, 89, 91, 99, 100, 101, 103], "command": [35, 79, 81, 83, 85, 87, 91, 93, 97, 100, 101, 103], "v1": 35, "11": [35, 82, 85, 86, 87, 88, 92, 96, 97, 98, 100], "6": [35, 44, 50, 52, 55, 56, 61, 62, 64, 65, 66, 67, 70, 71, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103], "your_function_nam": 35, "mu": [35, 82, 99], "popul": [35, 45, 46, 80, 86, 91], "size": [35, 40, 60, 80, 84, 85, 86, 88, 96, 97, 98, 101, 102, 103], "ttest_fun": 35, "mind": [35, 38, 90, 95, 100], "suppli": [35, 83, 87, 97, 101], "v2": 35, "7": [35, 44, 82, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102], "12": [35, 38, 60, 82, 85, 86, 87, 89, 90, 92, 94, 96, 98, 102], "exercise2": 35, "conduct": [36, 82, 83, 94], "week": [36, 46], "remind": [36, 38, 82, 91, 98], "bad": [36, 83, 86, 102], "my": [36, 79, 80, 82, 87, 95, 99, 100], "order": [36, 37, 38, 42, 80, 83, 84, 85, 86, 87, 88, 90, 91, 94, 97, 100, 101, 103], "detect": [36, 88, 91], "pretend": [36, 100], "sake": [36, 38, 83], "simplic": [36, 38, 80, 83], "although": [36, 83, 84, 98], "cours": [36, 80, 92], "unusu": [36, 102], "realiti": [36, 101], "contain": [36, 40, 41, 45, 46, 80, 83, 84, 90, 94, 95, 96, 97, 99, 100, 101, 102, 103], "acm": [36, 88], "d0": 36, "z0": 36, "object": [36, 37, 42, 43, 82, 84, 86, 90, 91, 94, 95, 96, 97, 98, 101, 102, 103], "fitm": [36, 88], "previous": [36, 83, 98], "next": [36, 45, 46, 83, 85, 87, 91, 95, 97, 98, 99, 100, 103], "num_simul": 36, "simout": [36, 91], "rep": [36, 42, 82, 83, 84, 85, 86, 91, 96], "ncol": [36, 38, 86, 87, 91, 95, 102], "acme_cov": 36, "IN": 36, "ade_cov": 36, "01": [36, 82, 86, 88, 89, 91, 92, 97, 98, 103], "75": [36, 86, 88, 92, 94, 97], "125": [36, 82, 90, 91], "150": [36, 38, 89, 96, 97, 98], "up": [36, 37, 38, 40, 42, 43, 80, 81, 83, 84, 86, 90, 92, 93, 96, 97, 99, 102], "around": [36, 38, 41, 86, 88, 92, 96, 99, 103], "minut": [36, 42, 84, 86, 88, 91, 98, 102], "per": [36, 45, 46, 84, 86, 88, 89, 90, 91, 95, 97, 102, 103], "harder": 36, "earlier": [37, 90, 97], "low": [37, 82, 83, 86, 88], "memori": 37, "ggplot2": [37, 38, 42, 45, 80, 83, 86, 89, 92, 97, 99, 101, 103], "freesurf": 37, "hemispher": 37, "consist": [37, 86, 91, 97, 101], "zero": [37, 40, 43, 44, 82, 86, 87, 91, 94, 95, 103], "ends_with": [37, 97], "end": [37, 44, 80, 83, 84, 86, 87, 92, 94, 95, 96, 98, 100, 103], "_vol": 37, "fs_": 37, "cor": [37, 83, 86, 92], "call": [37, 38, 79, 82, 83, 85, 86, 87, 88, 89, 90, 91, 95, 96, 97, 100, 101, 102, 103], "fs_cor": 37, "reshape2": 37, "melt": 37, "heatmap": [37, 86, 101], "scale_fill_gradient2": 37, "color": [37, 39, 42, 46, 80, 86, 89, 91, 96, 97, 98, 99, 101, 102], "red": [37, 86, 91, 99, 102], "blue": [37, 86, 98], "cap": 37, "fs_d": 37, "pca": [37, 86], "princomp": [37, 86], "cumul": [37, 92], "begin": [37, 80, 81, 87, 93, 97], "receiv": [37, 82, 90], "flag": 37, "somewher": [37, 80, 86], "validationplot": [37, 92], "msep": [37, 92], "cv": [37, 84, 92, 94], "adj_cv": 37, "funtion": 37, "arrai": [37, 84, 86, 87, 95], "singleton": 37, "origin": [37, 39, 86, 87, 88, 90, 91, 92, 95, 97, 99, 100, 103], "2x1x53": 37, "2x53": 37, "alon": 37, "variat": [37, 79, 89, 91, 97], "17": [37, 82, 84, 85, 86, 92, 96, 97], "properti": [38, 85, 87], "ultra": 38, "happen": [38, 80, 86, 89, 94, 97, 98, 100], "glmnet": [38, 86, 94], "cosin": 38, "121": [38, 83], "sigma_nois": 38, "seq": [38, 42, 80, 83, 85, 86, 87, 94, 99], "18": [38, 80, 85, 87, 88, 89, 92, 96, 97, 101], "co": [38, 99], "sd": [38, 85, 86, 91, 97], "51": [38, 88, 92, 97, 98], "randomli": [38, 42, 84, 86, 95, 101, 103], "expand": [38, 43, 85, 87, 91, 99], "_0": 38, "sum_": [38, 84, 87, 99], "_jx": 38, "poli": [38, 84], "2nd": [38, 84], "help": [38, 41, 42, 44, 45, 80, 81, 83, 86, 87, 89, 90, 91, 92, 93, 96, 97, 99, 101, 102, 103], "stat_smooth": [38, 80, 84], "12th": 38, "wors": [38, 88, 94], "median": [38, 82, 83, 86, 88, 89, 103], "throw": [38, 95], "off": [38, 39, 80, 83, 84, 86], "trade": [38, 83, 84], "setup": [38, 44, 94, 100], "train_rss": [38, 86], "test_rss": [38, 86], "copi": [38, 40, 41, 95, 100], "beyond": [38, 63], "geom_vlin": [38, 99, 102], "draw": [38, 80, 82, 83, 84, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 102, 103], "vertic": [38, 89, 102], "clear": [38, 80, 82, 86, 88, 90, 91, 96, 102], "larger": [38, 42, 86, 87, 90, 94, 95, 98, 99, 102], "repeat": [38, 40, 84, 85, 89, 91, 94, 97, 99, 100], "sparsiti": [38, 94], "lambda": [38, 94], "00005": 38, "rm": [38, 86], "shown": [38, 84, 87, 90, 94, 96, 97, 102], "upper": [38, 88, 100, 102, 103], "self": [39, 88], "collect": [39, 88, 91, 97], "intracrani": 39, "fs_intracranial_vol": 39, "scatter": [39, 92, 101], "logis": 39, "signficantli": 39, "histogram": [39, 81, 93, 101], "robust": [39, 98], "1000": [39, 88, 91, 95, 98], "much": [39, 42, 82, 84, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 102], "contribut": [39, 92, 102], "unpermut": [39, 95], "ablin": [39, 103], "29": [39, 86, 92], "question": [40, 43, 45, 46, 80, 82, 83, 88, 89, 91, 95, 97, 101], "beta_1x": 40, "beta_2x": 40, "beta_3x": 40, "beta_2": [40, 83], "beta_3": [40, 83], "constant": [40, 86, 87, 88], "regsubset": [40, 96], "view": [40, 81, 86, 93, 97, 99], "otherwis": [40, 82, 83, 86, 91, 99], "delet": [40, 86, 100, 103], "cell": [40, 41, 43, 44, 79, 80, 81, 85, 86, 90, 93, 94, 97, 103], "leav": [40, 97], "blank": 40, "mallow": [40, 96], "cp": [40, 96], "criteria": 40, "explor": [40, 79, 80, 84, 86, 99, 102, 103], "split": [40, 42, 46, 84, 86, 88, 91, 94, 99, 102], "900": 40, "mse": [40, 43, 84, 92, 94, 99], "identifi": [40, 45, 82, 84, 87, 91, 92, 96, 97, 100], "until": [40, 84, 86, 91, 100], "minim": [40, 43, 62, 86], "intermedi": [40, 97], "lexicaldata_toclean": 41, "1wsvrpme5nimuda0t3wqnsgzimlb1una7": 41, "d_word": 41, "useabl": 41, "check": [41, 42, 43, 46, 81, 83, 87, 91, 92, 93, 95, 97, 100, 101, 103], "gsub": 41, "filter": [41, 85, 91, 96, 102], "sure": [41, 82, 89, 91, 94, 95, 98, 99], "action": [41, 86], "address": [41, 42, 84, 87, 100], "m\u00fcller": [41, 68], "third": [41, 88, 97, 99, 101], "plai": [41, 80, 82, 86, 88, 96, 97, 102], "bit": [41, 43, 45, 86, 87, 92, 98, 101, 103], "pipe": [41, 85, 101], "summaris": [41, 101], "mutat": [41, 82, 85, 88, 91, 101, 102], "equal": [41, 82, 83, 87, 90, 97, 98, 99], "exercise4": 41, "13": [41, 69, 82, 85, 86, 88, 89, 91, 92, 96, 97, 98, 102, 103], "diamond": [42, 101], "qualiti": [42, 83, 86, 88, 91], "price": [42, 86, 88, 101, 103], "simpler": [42, 82, 84], "price_bin": 42, "indic": [42, 45, 83, 84, 86, 87, 92, 94, 96, 97, 98, 103], "if_els": [42, 97], "carat": [42, 101], "depth": [42, 82, 103], "aesthet": [42, 45, 102], "belong": 42, "asid": [42, 45, 84, 90, 97, 98, 101], "divid": [42, 83, 87, 91, 92, 95, 99], "30": [42, 82, 83, 89, 91, 92, 97, 98, 99, 101, 102], "allot": 42, "doubl": [42, 43, 46, 90, 100], "divis": [42, 94, 96], "review": [42, 49, 78, 87, 97, 99, 100], "format": [42, 43, 53, 82, 83, 85, 90, 97, 99, 101], "requir": [42, 80, 82, 83, 86, 89, 90, 91, 92, 94, 97, 98, 99, 100], "rerun": 42, "addit": [42, 90, 92, 97, 100, 101, 102], "didn": [42, 99], "hand": [42, 80, 92, 99, 102], "empti": [42, 91, 96, 100], "knn_fit": 42, "conf_df": 42, "geom_smooth": [42, 45, 80, 88, 89, 101, 102, 103], "layer": [42, 46, 98, 101], "sensit": [42, 84], "magnitud": [42, 89], "even": [42, 81, 82, 86, 87, 88, 89, 90, 91, 93, 97, 98, 99, 100, 101], "optim": [42, 91], "rescal": [42, 103], "22": [42, 76, 82, 85, 86, 92], "deeper": [43, 94], "dive": [43, 85, 94], "math": [43, 87, 99], "behind": [43, 88, 97, 101], "close": [43, 45, 82, 83, 84, 86, 91], "section": [43, 90, 91, 92, 97, 98, 99, 100, 102], "latex": 43, "equat": [43, 80, 84, 99], "page": [43, 79, 81, 93], "mle": 43, "algebra": [43, 101], "ii": 43, "var": [43, 80, 85, 91, 92, 97, 98, 99, 102], "prove": [43, 99], "solv": 43, "plug": [43, 99], "onc": [43, 79, 81, 85, 89, 91, 93, 96, 97, 99, 100], "xy": [43, 99], "assignemnt": 44, "recit": [44, 103], "wiki": 44, "video": [44, 81, 92, 93, 99], "titl": [44, 46, 80, 86], "00": [44, 87, 88, 92, 99], "access": [44, 85, 87, 90, 100], "submit": [44, 81, 93, 100], "materi": [44, 97], "post": 44, "throughout": 44, "semest": [44, 47, 80], "your_last_nam": 44, "_dspn_s23": 44, "user": [44, 80, 100], "coaxlab0": 44, "ta": [44, 87], "fhorner": 44, "clone": [44, 100], "collaboratori": 44, "rocket": 44, "button": 44, "googl": [44, 90, 102], "drive": [44, 99, 100, 103], "homework1_helloworld": 44, "hello": 44, "comment": [44, 80, 90], "email": [44, 80, 81, 93, 100], "jan": 44, "gapmind": [45, 46], "life": [45, 46, 87], "capita": [45, 46], "gdp": [45, 46], "countri": [45, 46, 102], "basic": [45, 80, 88, 95, 97, 99, 102, 103], "contin": [45, 46], "trend": [45, 91, 101, 102], "hmm": 45, "weird": [45, 86, 97], "unexpect": 45, "difficult": [45, 97, 101, 102], "caus": [45, 88, 102], "graph": [45, 101, 102], "drawn": [45, 91, 99], "top": [45, 83, 90, 96, 97], "black": [45, 90, 98, 101, 102], "underneath": [45, 102], "attribut": [45, 46, 92, 95, 96, 101], "global": [45, 46, 90, 100], "option": [45, 80, 81, 85, 86, 90, 91, 93, 97, 98, 100, 101, 102, 103], "overlai": 45, "gdppercap": 45, "lifeexp": 45, "squish": 45, "side": [45, 83, 97, 99], "hard": [45, 90, 92], "To": [45, 46, 81, 82, 85, 86, 88, 89, 90, 91, 93, 96, 97, 98, 100, 101, 102, 103], "transpar": [45, 72, 101, 102], "incorpor": [45, 90, 102], "alreadi": [45, 79, 86, 87, 97, 100, 101, 102, 103], "fite": 45, "introduc": [45, 82, 84, 91, 100], "trendlin": 45, "exercise5": 45, "advanc": [46, 85], "altern": [46, 81, 82, 85, 86, 90, 91, 93, 100], "facet": [46, 102], "panel": 46, "25": [46, 80, 82, 84, 88, 89, 97, 99, 102], "america": 46, "facet_wrap": [46, 85, 102], "addition": [46, 91], "easier": [46, 83, 87, 90, 97, 99, 100, 101], "theme": [46, 80, 102], "rotat": [46, 92, 102], "45": [46, 58, 86, 89, 97], "imagin": [46, 85, 87, 97, 100], "publish": 46, "manuscript": 46, "cleaner": [46, 97, 102], "label": [46, 80, 83, 85, 87, 97, 98, 101, 103], "lab": [46, 80, 81, 82, 83, 84, 86, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "legend": 46, "90": [46, 86, 88, 92, 97], "vari": [46, 84, 88, 89, 92, 102], "five": 46, "boxplot": [46, 101], "repres": [46, 85, 86, 87, 88, 89, 96, 101, 102], "year": [46, 83, 88, 94, 96, 98, 102], "element_blank": [46, 80], "readabl": [46, 90, 97], "ink": [46, 102], "edit": [46, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103], "welcom": [47, 81, 82, 93], "jupyt": [47, 79, 80, 103], "book": [47, 79, 81, 84, 93, 101], "cmu": [47, 81, 93, 100], "432": 47, "732": 47, "supplement": [47, 53, 72, 82], "standalon": 47, "content": [47, 79, 80, 86, 100, 103], "sourc": [47, 80, 81, 93, 97, 100], "continu": [47, 84, 86, 100, 101, 102], "throughtout": 47, "pleas": [47, 82], "refresh": 47, "wagenmak": 49, "pervas": 49, "psychonom": 49, "bulletin": 49, "14": [49, 80, 85, 86, 87, 88, 92, 96, 97, 102], "779": 49, "804": 49, "chapter": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 75, 83, 84, 86, 88, 89, 92, 94, 95, 96, 98, 102, 103], "jame": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 83, 84, 86, 92, 94, 95, 96, 98, 103], "witten": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 83, 84, 86, 92, 94, 95, 96, 98, 103], "hasti": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 83, 84, 86, 92, 94, 95, 96, 98, 103], "tibshirani": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 83, 84, 86, 92, 94, 95, 96, 98, 103], "introduct": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 75, 82, 83, 84, 86, 87, 92, 94, 95, 96, 97, 98, 100, 101, 103], "applic": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 83, 84, 86, 92, 94, 95, 96, 98, 100, 103], "vol": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71], "york": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72], "springer": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71], "2021": [51, 76, 77, 100], "build": [51, 77, 79, 80, 90, 103], "verisimilitud": [51, 77], "explanatori": [51, 77], "perspect": [51, 77], "platt": 51, "1964": 51, "strong": [51, 88, 91, 94], "146": [51, 91], "3642": 51, "347": [51, 92], "353": [51, 92], "wickham": 53, "2014": [53, 60, 89], "journal": 53, "softwar": [53, 81, 87, 90, 93, 102], "59": [53, 84, 86, 96], "1": [53, 59, 60, 62, 63, 67, 72, 73, 75, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103], "23": [53, 84, 85, 88, 89, 92, 97], "gorgolewski": 53, "auer": 53, "calhoun": 53, "v": 53, "craddock": 53, "da": [53, 87], "duff": 53, "handwerk": 53, "2016": [53, 72], "imag": [53, 83, 87, 100, 102], "organ": [53, 85, 90], "neuroimag": 53, "grolemund": 53, "o": [53, 59, 72, 77, 98], "reilli": 53, "media": 53, "inc": 53, "1997": 54, "virtu": 54, "necess": 54, "philosophi": 54, "64": [54, 82, 85, 86], "s4": [54, 89], "s195": 54, "s212": 54, "preacher": 57, "hay": 57, "2008": 57, "asymptot": 57, "assess": [57, 60, 91], "indirect": [57, 88], "40": [57, 80, 87, 88, 91, 92, 97, 98, 99], "879": 57, "891": 57, "bate": [58, 89], "dougla": 58, "2010": [58, 102], "470": 58, "474": 58, "2022": 58, "crisi": 58, "e1": 58, "survei": 59, "1959": 59, "routledg": 59, "On": [59, 89, 90, 102], "behaviour": 59, "beaujean": [60, 91], "19": [60, 63, 80, 84, 86, 92, 96], "regular": [61, 66, 79, 89], "dretsk": 62, "1983": 62, "pr\u00e9ci": 62, "flow": [62, 90], "55": [62, 82, 86, 87, 92, 95, 97, 98], "63": [62, 86, 92, 97, 98], "vlastelica": 62, "schirm": 63, "lazar": 63, "move": [63, 83, 84, 88, 92, 99], "05": [63, 80, 82, 83, 86, 88, 89, 91, 92, 97, 103], "statistician": 63, "73": [63, 82, 88, 92, 97, 98], "s1": 63, "freytag": 68, "2003": [68, 83], "challeng": 68, "berlin": 68, "hub": 68, "ib": 68, "164": 68, "mensh": 69, "ten": [69, 72], "rule": [69, 72, 87, 90, 102], "plo": [69, 72], "biol": [69, 72], "e1005619": 69, "goodman": 72, "fanelli": 72, "ioannidi": 72, "translat": [72, 80, 87, 90], "medicin": 72, "341": [72, 82, 85, 92], "341ps12": 72, "nekrutenko": 72, "taylor": 72, "hovig": 72, "e1003285": 72, "gilmor": 72, "diaz": 72, "wybl": 72, "progress": [72, 91, 100], "annal": 72, "academi": 72, "1396": 72, "de": 73, "regt": 73, "w": 73, "diek": 73, "2005": [73, 83], "synthes": 73, "144": [73, 91], "137": 73, "170": 73, "ipython": 74, "displai": [74, 79, 81, 91, 93, 97, 101, 103], "html": 74, "youtub": 74, "ifram": 74, "width": [74, 80, 85, 86, 88, 91, 92, 97, 98, 101, 103], "560": [74, 91], "height": [74, 85, 91, 98, 101, 102, 103], "315": 74, "src": 74, "http": [74, 80, 81, 93, 97, 100], "www": 74, "com": [74, 80, 82, 100], "emb": 74, "s_f2qv2_u00": 74, "amp": 74, "showinfo": 74, "framebord": 74, "allowfullscreen": 74, "2012": 75, "art": 75, "rider": 75, "liabil": 75, "genom": 75, "biologi": 75, "21": [75, 82, 85, 88, 92, 97, 98, 103], "padilla": 76, "shah": 76, "zack": 76, "hullman": 76, "110": [76, 86, 89], "161": [76, 86, 91], "16": [77, 82, 84, 86, 87, 88, 89, 92, 95, 96, 97, 99, 103], "682": 77, "697": 77, "forc": [77, 96, 102], "789": 77, "802": [77, 86], "wilei": 78, "interdisciplinari": 78, "299": 78, "306": [78, 97], "md": [79, 90], "flavor": 79, "stand": [79, 98], "markedli": 79, "slight": 79, "commonmark": 79, "small": [79, 91, 94, 99], "syntax": [79, 83], "extens": [79, 102], "sphinx": 79, "ecosystem": 79, "kind": [79, 95, 99], "written": [79, 81, 87, 90, 91, 93, 97], "markup": 79, "serv": [79, 80, 97, 101, 102], "purpos": [79, 80, 81, 86, 91, 93, 94, 95, 99, 100, 101, 102], "wherea": [79, 97], "span": [79, 94, 102], "At": [79, 83, 99, 100], "simplest": [79, 100, 101], "mydirectivenam": 79, "exist": [79, 86, 90, 91, 95, 100], "pre": [79, 80, 83, 90, 97, 98], "box": [79, 90, 100, 101], "rolenam": 79, "path": [79, 81, 93, 100], "intro": 79, "cite": 79, "bibtex": 79, "holdgraf_evidence_2014": 79, "render": 79, "moreoev": 79, "bibliographi": 79, "must": [79, 81, 83, 87, 88, 93, 94, 95, 101], "properli": 79, "bib": 79, "jupytext": 79, "metadata": 79, "init": [79, 100], "block": [79, 90], "default": [79, 84, 88, 90, 94, 96, 97, 101, 102], "kernel": [79, 90, 101], "nb": 79, "abl": [80, 81, 93, 97, 101], "discov": 80, "stori": [80, 102], "sit": 80, "intersect": 80, "machin": [80, 91], "aim": [80, 102], "holist": 80, "share": [80, 81, 83, 93, 100], "effici": [80, 88, 90, 91, 97], "borrow": 80, "dataconomi": 80, "07": [80, 85, 86, 88, 89, 92], "insight": 80, "internet": 80, "peopl": [80, 81, 90, 91, 93, 97, 98, 100], "clever": 80, "program": [80, 90, 97], "cool": 80, "big": [80, 89, 99], "journei": 80, "messi": [80, 97], "dead": 80, "everyth": [80, 84, 90, 100, 101], "reason": [80, 87, 88, 92, 97, 99, 100], "markdown": 80, "integr": [80, 90], "scipen": 80, "999": [80, 91], "notat": [80, 87], "1e": [80, 85, 94, 103], "48": [80, 85, 92], "theme_set": 80, "theme_bw": [80, 102], "bw": 80, "midwest": 80, "goo": 80, "gl": 80, "g1k41k": 80, "bkup": 80, "gg": 80, "area": 80, "poptot": 80, "popdens": 80, "loess": [80, 102], "xlim": 80, "ylim": [80, 102], "500000": 80, "subtitl": 80, "vs": [80, 87, 103], "caption": 80, "warn": [80, 86, 91, 101, 102, 103], "finit": 80, "hook": 80, "script": [80, 97], "record": [80, 83, 98, 100, 101, 103], "thought": [80, 87, 88, 90], "els": [80, 86, 87], "version": [80, 81, 85, 86, 87, 89, 90, 93, 95, 97, 102, 103], "recommend": [80, 92, 97, 100], "later": [80, 86, 87, 88, 97, 100], "goe": [80, 88, 90, 97, 100], "inlin": 80, "ye": [80, 86, 91], "syllabu": 80, "rhetor": 80, "alwai": [80, 84, 89, 90, 97, 99, 100, 101], "2018": 80, "03": [80, 88, 92, 97, 98], "server": [80, 100], "rooki": 80, "mistak": [80, 97], "enter": 80, "NOT": [80, 87], "violat": [80, 88, 89], "manipul": [80, 82, 85, 91, 96, 97, 99, 101], "aren": [80, 83, 96, 101], "excel": [80, 81, 90, 93, 97], "habit": 80, "raw": [80, 84, 97, 101], "untouch": 80, "reflect": [80, 87, 96, 99], "got": [80, 81, 92, 93, 98, 99], "preprocess": [80, 97], "fun": [80, 85, 86, 90, 91, 97, 101], "stuff": [80, 90], "ggtheme": [80, 102], "email_campaign_funnel": 80, "githubusercont": 80, "selva86": 80, "master": [80, 90, 100, 102], "brk": 80, "15000000": 80, "5000000": [80, 87], "lbl": 80, "paste0": [80, 85], "charact": [80, 90, 97], "stage": [80, 100], "geom_bar": [80, 101, 102], "stat": [80, 81, 93, 103], "ident": [80, 83, 89, 91], "bar": [80, 87, 89, 99, 101, 102], "scale_y_continu": [80, 91], "coord_flip": [80, 102], "flip": 80, "ax": [80, 101, 102], "campaign": 80, "funnel": 80, "theme_tuft": [80, 102], "tuft": 80, "ggfortifi": [80, 103], "element_text": 80, "hjust": 80, "tick": [80, 101], "centr": 80, "scale_fill_brew": 80, "palett": [80, 101], "dark2": 80, "hn": 80, "77llg_f95zlg9ftwmt7m88hr0000gp": 80, "rtmppu5vnf": 80, "downloaded_packag": [80, 97, 102], "brillianc": 80, "routin": 80, "pretti": [80, 86, 91, 92, 98, 100], "pictur": [80, 99], "game": 80, "plan": [80, 100], "whiteboard": 80, "chalkboard": 80, "crayon": 80, "wall": 80, "Or": [80, 86, 90, 91, 100], "whatev": [80, 95, 100], "Being": 80, "fly": 80, "troubl": 80, "never": [80, 90, 100], "sometim": [80, 83, 90, 98, 99, 100], "modifyng": 80, "sparingli": 80, "spend": [80, 88], "stress": [80, 88], "long": [80, 84, 85, 88, 90, 91, 92, 94, 99, 100, 101, 102], "heart": 80, "tricki": 80, "__simplicity__": 80, "__accuracy__": 80, "__maxim": 80, "convey__": 80, "convei": [80, 101], "prep": 80, "freqtabl": 80, "mpg": [80, 84, 86, 88, 95, 103], "manufactur": [80, 88, 103], "df": [80, 82, 83, 85, 86, 88, 89, 96, 97, 99, 103], "var1": [80, 97], "freq": 80, "audi": 80, "chevrolet": 80, "dodg": 80, "37": [80, 89, 92, 97, 103], "ford": 80, "honda": 80, "hyundai": 80, "theme_class": [80, 91, 97, 102], "tomato2": 80, "chart": [80, 101, 102], "vehicl": [80, 88], "angl": [80, 86], "65": [80, 86, 88, 92, 97, 98], "vjust": 80, "var1freq": 80, "chevrolet19": 80, "lose": [80, 92], "errorbar": 80, "hide": 80, "captur": [80, 83, 88, 92, 103], "nuanc": 80, "violin": [80, 101], "cty": 80, "geom_violin": [80, 101], "citi": [80, 86, 88, 102, 103], "mileag": [80, 88], "talk": [80, 83, 86, 87, 97, 98, 99, 100], "wrong": [80, 98], "impress": [80, 98], "tale": 80, "free": [81, 87, 93], "latest": [81, 93], "current": [81, 83, 93, 97, 100], "lib": [81, 82, 83, 91, 93, 94, 95, 103], "edu": [81, 93, 100], "cran": [81, 93], "mac": [81, 90, 93, 97, 100], "etc": [81, 85, 91, 93, 97, 100, 101], "faq": [81, 93], "great": [81, 93], "littl": [81, 86, 87, 89, 93, 98, 99, 103], "nicer": [81, 93, 99], "instruct": [81, 93, 100, 101], "hist": [81, 93, 95], "varieti": [81, 93], "audienc": [81, 93, 102], "weav": [81, 93], "narr": [81, 93], "aspect": [81, 85, 93, 96, 101, 103], "ground": [81, 93], "modular": [81, 93], "conveni": [81, 93], "snippet": [81, 93], "teach": [81, 93, 102], "platform": [81, 93, 100], "licens": [81, 93], "clean": [81, 90, 93, 96, 97], "novel": [81, 93], "revamp": [81, 93], "academ": [81, 93, 100], "anaconda": [81, 93], "choos": [81, 84, 91, 93, 97, 100], "prerequisit": [81, 93], "environ": [81, 85, 90, 93, 97, 103], "launch": [81, 93], "termin": [81, 93, 100], "consol": [81, 93, 100], "stick": [81, 82, 88, 93], "browser": [81, 93], "os": [81, 93], "invok": [81, 90, 93, 100], "within": [81, 82, 85, 87, 90, 91, 93, 97, 98, 102], "irkernel": [81, 93], "installspec": [81, 93], "regist": [81, 93], "prompt": [81, 93, 100], "cloud": [81, 93], "mirror": [81, 93, 98], "session": [81, 93, 100], "simpli": [81, 87, 90, 93, 99, 100, 102, 103], "linux": [81, 93, 100], "desktop": [81, 93], "author": [81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "ven": [81, 83, 84, 85, 86, 89, 91, 93, 94, 95, 96, 97, 100, 101, 103], "popov": [81, 83, 84, 85, 86, 89, 91, 93, 94, 95, 96, 97, 100, 101, 103], "krista": [81, 82, 83, 84, 85, 86, 87, 89, 91, 93, 94, 95, 96, 97, 100, 101, 103], "bond": [81, 82, 83, 84, 85, 86, 87, 89, 91, 93, 94, 95, 96, 97, 100, 101, 103], "charl": [81, 82, 83, 84, 85, 86, 87, 89, 91, 93, 94, 95, 96, 97, 100, 101, 103], "wu": [81, 82, 83, 84, 85, 86, 87, 89, 91, 93, 94, 95, 96, 97, 100, 101, 103], "patienc": [81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103], "steven": [81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103], "ami": [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "senti": [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "approxim": [82, 86], "belief": 82, "uncertainti": [82, 95, 103], "am": 82, "absolut": 82, "anyth": [82, 83, 87, 98, 100], "richard": 82, "feynman": 82, "bayesfactor": 82, "quantifi": [82, 83, 95, 96], "fulli": 82, "support": [82, 102], "reject": [82, 91, 95, 103], "altogeth": 82, "morei": 82, "analyt": [82, 91], "strength": [82, 101], "weight": [82, 84, 86, 88, 95, 102, 103], "express": [82, 87, 89, 97, 99], "bf": [82, 87, 98], "h_1": 82, "h_0": [82, 95], "penal": 82, "treatment": 82, "usr": [82, 83, 91, 94, 95, 103], "site": [82, 83, 86, 91, 94, 95, 100, 103], "unspecifi": [82, 83, 91, 94, 95, 103], "ellipt": 82, "contfrac": 82, "desolv": 82, "coda": 82, "pbappli": 82, "mvtnorm": 82, "gtool": 82, "matrixmodel": 82, "hypergeo": 82, "rcppeigen": [82, 91], "regresss": 82, "lsf": 82, "contact": 82, "richarddmorei": 82, "gmail": 82, "bfmanual": 82, "sleep": [82, 89], "depriv": [82, 89], "extragroupid": 82, "lt": [82, 85, 89, 90, 91, 92, 97, 98, 102, 103], "dbl": [82, 83, 85, 86, 87, 89, 90, 91, 92, 95, 97, 98, 102, 103], "gt": [82, 85, 89, 90, 91, 92, 95, 97, 98, 102, 103], "fct": [82, 89, 92, 97, 98, 102], "711": 82, "612": [82, 89], "213": [82, 86], "214": 82, "115": 82, "416": 82, "717": [82, 86], "818": 82, "019": 82, "0110": 82, "921": 82, "822": 82, "123": 82, "124": 82, "426": 82, "527": 82, "628": [82, 89], "629": 82, "4210": 82, "acertain": 82, "drug": 82, "extra": [82, 84], "hour": [82, 89, 91], "spread": [82, 85, 97], "group1": [82, 91], "group2": [82, 91], "reset": [82, 84, 91, 102, 103], "avoid": [82, 87, 90, 100], "integ": 82, "sleep_wd": 82, "wide": [82, 85, 92], "diffscor": 82, "idgroup1group2diffscor": 82, "33": [82, 85, 86, 97], "44": [82, 86, 88, 92, 97, 98], "66": [82, 86, 92], "0621": 82, "002833": 82, "percent": [82, 83], "4598858": 82, "7001142": 82, "58": [82, 86, 88, 92], "06": [82, 85, 86, 88, 97], "005": [82, 91], "smaller": [82, 84, 90, 91, 94, 97, 101, 102], "ttestbf": 82, "nonzero": 82, "alt": [82, 90], "707": 82, "25888": 82, "bfonesampl": 82, "jz": 82, "gotten": [82, 91], "05794119": 82, "707106781186548": 82, "nullinterv": 82, "rang": [82, 84, 85, 86, 91, 94, 95, 97, 101, 102], "inf": 82, "bfinterv": 82, "34": [82, 85, 92, 97, 98], "41694": 82, "1008246": 82, "evalau": 82, "tha": 82, "strongli": [82, 91], "42": [82, 86, 92], "achiev": [82, 91], "bfneg": 82, "3547": 82, "And": [82, 86, 87, 88, 91, 96, 97, 101], "invers": [82, 91], "bfposit": 82, "miniscul": 82, "002929504": 82, "allbf": 82, "ahhhh": 82, "love": 82, "hierarch": 82, "toothgrowth": 82, "len": 82, "tooth": 82, "independ": [82, 86, 88, 89, 91, 92, 100], "supp": 82, "took": [82, 84, 99], "vitamin": [82, 88], "orang": [82, 91], "juic": 82, "dose": 82, "log10": 82, "classic": [82, 86, 100], "lmtoothgrowth": 82, "lensuppdos": 82, "2vc0": 82, "211": 82, "5vc0": 82, "3vc0": 82, "8vc0": 82, "4vc0": 82, "610": [82, 89], "0vc0": 82, "min": [82, 83, 86, 88, 89, 94, 96, 99, 102, 103], "1q": [82, 83, 86, 88, 89, 103], "3q": [82, 83, 86, 88, 89, 103], "max": [82, 83, 86, 88, 89, 96, 102, 103], "5433": 82, "4921": 82, "5033": 82, "7117": 82, "8567": 82, "pr": [82, 83, 86, 88, 89, 103], "6633": 82, "6791": 82, "425": 82, "2e": [82, 86, 88, 89, 99, 103], "suppvc": 82, "7000": 82, "9605": 82, "852": 82, "000303": 82, "3102": 82, "7631": 82, "712": 82, "3e": 82, "8529": 82, "9076": 82, "266": [82, 86], "027366": 82, "signif": [82, 86, 88, 89, 103], "001": [82, 86, 88, 89, 91, 103], "72": [82, 87, 92, 97], "56": [82, 83, 85, 86, 92, 97], "7755": 82, "7635": 82, "growth": 82, "lmbf": 82, "nointeract": 82, "onlydos": 82, "onlysupp": 82, "651389e": 82, "54362e": 82, "769593e": 82, "198757": 82, "bflinearmodel": 82, "02911": 82, "literatur": [82, 91], "suggest": [82, 84, 97, 103], "role": [82, 89], "lean": 82, "configur": [83, 96], "variou": [83, 91, 96, 97, 100, 101, 103], "discrimin": [83, 101], "exponenti": [83, 99], "far": [83, 84, 86, 103], "fall": [83, 92, 95, 98], "umbrella": 83, "exercis": [83, 84], "daili": [83, 102], "1250": 83, "500": [83, 86], "index": [83, 86, 95], "2001": 83, "lag1": 83, "percentag": [83, 91, 92], "dai": [83, 89, 102], "lag2": 83, "lag3": 83, "lag4": 83, "lag5": 83, "billion": 83, "todai": [83, 99], "had": [83, 86, 87, 89, 91, 97, 98], "guess": [83, 91, 98], "smarket": 83, "922000": 83, "1st": [83, 87], "qu": 83, "2002": 83, "639500": 83, "640000": 83, "039000": 83, "038500": 83, "003834": 83, "003919": 83, "001716": 83, "3rd": [83, 84], "2004": 83, "596750": 83, "733000": 83, "92200": 83, "3561": 83, "64000": 83, "2574": 83, "03850": 83, "4229": 83, "001636": 83, "00561": 83, "4783": 83, "003138": 83, "59700": 83, "6417": 83, "73300": 83, "1525": 83, "602": 83, "648": 83, "glimps": 83, "among": [83, 86, 89, 96, 97, 98, 102], "cxy": 83, "traceback": [83, 90], "stop": 83, "upupdownupupup": 83, "colnam": [83, 103], "yearlag1lag2lag3lag4lag5volumetodai": 83, "year1": 83, "00000000": 83, "029699649": 83, "030596422": 83, "033194581": 83, "035688718": 83, "029787995": 83, "53900647": 83, "030095229": 83, "lag10": 83, "02969965": 83, "000000000": 83, "026294328": 83, "010803402": 83, "002985911": 83, "005674606": 83, "04090991": 83, "026155045": 83, "lag20": 83, "03059642": 83, "025896670": 83, "010853533": 83, "003557949": 83, "04338321": 83, "010250033": 83, "lag30": 83, "03319458": 83, "024051036": 83, "018808338": 83, "04182369": 83, "002447647": 83, "lag40": 83, "03568872": 83, "027083641": 83, "04841425": 83, "006899527": 83, "lag50": 83, "02978799": 83, "02200231": 83, "034860083": 83, "volume0": 83, "040909908": 83, "043383215": 83, "041823686": 83, "048414246": 83, "022002315": 83, "014591823": 83, "today0": 83, "03009523": 83, "01459182": 83, "appear": [83, 88], "539": 83, "weakli": 83, "beta_4": 83, "beta_5": 83, "tri": [83, 91, 97], "binomi": 83, "summar": [83, 89, 98, 101, 102], "devianc": 83, "446": [83, 102], "203": 83, "065": 83, "145": [83, 85], "326": 83, "z": [83, 86, 101, 103], "126000": 83, "240736": 83, "523": 83, "601": 83, "073074": 83, "050167": 83, "457": 83, "042301": 83, "050086": 83, "845": 83, "398": 83, "011085": 83, "049939": 83, "222": [83, 86], "824": 83, "009359": 83, "049974": 83, "187": [83, 95], "851": [83, 91], "010313": 83, "049511": 83, "208": 83, "835": 83, "135441": 83, "158360": 83, "855": 83, "392": [83, 84, 95], "dispers": 83, "taken": [83, 97], "1731": 83, "1249": [83, 89], "1727": 83, "1243": 83, "1741": 83, "fisher": 83, "signific": [83, 84, 86, 88, 89, 91, 97, 101, 103], "themselv": [83, 103], "par": [83, 91], "mfrow": 83, "glm_prob_df": 83, "predicted_prob": 83, "num_observ": 83, "prob": 83, "xlab": [83, 84, 86, 94, 95, 102, 103], "ylab": [83, 84, 86, 94, 102, 103], "notic": [83, 84, 86, 88, 89, 91, 94, 95, 96, 97, 99, 101, 103], "sigmoid": [83, 85], "rather": [83, 85, 89, 91, 97, 100, 101], "down0": 83, "up1": 83, "binar": [83, 86], "predicted_binari": 83, "cast": 83, "confusion_df": [83, 98], "141": [83, 91], "507": 83, "diagon": [83, 86, 87, 102], "averag": [83, 84, 86, 89, 91, 97, 99, 101, 102], "match": [83, 90, 94, 97, 99], "matric": [83, 89, 94], "caret": 83, "fourfoldplot": 83, "count": [83, 92, 101], "5216": 83, "52": [83, 92, 97], "glanc": 83, "chanc": [83, 91, 95, 98], "futur": [83, 90, 97, 102], "isol": 83, "entri": [83, 84, 94, 97], "train_idx": 83, "2005_test": 83, "occupi": 83, "dim": [83, 94, 96], "2529": 83, "peform": 83, "pred": [83, 92, 94, 98], "252": 83, "35": [83, 89, 97], "76": [83, 92], "106": [83, 86, 97], "55952380952381": 83, "replic": [83, 97, 100], "491984": 83, "508016": 83, "04279022": 83, "03389409": 83, "03954635": 83, "03132544": 83, "ld1": 83, "6420190": 83, "5135293": 83, "49": [83, 85, 88, 92], "boundari": 83, "w_1": 83, "w_2": 83, "decreas": [83, 84, 86, 91, 92, 94, 99], "posterior": 83, "probabiltii": 83, "otherword": 83, "analog": [83, 97], "downup": 83, "9990": 83, "49017920": 83, "5098208": 83, "10000": [83, 87, 91], "47921850": 83, "5207815": 83, "10010": 83, "46681850": 83, "5331815": 83, "10020": 83, "47400110": 83, "5259989": 83, "10030": 83, "49278770": 83, "5072123": 83, "10040": 83, "49385620": 83, "5061438": 83, "distinguish": [83, 89, 97], "somewhat": [83, 90], "lag": [83, 85, 91, 97], "lag1_posterior_df": 83, "lag1_return": 83, "down_posterior_prob": 83, "ago": 83, "special": [83, 86, 87, 90], "facet_grid": [83, 88, 91, 99, 102], "covari": [83, 99], "0278734923872115": 83, "0392480610374496": 83, "fair": 83, "overlap": [83, 90, 91, 94, 95, 98], "mu_": 83, "main": [83, 87, 89, 91, 97, 99, 100, 101, 102], "sigma_k": 83, "81": [83, 92, 95, 97, 99], "599206349206349": 83, "60": [83, 91, 92, 98, 99], "benefit": [84, 101], "refin": 84, "demo": [84, 91], "chosen": 84, "remaind": 84, "highli": [84, 92], "overestim": 84, "partit": 84, "auto": [84, 95], "acknowledg": 84, "196": 84, "horsepow": [84, 86, 88, 95, 103], "cubic": 84, "fit2": [84, 89], "fit3": 84, "2660086465003": 84, "1601734630785": 84, "5946481598143": 84, "quadrat": 84, "exact": 84, "subsampl": 84, "7265106448139": 84, "3090205440697": 84, "616933858347": 84, "demonstr": [84, 87, 91, 98, 99], "figur": [84, 85, 90, 100, 101], "substanti": [84, 89], "repeatedli": [84, 91], "9358610211705horsepow": [84, 95], "157844733353654": [84, 95], "cv_": 84, "mse_i": 84, "err": 84, "24": [84, 85, 86, 89, 92, 95, 97, 98], "231513517929224": 84, "2311440937562": 84, "equival": [84, 100], "foreshadow": 84, "lesson": 84, "compens": 84, "textbook": [84, 96], "superior": 84, "sy": 84, "loo": 84, "crossval": 84, "lootim": 84, "253145": 84, "sec": 84, "modest": 84, "worth": 84, "upgrad": 84, "polynom": 84, "bend": 84, "curv": [84, 102], "trust": [84, 86, 87], "fals": [84, 88, 89, 90, 91, 96, 97, 98, 102, 103], "loovc": 84, "kfoldtim": 84, "runtim": 84, "25314497947693": 84, "246827840805054": 84, "quicker": 84, "fiona": [84, 85, 86, 87, 89, 90, 97, 98, 99, 100], "horner": [84, 85, 86, 87, 89, 90, 97, 98, 99, 100], "gather": [85, 91, 97, 99], "timepoint": 85, "long_data": 85, "subjecttimepointobserv": 85, "int": [85, 87, 91, 97, 102], "38": [85, 89, 92, 94, 98], "83": [85, 97], "43": [85, 88, 92, 97, 98], "31": [85, 86, 88, 92, 97], "94": [85, 87, 89, 92, 98], "32": [85, 86, 90, 97, 103], "57": [85, 92, 94], "subjecttime1time2time3time4": 85, "whenev": [85, 100], "handi": [85, 87, 90, 92, 97, 100], "referenc": 85, "x1": [85, 86], "x2": [85, 86], "grid": [85, 91, 102], "exp": [85, 92], "1mattach": [85, 91, 97], "22m": [85, 89, 91, 97], "32m": [85, 91, 97], "39m": [85, 91, 97], "34mggplot2": [85, 91, 97], "34mpurrr": [85, 91, 97], "34mtibbl": [85, 91, 97], "34mdplyr": [85, 91, 97], "34mtidyr": [85, 91, 97], "34mstringr": [85, 91, 97], "34mreadr": [85, 91, 97], "34mforcat": [85, 91, 97], "1mconflict": [85, 91, 97], "tidyverse_conflict": [85, 91, 97], "31m": [85, 91, 97], "32mfilter": [85, 91, 97], "mask": [85, 91, 97], "34mstat": [85, 91, 97], "32mlag": [85, 91, 97], "x1x2y": 85, "3820138": 85, "3706878": 85, "3525741": 85, "3241418": 85, "2807971": 85, "2175745": 85, "repr": [85, 91, 98, 101, 103], "stat_summari": [85, 97, 101], "geom": [85, 97], "y_ob": 85, "model_fit": [85, 97, 101], "num": [85, 92, 97], "103": 85, "attr": 85, "chr": [85, 90, 91, 97], "289": 85, "161087": 85, "000838": 85, "047814": 85, "060155": 85, "099688": 85, "3291": 85, "0409": 85, "283": 85, "0562": 85, "1037": 85, "rank": [85, 86, 102], "502": 85, "429": 85, "357": 85, "284": 85, "212": [85, 90], "qr": 85, "0588": 85, "dimnam": 85, "qraux": 85, "08": [85, 92, 103], "09": [85, 88, 92], "pivot": 85, "tol": 85, "286": 85, "xlevel": 85, "r_globalenv": 85, "predvar": 85, "dataclass": 85, "ob": [85, 89, 98], "404": 85, "224": 85, "311": 85, "503054186787634x10": 85, "145736690427283x20": 85, "101914512975517": 85, "namevalu": 85, "5030542": 85, "x1x1": 85, "1457367": 85, "x2x2": 85, "1019145": 85, "x1x2yy_obsfit": 85, "39720021": 85, "4875506": 85, "40502036": 85, "4146823": 85, "37797924": 85, "3418139": 85, "41380740": 85, "2689456": 85, "20525168": 85, "1960772": 85, "09077483": 85, "1232089": 85, "new_data": 85, "newdata": [85, 86], "744664879536758": 85, "front": 86, "libari": 86, "matrixstat": 86, "denois": 86, "gplot": 86, "rcolorbrew": 86, "plot3d": 86, "car": [86, 88, 103], "everytim": [86, 97], "medv": 86, "lstat": [86, 103], "cars93": [86, 88, 103], "scatter3d": 86, "phi": 86, "tilt": 86, "zlab": 86, "footbal": 86, "confirm": 86, "546": [86, 89], "194": 86, "89": [86, 87, 88, 92, 103], "189": 86, "579": 86, "5999": 86, "519": 86, "540": 86, "622": 86, "097": 86, "102": 86, "156": 86, "281": 86, "692": 86, "75e": 86, "836": 86, "437": 86, "153": 86, "0022": 86, "274": 86, "7889": 86, "7842": 86, "168": 86, "symbol": [86, 87, 90], "num_col": 86, "unlist": 86, "lappli": [86, 97], "220": 86, "402": 86, "70": [86, 92, 97, 98, 102], "076": 86, "002": [86, 103], "69": [86, 92], "825": [86, 89], "764": 86, "140": [86, 97], "05133": 86, "658": 86, "01561": 86, "83213": 86, "165": [86, 98, 103], "31369": 86, "93918": 86, "619": 86, "53792": 86, "324": 86, "39700": 86, "532": 86, "71044": 86, "609": 86, "54471": 86, "71716": 86, "15830": 86, "608": 86, "54560": 86, "59419": 86, "31530": 86, "923": 86, "35969": 86, "highwai": [86, 88, 103], "22139": 86, "05965": 86, "232": 86, "02912": 86, "engines": [86, 88, 103], "54": [86, 92, 101, 103], "32469": 86, "99456": 86, "905": 86, "36860": 86, "32739": 86, "90113": 86, "82e": 86, "rpm": [86, 88, 103], "11785": 86, "05006": 86, "354": [86, 92], "02165": 86, "rev": [86, 88, 103], "mile": [86, 88, 95, 103], "11059": 86, "05473": 86, "021": 86, "04751": 86, "fuel": [86, 88, 103], "tank": [86, 88, 103], "58016": 86, "17775": 86, "00629": 86, "passeng": [86, 88, 103], "18737": 86, "37579": 86, "365": 86, "71620": 86, "60418": 86, "67397": 86, "096": 86, "04006": 86, "wheelbas": [86, 88, 103], "97271": 86, "32881": 86, "524": 86, "01410": 86, "81074": 86, "88571": 86, "166": 86, "86841": 86, "circl": [86, 88, 98, 103], "29436": 86, "03511": 86, "032": 86, "30583": 86, "rear": [86, 88, 103], "seat": [86, 88, 103], "room": [86, 88, 103], "53080": 86, "04313": 86, "059": 86, "95338": 86, "luggag": [86, 88, 103], "06806": 86, "94515": 86, "44783": 86, "114": 86, "missing": 86, "9674": 86, "9588": 86, "111": 86, "queri": [86, 96], "exclud": [86, 96, 97], "tild": 86, "fit_new": 86, "237": 86, "809": 86, "68": [86, 88, 92, 103], "733": [86, 88], "621": 86, "685": 86, "227": [86, 103], "473": 86, "147": [86, 91], "72555": 86, "651": 86, "85150": 86, "82142": 86, "96356": 86, "249": 86, "11030": 86, "305": 86, "76137": 86, "95766": 86, "497": 86, "76892": 86, "297": [86, 103], "76722": 86, "74": [86, 91], "20151": 86, "248": [86, 96], "91613": 86, "298": 86, "76656": 86, "03821": 86, "10838": 86, "773": 86, "44245": 86, "32891": 86, "75157": 86, "209": 86, "03068": 86, "86820": 86, "69431": 86, "571": [86, 103], "02e": 86, "08711": 86, "03597": 86, "422": 86, "01819": 86, "09151": 86, "05010": 86, "826": 86, "07232": 86, "29317": 86, "63264": 86, "755": 86, "00758": 86, "43428": 86, "61187": 86, "081": 86, "04135": 86, "52055": 86, "25976": 86, "479": 86, "01572": 86, "16370": 86, "61106": 86, "015": 86, "98774": 86, "52630": 86, "96200": 86, "071": 86, "28813": 86, "78306": 86, "61133": 86, "62082": 86, "43697": 86, "79114": 86, "698": 86, "48773": 86, "9669": 86, "9594": 86, "128": [86, 87], "swap": [86, 102], "mostli": [86, 88, 100], "carseat": 86, "workspac": 86, "ls": [86, 100], "sale": 86, "comppric": 86, "incom": 86, "advertis": 86, "shelveloc": 86, "educ": [86, 91], "urban": 86, "400": 86, "thousand": [86, 91, 98], "charg": 86, "competitor": 86, "dollar": [86, 98], "budget": 86, "compani": 86, "region": 86, "medium": 86, "shelv": 86, "No": [86, 98, 99, 101], "rural": 86, "pai": 86, "attent": 86, "9208": 86, "7503": 86, "0177": 86, "6754": 86, "3413": 86, "5755654": 86, "0087470": 86, "22e": 86, "0929371": 86, "0041183": 86, "567": 86, "0108940": 86, "0026044": 86, "183": 86, "57e": 86, "0702462": 86, "0226091": 86, "107": 86, "002030": 86, "0001592": 86, "0003679": 86, "433": 86, "665330": 86, "1008064": 86, "0074399": 86, "549": 86, "shelvelocgood": 86, "8486762": 86, "1528378": 86, "724": 86, "shelvelocmedium": 86, "9532620": 86, "1257682": 86, "0579466": 86, "0159506": 86, "633": 86, "000318": 86, "0208525": 86, "0196131": 86, "063": 86, "288361": 86, "urbany": 86, "1401597": 86, "1124019": 86, "247": 86, "213171": 86, "usy": 86, "1575571": 86, "1489234": 86, "058": [86, 88], "290729": 86, "0007510": 86, "0002784": 86, "007290": 86, "0001068": 86, "0001333": 86, "801": 86, "423812": 86, "011": 86, "386": 86, "8761": 86, "8719": 86, "210": 86, "automat": [86, 90, 94, 97, 100, 101, 102], "recod": 86, "goodmedium": 86, "bad00": 86, "good10": 86, "medium01": 86, "therefor": [86, 90, 91, 102], "bump": 86, "held": 86, "complic": [86, 87, 100], "longer": [86, 88, 90, 96, 97, 100], "watch": [86, 87], "carefulli": 86, "redefin": 86, "componenet": [86, 102], "essenti": [86, 102], "linearli": 86, "lrsim": 86, "signal": 86, "singular": [86, 87], "decomposit": 86, "svd": 86, "moment": [86, 97, 100], "intercorrel": 86, "make_data": 86, "otheriws": 86, "degree_diff": 86, "u": [86, 88], "space": [86, 90, 94, 102], "strongest": 86, "okai": [86, 100], "78569": 86, "62726": 86, "07531": 86, "59695": 86, "57939": 86, "03523": 86, "04533": 86, "777": 86, "4375": 86, "41500": 86, "61": [86, 92, 97, 98], "86812": 86, "395": 86, "6933": 86, "17653": 86, "10736": 86, "321": 86, "7480": 86, "x3": 86, "62072": 86, "67": [86, 97], "64961": 86, "260": 86, "7946": 86, "x4": 86, "45193": 86, "71": [86, 88, 89, 92, 97], "72453": 86, "1242": 86, "x5": 86, "11625": 86, "66273": 86, "588": 86, "5571": 86, "x6": 86, "133": 86, "22155": 86, "01748": 86, "018": 86, "0442": 86, "x7": 86, "86": [86, 88, 91, 92, 98, 102], "10253": 86, "68913": 86, "1227": 86, "x8": 86, "116": [86, 87], "70388": 86, "10784": 86, "739": 86, "0827": 86, "x9": 86, "108": 86, "78295": 86, "26610": 86, "1170": 86, "x10": 86, "71434": 86, "53488": 86, "4734": 86, "x11": 86, "51462": 86, "62": [86, 92, 97], "53258": 86, "064": 86, "2880": 86, "x12": 86, "94582": 86, "68294": 86, "793": 86, "4284": 86, "x13": 86, "71852": 86, "98526": 86, "171": 86, "8647": 86, "x14": 86, "02868": 86, "56074": 86, "055": 86, "9566": 86, "x15": 86, "80215": 86, "89896": 86, "906": 86, "3654": 86, "x16": 86, "39623": 86, "93919": 86, "638": 86, "1020": 86, "x17": 86, "76793": 86, "71295": 86, "686": 86, "4930": 86, "x18": 86, "36": [86, 88, 89, 92, 97], "66511": 86, "41676": 86, "552": 86, "5812": 86, "x19": 86, "25835": 86, "65191": 86, "244": 86, "8071": 86, "x20": 86, "65573": 86, "36835": 86, "2693": 86, "003": 86, "1889": 86, "155": 86, "577": 86, "266e": 86, "linkag": 86, "brewer": 86, "pal": 86, "rdbu": 86, "trace": 86, "none": 86, "rich": 86, "focu": [86, 88, 90, 92, 99, 102], "half": [86, 87, 88], "bv_lm": 86, "p_max": 86, "set_id": 86, "yhat_train": 86, "yhat_test": 86, "rss": [86, 96], "bv_df": 86, "geom_lin": [86, 91, 99, 101, 102], "darkr": 86, "noisi": [86, 91, 98], "skyrocket": 86, "squint": [86, 96], "clearer": [86, 91, 101], "n_iter": 86, "2000": 86, "aggreg": 86, "run_df": 86, "rowmean": 86, "strain": 86, "rowsd": 86, "stest": 86, "steelblu": 86, "linetyp": [86, 99, 101], "twodash": 86, "dash": [86, 90, 99, 101], "tim": 86, "verstynen": 86, "walk": [87, 90, 94, 96, 100, 101], "feel": [87, 88, 101], "skim": 87, "everyon": [87, 98], "wikipedia": 87, "seri": [87, 89, 97], "arrang": [87, 91, 102], "data_point": 87, "vector_1": 87, "vector_2": 87, "bmatrix": 87, "e_i": 87, "y_i": [87, 99], "bold": 87, "e_1": 87, "e_2": 87, "e_3": 87, "y_1": 87, "y_2": 87, "y_3": 87, "_1": 87, "_2": 87, "_3": 87, "summat": [87, 99], "x_i": [87, 99], "x_n": 87, "x_2": [87, 99], "x_3": 87, "nest": [87, 90, 91], "occasion": 87, "colsum": 87, "multipli": [87, 99], "prod_": [87, 99], "cover": [87, 97], "foil": [87, 99], "6x_i": 87, "care": [87, 89], "commut": 87, "6x_1": 87, "6x_2": 87, "6x_3": 87, "lastli": 87, "bring": [87, 101], "outsid": [87, 95, 99, 101, 102], "ok": [87, 97], "rectangular": 87, "a_": 87, "th": 87, "sample_matrix_by_col": 87, "byrow": 87, "sample_matrix_by_row": 87, "1357": 87, "246810": 87, "1234": 87, "678910": 87, "specifii": 87, "extent": 87, "square_matrix_4": 87, "square_matrix_10": 87, "913": 87, "261014": 87, "371115": 87, "481216": 87, "11121314151617181": 87, "91": [87, 88, 92, 97, 98, 102, 103], "21222324252627282": 87, "92": [87, 92, 97], "31323334353637383": 87, "93": [87, 88, 92, 97, 98], "41424344454647484": 87, "51525354555657585": 87, "61626364656667686": 87, "96": [87, 92, 102, 103], "71727374757677787": 87, "97": [87, 92, 103], "81828384858687888": 87, "98": [87, 92], "91929394959697989": 87, "99": [87, 89, 91, 92, 102], "102030405060708090100": 87, "touch": 87, "transpos": 87, "symmetric_matrix": 87, "triangular": 87, "lower_tri": 87, "61014": 87, "9101115": 87, "13141516": 87, "lgl": [87, 96, 98], "truetruetruetru": 87, "everywher": 87, "mat": 87, "diag": 87, "01000": 87, "00100": 87, "00010": 87, "00001": 87, "row_index": 87, "column_index": 87, "6th": 87, "5th": 87, "135": [87, 88, 91, 94], "246": [87, 88], "mat_1": 87, "mat_2": 87, "wise": [87, 90], "importantli": [87, 100], "becom": [87, 90, 91, 94, 97, 99, 100, 101], "denot": [87, 96, 97], "switch": [87, 97, 100], "transposed_mat_2": 87, "tranpos": 87, "mention": [87, 101], "2x2": 87, "bg": 87, "af": 87, "bh": 87, "ce": [87, 99], "dg": [87, 99], "cf": [87, 99], "dh": 87, "1428571": 87, "3333333": 87, "4545455": 87, "2500000": 87, "4000000": 87, "reciproc": 87, "usual": [87, 89, 90], "bc": 87, "776357e": 87, "000000e": 87, "det": 87, "bigger": [87, 88, 101], "invert": 87, "unassoci": 87, "obtain": [87, 91], "grad": [88, 90], "univers": 88, "illinoi": 88, "chicago": [88, 102], "reiter": 88, "m_e": 88, "put": [88, 89, 90, 91, 92, 97, 99], "rightarrow": 88, "coupl": [88, 99], "spanish": 88, "who": [88, 89, 90], "spain": [88, 102], "abil": 88, "speak": 88, "comprehend": 88, "listen": 88, "attend": 88, "mood": 88, "attende": 88, "m_o": 88, "perhap": 88, "stronger": [88, 91, 95], "regard": 88, "deem": 88, "anxieti": 88, "efficaci": 88, "unimport": 88, "exam": 88, "defici": 88, "boston": 88, "peak": 88, "punta": 88, "arena": 88, "chile": 88, "septemb": 88, "sunni": 88, "florida": 88, "weak": 88, "nonexist": 88, "airbag": [88, 103], "drivetrain": [88, 103], "cylind": [88, 103], "man": [88, 103], "tran": [88, 103], "avail": [88, 90, 100, 101, 102, 103], "carri": [88, 89], "gallon": [88, 95], "fitstart": 88, "4720": 88, "2919": 88, "5052": 88, "7081": 88, "3147": 88, "41": [88, 92, 97, 98], "2587": 88, "4697": 88, "3934": 88, "4759": 88, "46e": 88, "742": 88, "2175": 88, "2089": 88, "456e": 88, "heavier": 88, "air": [88, 102], "resist": 88, "ga": 88, "maintain": [88, 90, 95, 97], "speed": [88, 89, 91], "lighter": 88, "compact": 88, "awai": [88, 98], "iv": 88, "fiti": 88, "dv": 88, "1036": 88, "381": 88, "308": 88, "1276": 88, "1475": 88, "257": 88, "27e": 88, "314": 88, "336": [88, 92], "85e": 88, "494": 88, "3061": 88, "2985": 88, "7134": 88, "8418": 88, "0271": 88, "8858": 88, "5668": 88, "8777927": 88, "9165318": 88, "069": 88, "0071983": 88, "0006692": 88, "756": 88, "1321634": 88, "3799662": 88, "348": [88, 92], "729": 88, "154": [88, 91], "6576": 88, "quasi": 88, "ci": 88, "857": 88, "382": 88, "371": [88, 89], "prop": [88, 97], "942": [88, 91], "688": 88, "establish": [88, 94, 100], "opposit": [88, 99], "ouput": 88, "amd": 88, "engin": [88, 90], "fitmod": 88, "6537": 88, "9269": 88, "2388": 88, "9899": 88, "6858": 88, "551e": 88, "537e": 88, "440": 88, "347e": 88, "955e": 88, "02": [88, 89, 97], "406": [88, 97], "000991": 88, "132e": 88, "493e": 88, "585": 88, "06e": 88, "822e": 88, "377": 88, "001088": 88, "984": 88, "6969": 88, "6867": 88, "medh": 88, "vi": 88, "highhorsepow": 88, "ifels": 88, "oop": 88, "delv": 89, "lmer": [89, 91], "maechler": 89, "bolker": 89, "walker": 89, "eigen": 89, "classroom": 89, "sleepstudi": 89, "reactiondayssubject": 89, "56000308": 89, "2258": 89, "70471308": 89, "3250": 89, "80062308": 89, "4321": 89, "43983308": 89, "5356": 89, "85194308": 89, "6414": 89, "69015308": 89, "night": 89, "restrict": [89, 95], "180": [89, 103], "ms": [89, 91], "consecut": 89, "iid": 89, "1m": [89, 97], "baselin": [89, 91], "tangent": 89, "knew": 89, "gui": [89, 100], "335": 89, "he": 89, "thrive": 89, "fe": 89, "848": 89, "483": 89, "26": [89, 92, 97], "142": 89, "139": 89, "953": 89, "251": 89, "405": 89, "033": 89, "467": 89, "238": 89, "454": 89, "89e": 89, "47": [89, 92], "178": [89, 91], "2865": 89, "2825": 89, "46": [89, 92, 97], "894e": 89, "ignor": [89, 99], "usag": [89, 90, 97], "analyst": 89, "me": 89, "fit1": 89, "reml": [89, 91], "lmermod": 89, "converg": [89, 91, 94, 95], "1743": 89, "9536": 89, "4634": 89, "0231": 89, "1793": 89, "corr": 89, "741": 89, "922": 89, "654": 89, "592": 89, "838": 89, "771": 89, "intr": 89, "138": 89, "1786": 89, "2257": 89, "5529": 89, "0109": 89, "5188": 89, "2506": 89, "1378": 89, "960": 89, "4051": 89, "7467": 89, "79": [89, 92], "4673": 89, "8042": 89, "77": [89, 92], "conserv": [89, 91], "domain": 89, "bound": [89, 103], "lmertest": 89, "quanitifi": 89, "lost": [89, 101], "unexplain": 89, "akaik": 89, "ic": 89, "diff": [89, 91], "dfaic": 89, "fit31906": 89, "293": 89, "fit161755": 89, "fit241794": 89, "465": 89, "66478439641238": 89, "8368134349694": 89, "lowest": [89, 92, 94, 96], "carpentri": [90, 100], "style": [90, 97], "handbook": 90, "41018": 90, "avar": 90, "bvar": 90, "cvar": 90, "avarbvarcvar": 90, "14one": 90, "25two": 90, "36three": 90, "456": 90, "114one": 90, "bracket": 90, "construct": [90, 95], "testabl": 90, "perfom": 90, "elmin": 90, "redund": [90, 92, 102], "repetit": [90, 95], "discret": [90, 101], "certain": [90, 91, 97, 99, 100, 101], "statement": [90, 101], "temperatur": 90, "fanrenheit": 90, "celsiu": 90, "fahrenheit_to_celsiu": 90, "temp_f": 90, "bodi": 90, "convers": 90, "curli": 90, "brace": 90, "temp_c": 90, "especi": [90, 99], "phase": [90, 94], "explicitli": [90, 100], "freez": 90, "water": 90, "function_nam": 90, "input_1": 90, "my_sum": 90, "input_2": 90, "patrick": 90, "mineault": 90, "phd": 90, "particularli": [90, 102], "postdoc": 90, "whose": 90, "gem": 90, "punctuat": 90, "butitsuremakesthingseasiertoread": 90, "deriv": [90, 91, 95], "arbitrari": [90, 102], "underscor": 90, "fit_model": 90, "utility_funct": 90, "foo": 90, "prefix": 90, "similarli": [90, 91, 99, 100], "lowercas": 90, "day_on": 90, "day_1": 90, "dayon": 90, "camel": 90, "handl": 90, "subsequ": [90, 91], "do_something_very_compl": 90, "indent": [90, 97], "long_function_nam": 90, "arrow": 90, "convent": 90, "surfac": 90, "interchang": 90, "eval": 90, "expr": 90, "envir": 90, "enclo": 90, "12345678910": 90, "instanc": 90, "fact": [90, 91, 101], "rare": 90, "annoi": [90, 97], "shortcut": [90, 97, 103], "pc": [90, 92, 97], "dfine": 90, "shorten": 90, "consider": 90, "liter": 90, "necessit": 90, "rigid": 90, "disciplin": 90, "One": [90, 91, 96, 97, 100, 101], "tip": [90, 97, 102], "ensur": [90, 102], "restart": 90, "commit": 90, "git": 90, "broadli": 90, "rstudio": [90, 103], "accumul": 90, "phenomenon": 90, "hate": 90, "Not": 90, "enorm": 90, "wast": 90, "wade": 90, "wrap": [90, 102], "burner": 90, "old": [90, 103], "static": 90, "occur": [90, 91, 97, 100, 102], "unchang": 90, "greatli": 90, "debug": 90, "troubleshoot": 90, "small_fun1": 90, "small_fun2": 90, "big_fun": 90, "pitfal": 90, "mysteri": 90, "info": [90, 97], "magic": [90, 97], "duplic": [90, 97], "unwieldi": [90, 100], "io": [90, 97], "ifs": 90, "familiar": [90, 97, 100], "albeit": 90, "meta": 90, "inde": [90, 101, 102], "multi": 90, "docstr": 90, "readm": [90, 100], "elsewher": 90, "desir": [91, 98, 100], "accomplish": [91, 102], "offer": [91, 100], "plausibl": 91, "procedur": 91, "hors": 91, "taller": 91, "zebra": 91, "mu_h": 91, "163": 91, "cm": 91, "mu_z": 91, "sigma_h": 91, "15cm": 91, "sigma_z": 91, "7cm": 91, "compactli": 91, "height_h": 91, "mathcal": 91, "height_z": 91, "group1_mu": 91, "group1_sd": 91, "group2_mu": 91, "group2_sd": 91, "obs_group1": 91, "obs_group2": 91, "040819": 91, "4690": 91, "149": 91, "8151": 91, "4244": 91, "1182": 91, "3596": 91, "8281": 91, "2860": 91, "143": 91, "7526": 91, "0626": 91, "136": 91, "3627": 91, "run_analysi": 91, "stderr": 91, "0743144889811368": 91, "repeat_analysi": 91, "n_simul": 91, "cvg": 91, "successfulli": 91, "theta_bia": 91, "sigma_bia": 91, "sig": 91, "0208046123467318": 91, "0451000217137926": 91, "anim": 91, "stai": [91, 99], "law": 91, "00173086593671076": 91, "0370144165042127": 91, "18546": 91, "811": 91, "00493198128999189": 91, "0319896690283605": 91, "results_n5": 91, "results_n10": 91, "power_df": 91, "cbind": [91, 98, 103], "n5": 91, "n10": 91, "n_sampl": 91, "geom_histogram": [91, 101], "stat_bin": [91, 101, 102], "bin": [91, 101, 102], "pick": [91, 92, 94, 101, 102], "binwidth": [91, 101, 102], "nearli": 91, "wider": 91, "autom": [91, 101], "revisit": 91, "architectur": 91, "unnest": [91, 97], "imposs": 91, "combo": [91, 97], "neatli": 91, "tibbl": [91, 97], "idsample_sizealphapow": 91, "120": 91, "050": 91, "230": 91, "451": 91, "340": [91, 92], "704": 91, "450": [91, 102], "847": 91, "670": 91, "982": 91, "geom_hlin": [91, 102], "yintercept": 91, "drew": [91, 92], "tradition": 91, "scale_color_discret": 91, "scale_x_continu": [91, 101], "reach": [91, 92, 99, 100], "strict": 91, "beauti": 91, "prime": 91, "faster": 91, "congruent": 91, "incongru": 91, "rod": 91, "psycholinguist": 91, "_intercept": 91, "_slope": 91, "refram": 91, "plu": [91, 94, 99, 101], "center": [91, 97, 99, 101], "_differ": 91, "700": 91, "drastic": 91, "adapt": 91, "wrote": 91, "minqa": 91, "nloptr": 91, "statmod": 91, "timedatectl": 91, "intern": 91, "32mexpand": 91, "34mmatrix": 91, "32mpack": 91, "pack": 91, "32munpack": 91, "unpack": 91, "n_subject": 91, "n_trial": 91, "intercept_sd": 91, "slope_sd": 91, "trial_sd": 91, "subject_intercept": 91, "subject_slop": 91, "slower": 91, "ungroup": [91, 97, 102], "m0": 91, "lmercontrol": 91, "calc": 91, "m1": 91, "fixef": 91, "m_bic": 91, "04082020": 91, "deprec": 91, "tidyr": [91, 97], "preserv": [91, 95], "90mthi": 91, "90mcall": 91, "lifecycl": 91, "last_warn": 91, "subjectinterceptslopeprimert": 91, "1658": 91, "1670116": 91, "9944congruent": 91, "637": 91, "7850": 91, "355": [91, 92], "5954": 91, "312": 91, "3804": 91, "683": 91, "2322": 91, "641": 91, "0751": 91, "6410": 91, "541": 91, "0341": 91, "597": 91, "7813": 91, "9944congruent1001": 91, "2272": 91, "9944congruent1019": 91, "9264": 91, "2807": 91, "1596": 91, "3634congruent": 91, "630": 91, "8723": 91, "666": 91, "1075": 91, "765": 91, "4990": 91, "715": 91, "1133": 91, "515": 91, "6113": 91, "663": 91, "6446": 91, "676": 91, "5442": 91, "850": 91, "1468": 91, "564": 91, "6080": 91, "603": 91, "1024": 91, "concern": 91, "primeincongruent32": 91, "8173297042845226": 91, "406419691669633": 91, "75975221724593": 91, "rafteri": 91, "kass": 91, "1995": [91, 102], "optwrap": 91, "devfun": 91, "opt": 91, "rho": 91, "nloptwrap": 91, "nlopt_roundoff_limit": 91, "roundoff": 91, "led": 91, "newuoa": 91, "toler": 91, "idn_subjectsn_trialspowertheta_biassigma_bia": 91, "120200": 91, "006": [91, 97], "00641936810": 91, "07373782": 91, "230200": 91, "042": 91, "00052660410": 91, "05806434": 91, "340200": 91, "00844010880": 91, "02913024": 91, "420400": 91, "084": 91, "01147605220": 91, "03539564": 91, "530400": 91, "379": 91, "00188869910": 91, "08232914": 91, "640400": 91, "747": 91, "00208821350": 91, "05321679": 91, "720600": 91, "374": 91, "00420983240": 91, "05045607": 91, "830600": 91, "810": 91, "00679313510": 91, "05428755": 91, "940600": 91, "974": 91, "00296774270": 91, "02187785": 91, "pass": [91, 94, 95, 97, 101, 102], "neither": 91, "suffici": [91, 94], "008": 91, "inflat": 91, "takeawai": 91, "wtih": 91, "homogen": 91, "yourself": [91, 99], "plsr": 92, "physic": 92, "reduct": 92, "statquest": 92, "quick": [92, 99], "iri": [92, 97, 98], "petal": [92, 97, 98], "sepal": [92, 97, 98], "subspeci": 92, "flower": [92, 97, 98], "lengthsep": [92, 97, 98], "widthpet": [92, 97, 98], "lengthpet": [92, 97, 98], "widthspeci": [92, 97, 98], "2setosa": [92, 97, 98], "4setosa": [92, 97, 98], "convinc": 92, "ourselv": 92, "0000000": 92, "1175698": 92, "8717538": 92, "8179411": 92, "4284401": 92, "3661259": 92, "9628654": 92, "speci": [92, 97], "enough": [92, 98], "prcomp": 92, "sdev": 92, "root": 92, "eigenvalu": 92, "pc1pc2pc3pc4": 92, "5210659": 92, "37741762": 92, "7195664": 92, "2612863": 92, "2693474": 92, "92329566": 92, "2443818": 92, "1235096": 92, "5804131": 92, "02449161": 92, "1421264": 92, "8014492": 92, "5648565": 92, "06694199": 92, "6342727": 92, "5235971": 92, "pc1": 92, "almost": [92, 101], "evenli": 92, "pc2": 92, "heavili": 92, "coordin": 92, "257141": 92, "4784238": 92, "12727962": 92, "024087508": 92, "074013": 92, "6718827": 92, "23382552": 92, "102662845": 92, "356335": 92, "3407664": 92, "04405390": 92, "028282305": 92, "291707": 92, "5953999": 92, "09098530": 92, "065735340": 92, "381863": 92, "6446757": 92, "01568565": 92, "035802870": 92, "068701": 92, "4842053": 92, "02687825": 92, "006586116": 92, "job": 92, "firmer": 92, "grasp": [92, 102], "hitter": [92, 94, 96], "hit": [92, 94, 96], "salari": [92, 94, 96, 98], "trigger": 92, "263": 92, "svdpc": 92, "rmsep": 92, "segment": 92, "comp": 92, "452": 92, "351": 92, "352": 92, "343": 92, "adjcv": 92, "342": 92, "345": 92, "349": 92, "358": 92, "344": 92, "346": 92, "350": [92, 103], "356": 92, "339": 92, "338": 92, "337": 92, "84": [92, 97], "88": [92, 94], "28": [92, 97], "82": [92, 97], "53": [92, 97, 103], "unless": [92, 100], "val": 92, "ncomp": 92, "142811": 92, "810376319": 92, "131": 92, "kernelpl": 92, "428": 92, "325": 92, "329": 92, "328": 92, "327": 92, "78": 92, "interestingli": 92, "rmse": 92, "151995": 92, "259555806": 92, "maxim": [92, 94, 99], "tehcniqu": 94, "hyperparamet": 94, "basebal": [94, 96], "atbat": [94, 96], "hmrun": [94, 96], "rbi": [94, 96], "catbat": [94, 96], "chit": [94, 96], "chmrun": [94, 96], "crun": [94, 96], "crbi": [94, 96], "cwalk": [94, 96], "leagu": [94, 96], "putout": [94, 96], "assist": [94, 96], "newleagu": [94, 96], "foreach": 94, "lar": 94, "tune": 94, "l2": 94, "norm": 94, "l1": 94, "pressur": 94, "search": [94, 102, 103], "lambda_search_spac": 94, "extrem": [94, 103], "spars": 94, "lenient": 94, "elast": 94, "net": 94, "algorithm": [94, 96], "pure": 94, "mod": 94, "20100": 94, "11497": 94, "50th": 94, "coeff": [94, 95], "lamba": 94, "5699539774": 94, "retain": [94, 97], "5722367659": 94, "35022": 94, "11498": 94, "thresh": 94, "1e10": 94, "newx": 94, "ol": 94, "224669": 94, "833069663": 94, "142199": 94, "150722761": 94, "167789": 94, "778381119": 94, "upon": 94, "henc": 94, "util": 94, "contamin": 94, "train_hyperparamet": 94, "train_glm": 94, "test_hyperparamet": 94, "test_glm": 94, "bestlam": 94, "145590162423": 94, "390": 94, "119507": 94, "530651601": 94, "refit": 94, "dedic": 94, "win": 94, "812546181": 94, "007535828": 94, "517425980": 94, "090339763": 94, "407753980": 94, "037274878": 94, "172859070": 94, "143396736": 94, "014712552": 94, "109118248": 94, "leaguen": [94, 96], "177487099": 94, "183558581": 94, "171052370": 94, "023204448": 94, "742320818": 94, "divisionw": [94, 96], "newleaguen": [94, 96], "771290300": 94, "234770575": 94, "035088669": 94, "551198110": 94, "358141646": 94, "reus": 95, "varaibl": 95, "shuffl": 95, "target": [95, 100], "con": 95, "major": [95, 98], "wild": 95, "fn": 95, "9358610": 95, "1578447": 95, "saniti": 95, "boot_obj": 95, "t1": 95, "t2": 95, "nonparametr": 95, "0337235546": 95, "869718268": 95, "0003595084": 95, "007482048": 95, "t0": 95, "stype": 95, "strata": 95, "boot_typ": 95, "_": [95, 97], "estimatestd": 95, "errort": 95, "valuepr": 95, "93586100": 95, "717498656": 95, "659841": 95, "220362e": 95, "15784470": 95, "006445501": 95, "48914": 95, "031989e": 95, "1578": 95, "By": [95, 102], "nil": 95, "permauto": 95, "smake": 95, "perm": 95, "scrambl": 95, "eyebal": 95, "intact": 95, "tour": 96, "26320": 96, "omit": 96, "leap": 96, "annual": 96, "regfit": 96, "asterisk": 96, "exhaust": 96, "quot": 96, "colum": 96, "nvmax": 96, "reg": 96, "rsq": 96, "adjr2": 96, "outmat": 96, "obj": 96, "atbathitshmrunrunsrbiwalksyearscatbatchitschmruncrunscrbicwalksleaguendivisionwputoutsassistserrorsnewleaguen": 96, "1truefalsefalsefalsefalsefalsefalsefalsefalsefalsefalsefals": 96, "truefalsefalsefalsefalsefalsefalsefals": 96, "2truefals": 96, "truefalsefalsefalsefalsefalsefalsefalsefalsefals": 96, "3truefals": 96, "truefalsefalsefals": 96, "4truefals": 96, "truefalsefals": 96, "5true": 96, "6true": 96, "truefalsefalsefalsefalsefals": 96, "7truefals": 96, "truefals": 96, "truefalsefalsefalsefals": 96, "8true": 96, "9true": 96, "10true": 96, "11true": 96, "12true": 96, "13true": 96, "14true": 96, "15true": 96, "16true": 96, "17true": 96, "18true": 96, "19true": 96, "numvar": 96, "sequenc": [96, 97], "allfals": 96, "mark": [96, 98], "minrss": 96, "maxadjr2": 96, "adj": 96, "mincp": 96, "minbic": 96, "discrep": 96, "pg": 96, "250": 96, "rope": 97, "instinct": 97, "consequ": 97, "dplyr": [97, 102], "yg": 97, "xzc1rwm52nxc0l8mlvk8dkjw0000gp": 97, "rtmpotbuza": 97, "popular": [97, 102], "var2": 97, "streamlin": 97, "straight": [97, 103], "becuas": 97, "05733333333333": 97, "digit": [97, 101], "temporari": 97, "tmp": 97, "obs_mean": 97, "smoothli": 97, "decim": 97, "track": 97, "inner": 97, "outward": 97, "clutter": 97, "intermediari": 97, "keyboard": 97, "purrr": 97, "formerli": 97, "subtract": 97, "reassign": 97, "centered_seplen": 97, "widthspeciescentered_seplen": 97, "7433333": 97, "9433333": 97, "1433333": 97, "2433333": 97, "8433333": 97, "4433333": 97, "zscore": 97, "petlen_zscor": 97, "n_flower": 97, "widthspeciescentered_seplenpetlen_zscoresn_flow": 97, "335752150": 97, "392399150": 97, "279104150": 97, "165809150": 97, "smry": 97, "shortsepal_prop": 97, "setosa_prop": 97, "setosa": [97, 98], "seplen_mean": 97, "seplen_sd": 97, "seplen_s": 97, "n_flowersshortsepal_propsetosa_propseplen_meanseplen_sdseplen_s": 97, "1500": 97, "53333330": 97, "33333335": 97, "8433330": 97, "82806610": 97, "06761132": 97, "collaps": 97, "cleaned_dat": 97, "versi": 97, "versicolor": [97, 98], "virgi": 97, "virginica": [97, 98], "4versicolor": 97, "15666670": 97, "5336209150": 97, "5versicolor": 97, "55666670": 97, "4203256150": 97, "05666670": 97, "6469162150": 97, "3versicolor": 97, "34333330": 97, "1370873150": 97, "65666670": 97, "4769732150": 97, "14333330": 97, "5virginica": 97, "456666671": 97, "2700404150": 97, "9virginica": 97, "043333330": 97, "7602115150": 97, "1virginica": 97, "256666671": 97, "2133927150": 97, "8virginica": 97, "0434497150": 97, "2virginica": 97, "656666671": 97, "1567451150": 97, "756666671": 97, "6099263150": 97, "chain": [97, 101], "seplen_meanseplen_sd": 97, "9360": 97, "5161711": 97, "5880": 97, "6358796": 97, "irrelev": 97, "speciespet": 97, "1setosa1": 97, "2setosa1": 97, "3setosa1": 97, "4setosa1": 97, "5setosa1": 97, "6setosa1": 97, "sign": [97, 100, 101], "5setosa": 97, "0setosa": 97, "1setosa": 97, "6setosa": 97, "9setosa": 97, "inclus": 97, "batch": 97, "starts_with": 97, "helper": 97, "num_rang": 97, "tidyselect": 97, "ascend": 97, "descend": 97, "surround": 97, "desc": 97, "0433333": 97, "052513150": 97, "3setosa": 97, "revers": 97, "petaltyp": 97, "widthspeciescentered_seplenpetlen_zscoresn_flowerspetaltyp": 97, "335752150short": 97, "392399150short": 97, "279104150short": 97, "165809150short": 97, "new_var": 97, "input1": 97, "input2": 97, "combined_var": 97, "widthcombined_varspeciescentered_seplenpetlen_zscoresn_flowerspetaltyp": 97, "2setosa_shortsetosa": 97, "4setosa_shortsetosa": 97, "species1": 97, "petaltype1": 97, "widthspecies1petaltype1speciescentered_seplenpetlen_zscoresn_flowerspetaltyp": 97, "2setosashortsetosa": 97, "4setosashortsetosa": 97, "ineffici": 97, "join": 97, "afterward": 97, "90m": 97, "\u00b9": 97, "\u00b2": 97, "\u00b3": 97, "\u2074": 97, "\u2075": 97, "cent": 97, "\u2076": 97, "petl": 97, "\u2077": 97, "3m": 97, "23m": 97, "31m0": 97, "31m743": 97, "31m1": 97, "31m34": 97, "31m943": 97, "31m14": 97, "31m39": 97, "31m24": 97, "31m28": 97, "31m843": 97, "31m443": 97, "31m17": 97, "31m44": 97, "90m10": 97, "abbrevi": [97, 102], "implicit": 97, "sepwid_mean": 97, "sepwid_sd": 97, "overrid": 97, "grouped_df": 97, "speciespetaltypeseplen_meanseplen_sdsepwid_meansepwid_sd": 97, "short5": 97, "0060000": 97, "35248973": 97, "4280000": 97, "3524897": 97, "versicolorlong": 97, "0465120": 97, "45374052": 97, "8232560": 97, "4537405": 97, "versicolorshort5": 97, "2571430": 97, "33094382": 97, "4428570": 97, "3309438": 97, "5880000": 97, "63587962": 97, "9740000": 97, "scene": 97, "dat_cent": 97, "seplen_centered_overal": 97, "seplen_centered_byspeci": 97, "speciesseplen_centered_overallseplen_centered_byspeci": 97, "094": 97, "394": 97, "seplen_centering_byspeci": 97, "meanwhil": 97, "seplen_centering_overal": 97, "regardless": 97, "widthspeciespetaltyp": 97, "2setosashort": 97, "4setosashort": 97, "90m1": 97, "90m2": 97, "90m3": 97, "becam": 97, "widthpetaltyp": 97, "2short": 97, "4short": 97, "wait": 97, "90m4": 97, "fanci": 97, "sappli": 97, "subgroup": 97, "nested_lm": 97, "nest_df": 97, "21316822303424petal": 97, "length0": 97, "542292597103803": 97, "1276221410204282": 97, "07237785897956363": 97, "2181485992691844": 97, "42660711868994550": 97, "02762214102043660": 97, "2649343618892957": 97, "3723778589795648": 97, "02660711868994449": 97, "57237785897956410": 97, "126607118689944110": 97, "37339288131005612": 97, "28083637840032513": 97, "17237785897956414": 97, "509690079848423150": 97, "936080660441196160": 97, "673392881310056170": 97, "481851400730817180": 97, "127622141020436190": 97, "564934361889295200": 97, "0733928813100553210": 97, "264934361889295220": 97, "073392881310055323": 97, "15546082013804324": 97, "035065638110705325": 97, "44352415753146626": 97, "080836378400324727": 97, "0808363784003247280": 97, "173392881310056290": 97, "22762214102043630": 97, "38083637840032431": 97, "280836378400325320": 97, "373392881310056330": 97, "173392881310056340": 97, "52762214102043635": 97, "126607118689944360": 97, "136080660441197370": 97, "58185140073081638": 97, "072377858979563739": 97, "518148599269183400": 97, "0733928813100553410": 97, "081851400730816242": 97, "41814859926918443": 97, "51814859926918344": 97, "080836378400324745": 97, "14352415753146646": 97, "172377858979564470": 97, "019163621599674948": 97, "372377858979564490": 97, "273392881310055500": 97, "027622141020436": 97, "super": 97, "ugli": 97, "542": 97, "858": 97, "90m5": 97, "90m6": 97, "865": 97, "90m7": 97, "90m8": 97, "996": 97, "omayma": 97, "climate_change_expanalysi": 97, "aslo": 97, "newdat": 97, "widthspeciesflow": 97, "2setosa2": 97, "2setosa3": 97, "2setosa4": 97, "2setosa5": 97, "4setosa6": 97, "names_to": 97, "values_to": 97, "concaten": 97, "iris_attribut": 97, "speciesflow": 97, "numiris_attributevalu": 97, "setosa1sep": 97, "length5": 97, "setosa1pet": 97, "length1": 97, "setosa2sep": 97, "length4": 97, "tidier": 97, "names_from": 97, "values_from": 97, "numsep": 97, "setosa15": 97, "setosa24": 97, "setosa34": 97, "setosa44": 97, "setosa55": 97, "setosa65": 97, "inner_join": 97, "right_join": 97, "full_join": 97, "p01": 97, "p02": 97, "p03": 97, "firstlang": 97, "chines": 97, "nameagefirstlang": 97, "1p0118english": 97, "2p0221chines": 97, "3p0323english": 97, "namerespons": 97, "1p010": 97, "2p011": 97, "3p021": 97, "4p020": 97, "nameagefirstlangrespons": 97, "2p0118english": 97, "3p0221chines": 97, "4p0221chines": 97, "5p0323englishna": 97, "1p0118english0": 97, "2p0118english1": 97, "3p0221chinese1": 97, "4p0221chinese0": 97, "straightforward": 98, "bunch": 98, "closest": 98, "whichev": 98, "ind": 98, "widthspeciesi": 98, "testspecies_predknn_correct": 98, "2setosafalsesetosatru": 98, "4setosafalsesetosatru": 98, "spec": 98, "versicolorvirginicasetosasetosaversicolorversicolorsetosavirginicavirginicasetosa": 98, "species_pr": 98, "knn_correct": 98, "ggtitl": [98, 103], "solid": [98, 101], "edg": 98, "green": 98, "866666666666667": 98, "mislabel": 98, "viginica": 98, "species_predk1": 98, "species_predk100": 98, "misclassifi": 98, "border": [98, 101], "strai": 98, "notabl": 98, "farther": 98, "verginica": 98, "suffer": 98, "caravan": 98, "bought": 98, "insur": 98, "purchas": 98, "abystand": 98, "mostypemaanthuimgemomvmgemleefmoshoofdpurchas": 98, "133132": 98, "8no": 98, "237122": 98, "337122": 98, "9133": 98, "3no": 98, "54014210no": 98, "623121": 98, "5no": 98, "vastli": 98, "037847395189": 98, "164707781931954": 98, "proper": 98, "soon": 98, "1001": 98, "purch": 98, "941": 98, "bui": 98, "fluke": 98, "paul": 99, "dx": 99, "lim_": 99, "satisfi": [99, 100], "connect": [99, 100, 101], "2x": 99, "df_dx": 99, "x_dat": 99, "func": 99, "relevel": 99, "010": 99, "040": 99, "090": 99, "160": 99, "sin": 99, "x_min": 99, "xintercept": 99, "steep": 99, "dot": [99, 101], "dmse": 99, "flat": [99, 103], "nx": 99, "3x": 99, "q": [99, 103], "rewritten": 99, "1x": 99, "4x": 99, "8x": 99, "dx_1": 99, "dx_2": 99, "2x_1": 99, "4x_1x_2": 99, "4x_2": 99, "4x_1": 99, "2x_2": 99, "trickier": 99, "jump": 99, "log_": 99, "rais": 99, "ln": 99, "relatedli": 99, "monoton": 99, "log_f": 99, "flatter": 99, "beta_1x_i": 99, "pain": 99, "fourth": 99, "cy": 99, "2cxy": 99, "2y": 99, "2ce": 99, "2c": 99, "2var": 99, "folk": 99, "fear": 99, "mental": 100, "earli": 100, "request": 100, "advisor": 100, "suddenli": 100, "surprisingli": 100, "backup": 100, "forth": 100, "interfac": 100, "paragraph": 100, "gitkraken": 100, "versatil": 100, "app": 100, "complementari": 100, "servic": 100, "host": 100, "onlin": 100, "sync": 100, "scm": 100, "privat": [100, 102], "memor": 100, "config": 100, "andrew": 100, "usernam": 100, "password": 100, "token": 100, "proceed": 100, "corner": 100, "lieu": 100, "login": 100, "repo": 100, "permiss": 100, "unix": 100, "shell": 100, "navig": 100, "cd": 100, "foldernam": 100, "ever": [100, 101], "pwd": 100, "dir": 100, "hassl": 100, "readi": [100, 102], "coaxlab": 100, "datasciencepsychneuro_cmu85732": 100, "mkdir": 100, "pathnam": 100, "data_sci": 100, "my_awesome_project": 100, "colon": 100, "yournam": 100, "remot": 100, "myusernam": 100, "nameofrepositori": 100, "laptop": 100, "period": 100, "filenam": 100, "script1": 100, "script2": 100, "draft": 100, "experiment": 100, "stimuli": 100, "gitignor": 100, "spent": 100, "revis": 100, "briefli": 100, "hasn": 100, "tree": 100, "protect": 100, "checkout": 100, "nameofnewbranch": 100, "creation": 100, "branchnam": 100, "simultan": 100, "newer": 100, "devot": 100, "weirdtestbranch": 100, "pan": 100, "wish": 100, "discard": 100, "filetokeep": 100, "unsur": 100, "3a": 100, "myproject": 100, "3b": 100, "scratch": 100, "upstream": 100, "happi": [100, 102], "specialbranchfornewfeatur": 100, "rins": 100, "fortun": 100, "ton": 100, "jenni": 100, "bryan": 100, "bookdown": 100, "ey": 100, "workshop": 100, "regularli": 100, "sheet": 101, "cheat": 101, "geometr": 101, "dissect": 101, "aesteth": 101, "x_axi": 101, "readibl": 101, "clariti": 101, "overplot": 101, "dsmall": 101, "ordin": 101, "n_shape": 101, "advis": 101, "AND": 101, "broad": 101, "densiti": 101, "datapoint": [101, 102], "geom_col": 101, "geom_til": 101, "geom_dens": 101, "bandwidth": 101, "selector": 101, "summarising_funct": 101, "typeofplot": 101, "mean_s": 101, "stat_summary_2d": 101, "geom_boxplot": 101, "pointrang": 101, "geom_seg": [101, 102], "expens": 101, "scarciti": 101, "highgest": 101, "logarithm": 101, "squash": 101, "tail": [101, 103], "skew": 101, "linerang": 101, "log_carat": 101, "log_pric": 101, "paranoid": 101, "geom_dotplot": 101, "binaxi": 101, "stackdir": 101, "stat_bindot": 101, "ggalli": 102, "guidelin": 102, "ggpair": 102, "suppress": [102, 103], "suppressmessag": 102, "piec": 102, "sj": 102, "v1s3b78s07z2w0md4brp2kmm0000gn": 102, "rtmpkw4pdx": 102, "nepali": 102, "farawai": 102, "health": 102, "nepales": 102, "rtmpfbuygz": 102, "sex": 102, "child": 102, "wt": 102, "ht": 102, "male": 102, "femal": 102, "keep_al": 102, "idsexwthtag": 102, "1120011male": 102, "241": 102, "2120012female14": 102, "9103": 102, "957": 102, "3120021femal": 102, "4120022female12": 102, "435": 102, "5120023male": 102, "449": 102, "6120031male": 102, "broken": 102, "worldcup": 102, "player": 102, "soccer": 102, "cup": 102, "chicagonmmap": 102, "dlnm": 102, "nation": 102, "morbid": 102, "mortal": 102, "pollut": 102, "nmmap": 102, "chic": 102, "chic_juli": 102, "juli": 102, "thumb": 102, "showcas": 102, "extran": 102, "theme_linedraw": 102, "theme_minim": 102, "theme_void": 102, "theme_dark": 102, "heatwav": 102, "chicago_plot": 102, "date": 102, "death": 102, "geom_area": 102, "theme_excel": 102, "excess": 102, "background": 102, "eas": 102, "orient": 102, "abrevi": 102, "messier": 102, "forcat": 102, "wc_example_data": 102, "renam": 102, "fct_recod": 102, "dc": 102, "defend": 102, "fw": 102, "forward": 102, "gk": 102, "goalkeep": 102, "mf": 102, "midfield": 102, "elimin": 102, "spell": 102, "lightgrai": 102, "advic": 102, "obviou": 102, "headspac": 102, "shade": [102, 103], "horizont": 102, "smooth": 102, "shot": 102, "theme_few": 102, "cue": 102, "wiggli": 102, "geom_ablin": [102, 103], "geom_polygon": 102, "polygon": 102, "geom_path": 102, "unfil": 102, "guidanc": 102, "obscur": 102, "ultim": 102, "overwhelm": 102, "theabov": 102, "holland": 102, "finalist": 102, "team": 102, "netherland": 102, "categori": 102, "alphabet": 102, "group_bi": 102, "mean_tim": 102, "ave_tim": 102, "min_tim": 102, "max_tim": 102, "xend": 102, "yend": 102, "grai": 102, "cookbook": 102, "websit": 102, "cheatsheet": 102, "namespac": 103, "attach": 103, "1993": 103, "libarari": 103, "qq": 103, "dist": 103, "rougli": 103, "safe": 103, "preliminari": 103, "joint": 103, "543": 103, "87": 103, "176": 103, "899": 103, "2894": 103, "460": 103, "376": 103, "287": 103, "505": 103, "6501": 103, "6462": 103, "169": 103, "star": 103, "grab": 103, "29710281562": 103, "5712895035716": 103, "confit": 103, "3808": 103, "77815": 103, "1979": 103, "81606": 103, "59531": 103, "54727": 103, "inch": 103, "length_input_valu": 103, "prediction_t": 103, "pred_input_t": 103, "bind": 103, "length_input": 103, "lower_ci_bound": 103, "upper_ci_bound": 103, "length_inputpredict": 103, "fitlower_ci_boundupper_ci_bound": 103, "11652479": 103, "972364": 103, "082595": 103, "21802968": 103, "542894": 103, "533042": 103, "31953457": 103, "103364": 103, "003550": 103, "lb": 103, "3042": 103, "diagnost": 103, "suppresswarn": 103, "autoplot": 103, "reveal": 103, "strictli": 103, "rstudent": 103, "hatvalu": 103}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"fiona": 0, "test": [0, 35, 36, 39, 40, 42, 94, 95, 98, 104], "md": 0, "discuss": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "question": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "exercis": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "10": 29, "classif": 29, "1": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 80, 87, 99, 104], "load": [29, 31, 32, 34, 37, 39, 41], "format": [29, 34], "data": [29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 53, 68, 69, 80, 84, 85, 90, 91, 97, 98, 102], "point": [29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46], "2": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 80, 87, 99], "visual": [29, 32, 33, 38, 39, 75, 76, 102], "3": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 80, 87, 99], "logist": [29, 39, 83], "regress": [29, 32, 38, 43, 55, 64, 83, 86, 87, 92, 94, 103], "fit": [29, 34, 38, 103], "model": [29, 31, 32, 34, 38, 40, 43, 56, 58, 59, 66, 82, 85, 86, 88, 89, 91, 94, 96, 98, 103], "4": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 80, 99], "interpret": 29, "predict": [29, 83, 98, 103], "from": [29, 100], "5": [29, 31, 32, 33, 36, 37, 39, 45, 80, 99], "qda": [29, 83], "12": 30, "cross": [30, 52, 84], "valid": [30, 52, 84, 94], "pt": [30, 31, 35, 36, 42, 46], "leav": [30, 84], "one": [30, 84, 97], "out": [30, 81, 84, 87, 93, 99], "compar": 30, "cv": 30, "glm": [30, 83], "adjust": 30, "k": [30, 84, 98], "reflect": [30, 32, 33, 34, 36, 37, 38, 39], "object": [31, 53, 85], "packag": 31, "replic": 31, "summari": [31, 35, 87], "output": 31, "tabl": [31, 41], "index": [31, 87, 90], "7": [32, 46], "linear": [32, 43, 55, 56, 86, 87, 89, 103], "initi": 32, "plot": [32, 41, 42, 45, 46, 101, 102, 103], "14": 33, "mediat": [33, 57, 88], "simul": [33, 36, 38, 60, 86, 91], "analysi": [33, 37, 60, 75, 91, 92], "9": 34, "mix": [34, 58, 82, 89, 91], "effect": [34, 39, 58, 82, 89], "assess": [34, 98], "code": [35, 79, 90], "habit": [35, 90], "function": [35, 36, 90, 91, 97, 99], "statist": [35, 45, 80], "t": 35, "set": [35, 42, 84, 94, 100], "default": 35, "valu": [35, 63, 72, 99], "15": 36, "power": [36, 60, 91, 99], "analys": [36, 91], "run_analysi": 36, "repeat_analysi": 36, "differ": [36, 88, 95, 100], "sampl": [36, 91], "size": [36, 91], "18": 37, "princip": [37, 61, 92], "compon": [37, 61, 92], "method": [37, 39, 61, 65], "correl": [37, 101], "structur": [37, 90], "associ": 37, "flanker": 37, "task": 37, "peform": 37, "17": 38, "regular": [38, 64], "bia": [38, 67, 86], "varianc": [38, 67, 86, 91], "tradeoff": [38, 67, 86], "polynomi": 38, "appli": 38, "bonu": 38, "extra": 38, "credit": 38, "13": 39, "resampl": [39, 65], "classifi": [39, 50, 83, 98], "bootstrap": [39, 95], "accuraci": 39, "permut": [39, 95], "grei": 39, "matter": [39, 80], "16": 40, "select": [40, 66, 96, 97], "best": [40, 66, 96], "subset": [40, 96], "forward": 40, "backward": 40, "stepwis": 40, "train": [40, 42], "error": [40, 54], "manipul": [41, 87], "cleans": [41, 68, 97], "tidyvers": [41, 97], "11": 42, "The": [42, 67, 70, 71, 72, 80, 88, 99], "beauti": [42, 70], "knn": [42, 70, 98], "vs": 42, "loop": 42, "standard": [42, 97, 98], "predictor": [42, 86, 103], "8": 43, "continu": 43, "deriv": [43, 99], "maximum": 43, "likelihood": 43, "estim": [43, 82], "simpl": [43, 82, 84, 103], "6": [43, 45, 46], "connect": 43, "github": [44, 100], "jupyt": [44, 81, 90, 93], "us": [45, 79, 81, 84, 87, 90, 93, 98, 99, 100], "ggplot": 45, "color": 45, "type": 45, "layer": 45, "ad": [45, 79, 99, 100], "more": [46, 86, 91, 102], "option": 46, "multipanel": 46, "figur": 46, "increas": 46, "densiti": [46, 102], "explor": 47, "art": [48, 80], "investig": 48, "lectur": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "bay": [49, 82], "factor": [49, 82], "requir": [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "read": [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "video": [49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 104], "slide": [49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77], "pdf": [49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77], "construct": [51, 73], "testabl": [51, 59], "hypothesi": 51, "architectur": 53, "infer": [54, 103], "limit": 55, "variat": 55, "moder": [57, 88], "hypothes": 59, "via": 60, "quantit": 62, "epsitemolog": 62, "reconsid": 63, "p": 63, "techniqu": 68, "tell": 69, "your": [69, 79, 80, 91, 102], "stori": 69, "ordinari": 71, "least": [71, 92, 99], "squar": [71, 87, 92, 99], "solut": 71, "open": 72, "theori": [73, 77], "social": 73, "through": 76, "human": 76, "ey": 76, "what": [77, 78, 79, 82, 87, 91, 99, 100], "learnabl": 78, "markdown": 79, "file": [79, 100], "myst": 79, "ar": [79, 99, 100], "role": 79, "direct": 79, "citat": 79, "execut": 79, "poetri": 80, "rule": [80, 99], "track": [80, 100], "chronicl": 80, "preserv": 80, "subrul": 80, "everi": 80, "detail": 80, "autom": 80, "much": 80, "you": 80, "can": 80, "proactiv": 80, "reactiv": 80, "see": 80, "languag": 80, "magic": 80, "tutori": [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "get": [81, 86, 93, 97], "start": [81, 86, 93, 97], "goal": [81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "instal": [81, 93], "r": [81, 85, 88, 90, 93], "rstudio": [81, 93], "try": [81, 93], "julia": [81, 93], "python": [81, 93], "notebook": [81, 90, 93], "why": [81, 84, 93, 99, 100], "kernel": [81, 93], "implement": [82, 84], "exampl": [82, 91, 99, 100], "calcul": [82, 99], "comparison": 82, "candid": 82, "basic": [83, 87, 90, 91, 92, 94, 100, 101], "stock": 83, "market": 83, "lda": 83, "approach": [84, 92], "loocv": 84, "fold": 84, "tidi": [85, 90], "interact": 85, "multipl": [86, 87, 97, 102], "work": [86, 87, 99, 100], "categor": 86, "qualit": 86, "refresh": [87, 99], "matric": 87, "vector": [87, 90, 97], "sum": 87, "product": [87, 99], "equat": 87, "trick": 87, "pull": [87, 100], "term": 87, "split": [87, 97], "up": [87, 100], "coeffici": 87, "matrix": 87, "kind": 87, "symmetr": 87, "ident": 87, "oper": [87, 97], "addit": 87, "subtract": 87, "transposit": 87, "divis": 87, "invers": 87, "determin": [87, 91], "solv": [87, 99], "problem": 87, "hand": 87, "run": [88, 89, 91, 98], "between": [88, 95], "introduct": 90, "good": 90, "command": 90, "arithmet": 90, "frame": [90, 97], "how": 90, "write": [90, 91], "research": 90, "practic": 90, "keep": [90, 97], "consist": 90, "delet": 90, "dead": 90, "pure": 90, "bad": 90, "thing": 90, "do": 90, "document": 90, "algorithm": 91, "sourc": 91, "artifici": 91, "conduct": 91, "intend": 91, "vari": [91, 98], "alpha": 91, "level": 91, "extend": [91, 102], "complic": 91, "But": 91, "import": [91, 94], "number": 91, "subject": 91, "trial": 91, "pca": 92, "big": 92, "pictur": 92, "partial": 92, "ridg": 94, "lasso": 94, "an": [94, 98], "note": 94, "about": 94, "boostrap": 95, "A": [95, 97, 99], "remind": 95, "grammar": 97, "pipe": 97, "transform": 97, "mutat": 97, "exist": 97, "variabl": [97, 99], "creat": 97, "new": [97, 100], "summaris": 97, "summar": 97, "filter": 97, "row": 97, "base": 97, "condit": 97, "column": 97, "remov": 97, "arrang": 97, "sort": 97, "unit": 97, "combin": 97, "two": [97, 99], "separ": 97, "group_bi": 97, "implicitli": 97, "group": 97, "nest": 97, "explicitli": 97, "map": 97, "perform": [97, 98], "same": 97, "each": 97, "element": 97, "list": 97, "restructur": 97, "long": 97, "wide": 97, "merg": [97, 100], "pivot_long": 97, "pivot_wid": 97, "_join": 97, "nearest": 98, "neighbor": 98, "intro": 98, "iris": 98, "identifi": 98, "item": 98, "speci": 98, "oridinari": 99, "tip": 99, "constant": 99, "take": 99, "find": 99, "minim": 99, "logarithm": 99, "e": 99, "quotient": 99, "expon": 99, "we": 99, "thi": 99, "class": 99, "expect": 99, "repositori": 100, "version": 100, "control": 100, "git": 100, "configur": 100, "updat": 100, "authent": 100, "process": 100, "bash": 100, "script": 100, "chang": 100, "commit": 100, "branch": 100, "onli": 100, "specif": 100, "put": 100, "all": 100, "togeth": 100, "workflow": 100, "distribut": 101, "first": 101, "aesthet": 101, "geom": 101, "advanc": 102, "ggplot2": 102, "custom": 102, "high": 102, "meaning": 102, "label": 102, "refer": 102, "small": 102, "order": 102, "resourc": 102, "singl": 103}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})