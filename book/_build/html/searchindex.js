Search.setIndex({"docnames": ["discussions/Fiona-test", "discussions/bayes-factor-accepting-the-null", "discussions/classifiers", "discussions/cross-validation", "discussions/data-as-objects-and-architectures", "discussions/errors-and-inferences", "discussions/limits-of-linear-regression", "discussions/linear-models", "discussions/mediation-and-moderation", "discussions/mixed-effects-models", "discussions/models-as-testable-hypotheses", "discussions/power-analysis-via-simulations", "discussions/principal-component-methods", "discussions/quantitative-epistemology", "discussions/reconsidering-the-p-value", "discussions/regularized-regression", "discussions/resampling-methods", "discussions/selecting-the-best-model", "discussions/statistical-learning-theory", "discussions/techniques-for-data-cleansing", "discussions/telling-your-data-story", "discussions/the-beauty-of-knn", "discussions/the-ordinary-least-squares-solution", "discussions/the-value-of-openness", "discussions/theories-as-social-constructs", "discussions/visualization-as-analysis", "discussions/visualization-through-human-eyes", "discussions/what-is-a-theory", "discussions/what-is-learnable", "exercises/classifiers", "exercises/cross-validation", "exercises/data-as-objects-and-architectures", "exercises/linear-models", "exercises/mediation-and-moderation", "exercises/mixed-effects-models", "exercises/models-as-testable-hypotheses", "exercises/power-analysis-via-simulations", "exercises/principal-component-methods", "exercises/regularized-regression", "exercises/resampling-methods", "exercises/selecting-the-best-model", "exercises/techniques-for-data-cleansing", "exercises/the-beauty-of-knn", "exercises/the-ordinary-least-squares-solution", "exercises/the-value-of-openness", "exercises/visualization-as-analysis", "exercises/visualization-through-human-eyes", "intro", "lectures/art-of-data-investigations", "lectures/bayes-factor-accepting-the-null", "lectures/classifiers", "lectures/constructing-a-testable-hypothesis", "lectures/cross-validation", "lectures/data-as-objects-and-architectures", "lectures/errors-and-inferences", "lectures/limits-of-linear-regression", "lectures/linear-models", "lectures/mediation-and-moderation", "lectures/mixed-effects-models", "lectures/models-as-testable-hypotheses", "lectures/power-analysis-via-simulations", "lectures/principal-component-methods", "lectures/quantitative-epistemology", "lectures/reconsidering-the-p-value", "lectures/regularized-regression", "lectures/resampling-methods", "lectures/selecting-the-best-model", "lectures/statistical-learning-theory", "lectures/techniques-for-data-cleansing", "lectures/telling-your-data-story", "lectures/the-beauty-of-knn", "lectures/the-ordinary-least-squares-solution", "lectures/the-value-of-openness", "lectures/theories-as-social-constructs", "lectures/video-test-1", "lectures/visualization-as-analysis", "lectures/visualization-through-human-eyes", "lectures/what-is-a-theory", "lectures/what-is-learnable", "markdown", "notebooks/01-Introduction-to-data-investigations", "notebooks/Untitled", "notebooks/art-of-data-investigations", "notebooks/bayes-factor-accepting-the-null", "notebooks/classifiers", "notebooks/cross-validation", "notebooks/cross-validation.old", "notebooks/data-as-objects-and-architectures", "notebooks/limits-of-linear-regression", "notebooks/linear-models", "notebooks/mediation-and-moderation", "notebooks/mixed-effects-models", "notebooks/models-as-testable-hypotheses", "notebooks/power-analysis-via-simulations", "notebooks/principal-component-methods", "notebooks/quantitative-epistemology", "notebooks/regularized-regression", "notebooks/resampling-methods", "notebooks/selecting-the-best-model", "notebooks/techniques-for-data-cleansing", "notebooks/the-beauty-of-knn", "notebooks/the-ordinary-least-squares-solution", "notebooks/the-value-of-openness", "notebooks/visualization-as-analysis", "notebooks/visualization-through-human-eyes", "notebooks/what-is-learnable", "video1"], "filenames": ["discussions/Fiona-test.md", "discussions/bayes-factor-accepting-the-null.md", "discussions/classifiers.md", "discussions/cross-validation.md", "discussions/data-as-objects-and-architectures.md", "discussions/errors-and-inferences.md", "discussions/limits-of-linear-regression.md", "discussions/linear-models.md", "discussions/mediation-and-moderation.md", "discussions/mixed-effects-models.md", "discussions/models-as-testable-hypotheses.md", "discussions/power-analysis-via-simulations.md", "discussions/principal-component-methods.md", "discussions/quantitative-epistemology.md", "discussions/reconsidering-the-p-value.md", "discussions/regularized-regression.md", "discussions/resampling-methods.md", "discussions/selecting-the-best-model.md", "discussions/statistical-learning-theory.md", "discussions/techniques-for-data-cleansing.md", "discussions/telling-your-data-story.md", "discussions/the-beauty-of-knn.md", "discussions/the-ordinary-least-squares-solution.md", "discussions/the-value-of-openness.md", "discussions/theories-as-social-constructs.md", "discussions/visualization-as-analysis.md", "discussions/visualization-through-human-eyes.md", "discussions/what-is-a-theory.md", "discussions/what-is-learnable.md", "exercises/classifiers.ipynb", "exercises/cross-validation.ipynb", "exercises/data-as-objects-and-architectures.ipynb", "exercises/linear-models.ipynb", "exercises/mediation-and-moderation.ipynb", "exercises/mixed-effects-models.ipynb", "exercises/models-as-testable-hypotheses.ipynb", "exercises/power-analysis-via-simulations.ipynb", "exercises/principal-component-methods.ipynb", "exercises/regularized-regression.ipynb", "exercises/resampling-methods.ipynb", "exercises/selecting-the-best-model.ipynb", "exercises/techniques-for-data-cleansing.ipynb", "exercises/the-beauty-of-knn.ipynb", "exercises/the-ordinary-least-squares-solution.ipynb", "exercises/the-value-of-openness.ipynb", "exercises/visualization-as-analysis.ipynb", "exercises/visualization-through-human-eyes.ipynb", "intro.md", "lectures/art-of-data-investigations.md", "lectures/bayes-factor-accepting-the-null.md", "lectures/classifiers.md", "lectures/constructing-a-testable-hypothesis.md", "lectures/cross-validation.md", "lectures/data-as-objects-and-architectures.md", "lectures/errors-and-inferences.md", "lectures/limits-of-linear-regression.md", "lectures/linear-models.md", "lectures/mediation-and-moderation.md", "lectures/mixed-effects-models.md", "lectures/models-as-testable-hypotheses.md", "lectures/power-analysis-via-simulations.md", "lectures/principal-component-methods.md", "lectures/quantitative-epistemology.md", "lectures/reconsidering-the-p-value.md", "lectures/regularized-regression.md", "lectures/resampling-methods.md", "lectures/selecting-the-best-model.md", "lectures/statistical-learning-theory.md", "lectures/techniques-for-data-cleansing.md", "lectures/telling-your-data-story.md", "lectures/the-beauty-of-knn.md", "lectures/the-ordinary-least-squares-solution.md", "lectures/the-value-of-openness.md", "lectures/theories-as-social-constructs.md", "lectures/video-test-1.ipynb", "lectures/visualization-as-analysis.md", "lectures/visualization-through-human-eyes.md", "lectures/what-is-a-theory.md", "lectures/what-is-learnable.md", "markdown.md", "notebooks/01-Introduction-to-data-investigations.ipynb", "notebooks/Untitled.ipynb", "notebooks/art-of-data-investigations.ipynb", "notebooks/bayes-factor-accepting-the-null.ipynb", "notebooks/classifiers.ipynb", "notebooks/cross-validation.ipynb", "notebooks/cross-validation.old.ipynb", "notebooks/data-as-objects-and-architectures.ipynb", "notebooks/limits-of-linear-regression.ipynb", "notebooks/linear-models.ipynb", "notebooks/mediation-and-moderation.ipynb", "notebooks/mixed-effects-models.ipynb", "notebooks/models-as-testable-hypotheses.ipynb", "notebooks/power-analysis-via-simulations.ipynb", "notebooks/principal-component-methods.ipynb", "notebooks/quantitative-epistemology.ipynb", "notebooks/regularized-regression.ipynb", "notebooks/resampling-methods.ipynb", "notebooks/selecting-the-best-model.ipynb", "notebooks/techniques-for-data-cleansing.ipynb", "notebooks/the-beauty-of-knn.ipynb", "notebooks/the-ordinary-least-squares-solution.ipynb", "notebooks/the-value-of-openness.ipynb", "notebooks/visualization-as-analysis.ipynb", "notebooks/visualization-through-human-eyes.ipynb", "notebooks/what-is-learnable.ipynb", "video1.md"], "titles": ["Fiona Test MD", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Discussion questions", "Exercise 9: Classification", "Exercise 12: Cross validation", "Exercise 3: Data objects", "Exercise 7:  Linear models", "Exercise 14: Mediation", "Exercise 10: Mixed effects", "Exercise 2: Coding Habits &amp; Functions", "Exercise 15: Power analyses", "Exercise 18: Principal component methods", "Exercise 17: Regularized regression", "Exercise 13:  Resampling methods", "Exercise 16: Model selection", "Exercise 4: Data cleansing", "Exercise 11: The beauty of kNN", "Exercise 8:  Linear models, continued", "Exercise 1: Github &amp; Jupyter", "Exercise 5: Using ggplot", "Exercise 6: More plotting options", "Data explorations", "Art of data investigations", "Bayes factor", "Classifiers", "Constructing a testable hypothesis", "Cross validation", "Data as objects and architectures", "Errors and inferences", "Limits and variations of linear regression", "Linear models", "Mediation and moderation", "Mixed effects models", "Models as testable hypotheses", "Power analysis via simulations", "Principal component methods", "Quantitative epsitemology", "Reconsidering the p-value", "Regularized regression", "Resampling methods", "Selecting the best model", "The bias-variance tradeoff", "Techniques for data cleansing", "Telling your data story", "The beauty of kNN", "The ordinary least squares solution", "The value of openness", "Theories as social constructs", "&lt;no title&gt;", "Visualization as analysis", "Visualization through human eyes", "What is a theory?", "What is learnable?", "Markdown Files", "The art of \u201cdata poetry\u201d", "&lt;no title&gt;", "Tutorial: Getting started", "Tutorial: Estimating Bayes factors", "Tutorial: Basics classifiers", "Tutorial: Implementing cross validation", "Tutorial: Implementing cross validation", "Tutorial: Data as Objects and Tidy Data", "Tutorial: More on linear models", "Tutorial: Refresher on working with matrices", "Tutorial: Running mediation and moderation models", "Tutorial: Running linear mixed effects models", "Tutorial: Introduction to R, functions, and good coding habits", "Tutorial: Running basic power analyses", "Tutorial: Basic PCA approaches", "Tutorial: Getting started", "Tutorial: Basic ridge and LASSO models", "Tutorial: Boostrap and permutation tests", "Tutorial: Model selection", "Tutorial: Data Cleansing and the Tidyverse", "Tutorial: Running kNN models", "Tutorial: Refresher for solving oridinary least squares", "Tutorial: Repositories and version control", "Tutorial: Basics of plotting", "Tutorial: More advanced plotting", "Tutorial: Fitting and prediction", "Video test 1"], "terms": {"consid": [1, 4, 6, 8, 14, 43, 80, 92, 94, 96, 103, 104], "situat": [1, 36, 83, 88, 102], "where": [1, 2, 4, 9, 11, 17, 20, 21, 24, 25, 26, 27, 30, 31, 32, 34, 35, 38, 40, 41, 42, 44, 45, 46, 80, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 105], "you": [1, 2, 5, 8, 16, 17, 19, 21, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "have": [1, 2, 11, 21, 22, 25, 28, 29, 30, 31, 36, 37, 38, 39, 42, 46, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105], "uniform": 1, "prior": [1, 46, 83, 84, 89, 93, 94, 99, 102], "your": [1, 3, 4, 10, 11, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105], "model": [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 21, 22, 30, 33, 36, 37, 39, 42, 45, 53, 57, 60, 61, 64, 77, 84, 85, 86, 89, 92, 94, 97, 99, 101, 102, 103, 104], "i": [1, 3, 4, 8, 9, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 62, 75, 82, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "e": [1, 2, 9, 10, 12, 21, 26, 27, 30, 34, 36, 38, 39, 40, 43, 45, 49, 53, 59, 72, 77, 80, 84, 85, 86, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 102, 103, 104, 105], "an": [1, 3, 4, 7, 10, 11, 13, 16, 20, 21, 23, 25, 27, 30, 33, 34, 35, 36, 37, 38, 40, 46, 47, 50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 75, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 102, 103, 104, 105], "unknown": 1, "thi": [1, 5, 7, 8, 9, 10, 12, 13, 14, 16, 20, 21, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "effect": [1, 3, 8, 9, 11, 12, 16, 20, 24, 26, 33, 36, 45, 57, 80, 82, 84, 87, 88, 90, 93, 95, 97, 99, 104, 105], "nullifi": 1, "relev": [1, 22, 99, 101, 104, 105], "distribut": [1, 9, 16, 21, 39, 82, 84, 87, 91, 93, 94, 95, 97, 101, 104, 105], "calcul": [1, 15, 30, 31, 35, 36, 37, 42, 43, 84, 88, 89, 93, 94, 97, 99, 100, 103], "bay": 1, "factor": [1, 29, 39, 42, 84, 85, 86, 87, 88, 89, 90, 91, 93, 99, 101, 104, 105], "turn": [1, 44, 80, 88, 90, 94, 104, 105], "ratio": [1, 46, 83, 88, 93, 104], "likelihood": [1, 22, 83, 93, 101], "now": [1, 29, 30, 31, 34, 36, 37, 38, 39, 41, 42, 43, 45, 46, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "compar": [1, 7, 29, 31, 34, 35, 37, 39, 40, 43, 57, 83, 85, 86, 88, 91, 93, 94, 97, 100, 102, 104], "p": [1, 14, 15, 17, 31, 36, 38, 40, 49, 53, 72, 76, 80, 83, 84, 88, 90, 91, 93, 96, 97, 101, 105], "valu": [1, 14, 15, 29, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 46, 49, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 103, 104, 105], "what": [1, 2, 3, 5, 8, 11, 13, 14, 16, 17, 18, 20, 22, 24, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 42, 43, 45, 72, 76, 80, 84, 85, 86, 87, 88, 90, 91, 92, 94, 96, 97, 98, 99, 100, 103, 104, 105], "kei": [1, 83, 88, 90, 93, 99], "differ": [1, 5, 6, 12, 16, 17, 22, 26, 28, 29, 30, 31, 34, 37, 40, 42, 79, 80, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 96, 98, 99, 100, 101, 103, 104, 105], "between": [1, 2, 10, 19, 25, 26, 28, 32, 33, 36, 37, 38, 39, 40, 41, 42, 45, 80, 83, 84, 85, 86, 87, 88, 91, 93, 96, 99, 100, 102, 103, 104, 105], "how": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51, 77, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105], "doe": [1, 2, 5, 7, 8, 9, 13, 15, 16, 20, 23, 24, 26, 27, 28, 29, 35, 37, 38, 39, 40, 42, 72, 80, 84, 88, 92, 93, 94, 99, 100, 102, 105], "impact": [1, 3, 6, 8, 11, 19, 23, 42, 83, 90, 91, 93, 96, 99], "interpret": [1, 2, 6, 8, 19, 31, 33, 34, 36, 42, 45, 83, 84, 88, 90, 91, 93, 97, 98, 103, 104], "result": [1, 20, 21, 25, 26, 30, 31, 32, 33, 35, 36, 37, 38, 40, 79, 80, 83, 84, 85, 86, 87, 88, 90, 92, 93, 96, 97, 99, 100, 102, 103, 105], "context": [1, 11, 16, 22, 30, 38, 83, 85, 86, 94, 96, 100, 104], "atom": [1, 14], "approach": [1, 5, 11, 14, 21, 37, 73, 93, 99, 104], "wasserstein": [1, 14, 63], "et": [1, 14, 23, 26, 84], "al": [1, 14, 23, 26, 84], "2019": [1, 9, 62, 63], "lectur": [1, 2, 5, 10, 13, 14, 25, 28, 44, 47, 84, 88, 89, 92, 93, 100, 101], "us": [1, 3, 4, 5, 10, 11, 14, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 60, 80, 83, 84, 87, 88, 90, 91, 93, 94, 96, 97, 98, 99, 103, 104, 105], "need": [1, 14, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 46, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105], "ar": [1, 3, 6, 8, 11, 14, 16, 17, 20, 21, 23, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105], "adopt": [1, 11, 16], "why": [1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 20, 28, 29, 30, 33, 34, 36, 38, 80, 84, 89, 90, 92, 93, 94, 99, 103], "other": [2, 6, 10, 21, 22, 23, 28, 29, 30, 34, 36, 42, 44, 80, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "than": [2, 6, 17, 30, 33, 36, 38, 42, 46, 83, 84, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104], "allow": [2, 43, 45, 46, 79, 80, 82, 84, 88, 95, 97, 98, 99, 100, 102, 104], "classifi": [2, 29, 30], "case": [2, 5, 10, 16, 17, 21, 25, 30, 31, 34, 35, 38, 80, 83, 84, 88, 89, 90, 91, 92, 93, 96, 97, 99, 100, 101, 102, 103, 104, 105], "y": [2, 7, 19, 28, 29, 32, 38, 39, 40, 42, 43, 45, 46, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 103, 104, 105], "ha": [2, 7, 30, 34, 38, 42, 45, 79, 82, 84, 85, 86, 87, 88, 89, 91, 93, 95, 98, 99, 101, 102, 103, 104, 105], "more": [2, 6, 16, 17, 18, 21, 23, 29, 30, 33, 36, 41, 42, 45, 79, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105], "two": [2, 7, 10, 16, 25, 30, 34, 37, 42, 45, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 105], "group": [2, 30, 83, 84, 85, 86, 91, 93, 103, 104], "advantag": [2, 11, 45, 84, 85, 86, 97, 99, 103], "do": [2, 5, 25, 29, 30, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 45, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 105], "lda": 2, "qda": 2, "over": [2, 11, 12, 17, 21, 22, 36, 38, 45, 46, 59, 83, 85, 86, 88, 89, 91, 92, 94, 97, 99, 100, 103, 105], "standard": [2, 3, 9, 31, 33, 35, 36, 39, 41, 83, 88, 90, 91, 93, 97, 103, 105], "logist": [2, 21, 30, 102], "regress": [2, 7, 12, 15, 21, 30, 39, 56, 60, 71, 83, 85, 86, 87, 91, 93, 97, 101, 102, 103], "when": [2, 8, 12, 15, 21, 25, 26, 31, 33, 35, 36, 38, 39, 40, 41, 43, 45, 79, 80, 82, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "would": [2, 4, 11, 12, 17, 21, 22, 27, 30, 36, 38, 42, 80, 83, 85, 86, 88, 89, 90, 91, 92, 93, 97, 98, 99, 102, 103, 105], "prefer": [2, 11, 12, 17, 21, 22, 92, 102], "The": [2, 4, 5, 10, 14, 15, 21, 22, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 45, 46, 53, 58, 59, 63, 75, 76, 79, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "went": [2, 84, 88, 92, 99, 105], "function": [2, 10, 22, 30, 31, 32, 33, 37, 38, 39, 41, 42, 43, 45, 75, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 100, 103, 104, 105], "defin": [2, 30, 35, 38, 79, 84, 85, 86, 89, 92, 93, 96, 97], "state": [2, 10, 15, 80, 85, 86, 93, 101], "transit": 2, "If": [2, 13, 24, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105], "fit": [2, 6, 17, 22, 28, 30, 31, 37, 42, 43, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 103, 104], "produc": [2, 38, 97], "shallow": 2, "slope": [2, 89, 91, 93, 101, 104, 105], "tell": [2, 37, 41, 80, 82, 84, 85, 86, 87, 88, 90, 95, 99, 101, 102, 103, 105], "about": [2, 3, 24, 28, 29, 30, 31, 34, 37, 42, 45, 46, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105], "relationship": [2, 10, 14, 19, 28, 33, 36, 37, 38, 40, 41, 45, 80, 84, 87, 88, 90, 97, 104, 105], "x": [2, 7, 19, 28, 29, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105], "specif": [2, 11, 16, 17, 19, 22, 24, 45, 46, 79, 83, 85, 86, 87, 89, 91, 92, 97, 99, 100, 105], "predictor": [2, 6, 19, 29, 34, 40, 43, 83, 84, 89, 90, 91, 94, 96, 98, 100], "variabl": [2, 6, 9, 12, 15, 18, 19, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 103, 104, 105], "g": [2, 10, 26, 28, 29, 34, 36, 41, 45, 50, 51, 52, 53, 54, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 77, 80, 84, 85, 86, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "x_1": [2, 89, 101], "cross": [3, 37, 38, 94, 96, 98], "valid": [3, 16, 24, 37, 79, 88, 94, 98, 105], "seen": [3, 104], "gold": 3, "estim": [3, 9, 11, 16, 31, 36, 38, 39, 84, 85, 86, 87, 88, 89, 90, 91, 93, 96, 97, 101, 103, 105], "generaliz": [3, 9, 58], "observ": [3, 10, 15, 29, 30, 31, 38, 39, 40, 41, 42, 84, 85, 86, 87, 88, 89, 91, 93, 94, 96, 97, 98, 99, 100, 101], "wai": [3, 5, 13, 20, 38, 41, 45, 80, 82, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104], "inform": [3, 17, 25, 26, 27, 31, 34, 40, 42, 45, 46, 62, 75, 79, 80, 83, 84, 85, 86, 88, 91, 92, 93, 94, 97, 98, 99, 102, 103, 105], "can": [3, 5, 7, 10, 13, 18, 19, 23, 25, 26, 28, 29, 30, 31, 33, 35, 36, 38, 40, 41, 42, 43, 45, 46, 77, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "leak": 3, "process": [3, 24, 25, 80, 93, 99], "": [3, 5, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 53, 72, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "risk": [3, 62, 97], "while": [3, 16, 42, 80, 84, 89, 90, 92, 93, 94, 96, 97, 99, 102, 103, 104], "larg": [3, 45, 88, 92, 93, 96, 100], "evalu": [3, 10, 14, 16, 22, 37, 38, 39, 42, 60, 83, 84, 88, 91, 94, 98, 99], "test": [3, 5, 7, 10, 14, 16, 22, 28, 30, 31, 38, 51, 77, 80, 82, 83, 84, 85, 86, 88, 90, 91, 92, 93, 94, 95, 99, 102], "error": [3, 5, 18, 28, 30, 31, 37, 38, 42, 43, 80, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 105], "measur": [3, 17, 21, 30, 32, 37, 39, 43, 83, 85, 86, 87, 91, 93, 94, 98, 99, 100, 104], "predict": [3, 10, 27, 30, 31, 37, 38, 39, 42, 80, 85, 86, 87, 88, 89, 90, 94, 96, 97, 98, 99], "accuraci": [3, 11, 29, 38, 42, 84, 85, 86, 88, 96, 100], "ask": [3, 29, 34, 41, 83, 93, 94, 97, 99, 102], "inferenti": [3, 91, 97], "data": [3, 4, 12, 13, 14, 19, 20, 21, 25, 26, 40, 45, 62, 76, 79, 82, 83, 84, 88, 89, 90, 91, 94, 95, 96, 97, 98, 101, 103, 105], "provid": [4, 5, 7, 10, 19, 20, 21, 22, 23, 24, 26, 27, 29, 31, 32, 33, 34, 37, 39, 41, 42, 43, 85, 86, 91, 92, 94, 99, 102, 104], "2": [4, 22, 44, 67, 70, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "hypothet": [4, 10, 19, 23, 25, 31], "exampl": [4, 5, 7, 10, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 79, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105], "dirti": 4, "aka": [4, 31, 93, 102], "tidi": [4, 31, 53, 93, 99, 100, 103], "tabl": [4, 19, 37, 41, 42, 80, 84, 87, 88, 98, 100, 105], "could": [4, 9, 11, 23, 31, 34, 38, 80, 84, 89, 90, 93, 94, 98, 99, 101, 103, 104], "hamper": 4, "analysi": [4, 25, 36, 38, 80, 83, 84, 90, 92, 97, 99, 102, 105], "concept": [4, 5, 21, 88, 89, 101, 102, 104], "link": [4, 31, 35, 41, 42, 44, 45, 82, 90, 95, 99, 102, 103, 104], "goal": [4, 24, 25, 36], "done": [4, 16, 82, 88, 90, 95, 98], "give": [4, 5, 17, 25, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 80, 84, 85, 86, 87, 93, 94, 96, 99, 100, 102, 103, 104, 105], "same": [4, 21, 26, 30, 31, 34, 36, 38, 40, 42, 46, 79, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 100, 101, 102, 103, 104], "one": [4, 10, 20, 22, 23, 25, 28, 33, 34, 35, 36, 38, 41, 45, 46, 79, 82, 83, 84, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105], "set": [4, 12, 16, 19, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 46, 80, 82, 83, 84, 87, 88, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 103, 104, 105], "anoth": [4, 27, 35, 45, 79, 83, 84, 91, 92, 99, 102, 104], "vice": 4, "versa": 4, "spreadsheet": 4, "text": [4, 46, 79, 80, 84, 92], "editor": 4, "show": [4, 5, 19, 26, 32, 37, 39, 40, 43, 45, 80, 82, 83, 84, 88, 89, 90, 93, 94, 95, 96, 98, 99, 100, 103, 104, 105], "breast": 5, "cancer": 5, "screen": [5, 102], "read": [5, 14, 25, 30, 32, 33, 36, 37, 39, 41, 43, 46, 47, 80, 85, 86, 89, 92, 93, 98, 99, 101, 102, 104], "evidentiari": 5, "existenti": 5, "method": [5, 7, 11, 12, 17, 21, 22, 29, 34, 36, 40, 41, 45, 46, 52, 57, 60, 68, 80, 85, 86, 89, 90, 91, 94, 97, 100, 101, 104, 105], "arriv": 5, "similar": [5, 21, 34, 79, 83, 85, 86, 89, 93, 94, 97, 99, 103, 105], "conclus": [5, 25, 26, 90], "mayo": [5, 54], "make": [5, 6, 10, 15, 26, 32, 37, 38, 39, 41, 43, 45, 46, 54, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "statist": [5, 7, 8, 10, 11, 13, 14, 16, 31, 37, 38, 41, 50, 52, 53, 54, 55, 56, 61, 64, 65, 66, 67, 70, 71, 82, 83, 84, 85, 86, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 104, 105], "better": [5, 9, 33, 34, 38, 80, 84, 90, 91, 93, 94, 99, 100, 102, 103, 104], "window": [5, 82, 95, 102, 105], "toward": [5, 9, 17, 62, 72, 83], "understand": [5, 14, 22, 24, 25, 28, 37, 43, 73, 80, 84, 85, 86, 89, 90, 92, 93, 94, 96, 101, 104], "bayesian": [5, 40, 83, 90, 93, 98], "studi": [5, 91, 93, 104], "guid": [5, 30, 92], "answer": [5, 7, 19, 24, 31, 43, 80, 83, 90, 93, 97, 99], "sever": [5, 80, 99, 102], "hypothesi": [5, 8, 10, 11, 14, 16, 25, 28, 75, 83, 91, 92, 97, 105], "relat": [5, 14, 28, 36, 37], "popper": [5, 59], "idea": [5, 10, 20, 80, 93, 101, 102, 103, 104], "falsifiabilti": 5, "In": [5, 13, 21, 22, 30, 31, 33, 35, 38, 40, 42, 43, 46, 59, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "thei": [5, 6, 14, 17, 29, 30, 34, 41, 46, 79, 80, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 102, 103, 104], "categor": [6, 29, 84, 99, 104], "4": [6, 7, 44, 50, 70, 77, 78, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 104, 105], "level": [6, 10, 27, 84, 88, 90, 96, 98, 99, 100, 103, 104, 105], "explain": [6, 10, 11, 16, 37, 38, 80, 87, 88, 94, 102, 103], "code": [6, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 98, 99, 102, 103, 104, 105], "3": [6, 44, 53, 55, 56, 57, 71, 75, 76, 78, 82, 83, 84, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105], "separ": [6, 30, 31, 38, 45, 89, 91, 92, 93, 96, 101, 103, 104, 105], "dummi": [6, 96], "binari": [6, 30, 42, 80, 84, 88, 99, 104], "sens": [6, 15, 83, 84, 85, 86, 89, 90, 94, 99, 101, 103, 104], "singl": [6, 14, 30, 43, 80, 82, 84, 85, 86, 87, 88, 89, 92, 95, 99, 102, 103], "outlier": [6, 38, 88], "high": [6, 10, 30, 37, 38, 51, 77, 84, 90, 100, 105], "leverag": [6, 84, 105], "point": [6, 16, 21, 35, 82, 84, 85, 86, 87, 89, 90, 92, 95, 98, 99, 100, 102, 103, 104, 105], "often": [6, 38, 47, 80, 89, 92, 97, 99, 102, 103, 104], "confus": [6, 29, 42, 84, 97, 100, 102], "each": [6, 7, 11, 14, 19, 22, 23, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 43, 45, 46, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105], "linear": [7, 21, 30, 31, 34, 42, 61, 64, 66, 71, 83, 84, 85, 86, 87, 90, 92, 96, 97, 99, 101, 104], "research": [7, 24, 29, 34, 41, 57, 60, 72, 80], "typic": [7, 89, 90, 93, 99, 100], "reserv": 7, "specialti": 7, "like": [7, 12, 17, 21, 29, 30, 32, 37, 38, 41, 46, 79, 80, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105], "t": [7, 29, 30, 31, 33, 34, 36, 37, 38, 40, 42, 45, 50, 52, 53, 55, 56, 58, 61, 64, 65, 66, 67, 70, 71, 72, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "anova": [7, 93], "For": [7, 38, 41, 44, 79, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105], "pearson": 7, "correl": [7, 12, 32, 39, 83, 84, 88, 90, 91, 94], "coeffici": [7, 15, 30, 31, 32, 38, 40, 43, 83, 84, 87, 88, 90, 91, 93, 96, 97, 99, 101, 105], "form": [7, 8, 13, 22, 27, 28, 33, 36, 43, 80, 82, 84, 89, 92, 93, 95, 97, 99, 101, 103, 104], "r": [7, 22, 29, 30, 31, 34, 35, 36, 40, 41, 43, 50, 51, 52, 53, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 70, 71, 72, 80, 83, 84, 85, 86, 88, 89, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "frac": [7, 31, 35, 83, 85, 86, 89, 92, 101], "cov": [7, 43, 84, 101], "std": [7, 83, 84, 88, 90, 91, 97, 105], "ordinari": [7, 97], "least": [7, 12, 20, 37, 96, 98], "squar": [7, 12, 31, 35, 37, 38, 43, 83, 85, 86, 88, 90, 91, 92, 96, 98, 105], "solut": [7, 15, 38, 43, 49, 93, 101], "hat": [7, 38, 39, 84, 88, 89, 97, 105], "beta": [7, 38, 40, 89, 96, 97, 99, 105], "quantit": [7, 27, 88, 94], "comparison": [7, 88, 91, 104], "explan": [7, 92, 101], "polynomi": [7, 85, 86], "still": [7, 29, 30, 37, 42, 82, 90, 91, 93, 94, 95, 99, 101], "meet": [7, 90], "assumpt": [7, 11, 16, 21, 90, 91, 97, 105], "normal": [7, 87, 89, 91, 93, 94, 101, 105], "justifi": [7, 21, 24], "against": [7, 16, 17, 32, 39, 83, 85, 86, 87], "follow": [8, 31, 38, 44, 46, 79, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 99, 102, 103, 104], "perform": [8, 29, 30, 32, 37, 39, 40, 42, 43, 84, 85, 86, 87, 89, 92, 93, 94, 96, 98, 102], "delai": 8, "discount": 8, "task": [8, 29, 32, 33, 39, 43, 90, 92, 101], "neg": [8, 30, 32, 83, 84, 90, 91, 97, 98, 99, 101], "childhood": 8, "poverti": 8, "onli": [8, 32, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 79, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 96, 98, 99, 100, 101, 103, 104, 105], "lack": [8, 24, 91, 93], "commun": [8, 20, 24, 26, 76, 80, 82, 88, 95, 102, 104], "resourc": [8, 43, 92, 102], "evid": [8, 83, 90, 93], "neglect": 8, "home": [8, 101, 102, 104], "influenc": [8, 39, 88], "amount": [8, 33, 36, 45, 80, 83, 84, 91, 94, 99, 104], "fund": 8, "place": [8, 89, 90, 103], "local": [8, 32, 37, 41, 44, 83, 84, 85, 88, 93, 96, 97, 101, 102, 105], "school": 8, "district": 8, "well": [8, 27, 29, 32, 34, 35, 38, 41, 46, 80, 84, 92, 93, 94, 97, 99, 100, 102, 103, 104], "ag": [8, 31, 33, 36, 88, 92, 99, 100, 104], "primari": [8, 45, 80], "caregiv": 8, "graphic": [8, 25, 26, 33, 75, 80, 92, 102, 103, 104], "mediat": [8, 10, 36], "moder": [8, 33], "causal": [8, 90], "exactli": [8, 9, 15, 37, 40, 80, 99, 100], "mean": [8, 30, 31, 32, 34, 35, 37, 41, 42, 43, 72, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104], "both": [8, 12, 29, 36, 37, 40, 41, 45, 79, 80, 82, 83, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 105], "outcom": [8, 16, 30, 84, 93, 98, 100], "infer": [8, 51, 59, 84, 89, 91], "random": [9, 30, 34, 37, 39, 40, 85, 86, 88, 91, 93, 94, 97, 100, 101], "mix": [9, 92], "involv": [9, 35, 89, 99], "varianc": [9, 12, 15, 18, 30, 32, 37, 80, 84, 85, 86, 89, 91, 94, 96, 100, 101], "gener": [9, 10, 29, 30, 33, 36, 38, 40, 45, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 99, 101, 102, 103, 104, 105], "eta": 9, "sim": [9, 88, 90, 93, 97], "n": [9, 15, 31, 35, 38, 40, 63, 72, 78, 84, 85, 86, 87, 88, 89, 93, 101], "0": [9, 29, 30, 33, 35, 36, 38, 39, 41, 42, 63, 74, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 103, 104, 105], "sigma_": [9, 93], "theta": [9, 88, 93], "step": [9, 14, 19, 82, 87, 88, 90, 92, 93, 95, 96, 99, 102, 104, 105], "necessari": [9, 46, 92, 93], "differenti": [9, 39, 42], "from": [9, 12, 15, 21, 24, 25, 26, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 54, 74, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105], "nuisanc": 9, "yarkoni": [9, 58, 72], "argu": [9, 14], "should": [9, 25, 26, 30, 36, 38, 43, 45, 80, 82, 83, 85, 86, 88, 90, 92, 94, 95, 96, 99, 102, 103], "practic": [9, 14, 23, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 46, 49, 60, 84, 85, 86, 87, 90, 91, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105], "increas": [9, 17, 18, 30, 33, 36, 38, 84, 85, 86, 88, 89, 91, 93, 96, 98, 101, 104], "find": [9, 25, 31, 37, 38, 43, 80, 83, 84, 87, 88, 89, 90, 91, 93, 96, 98, 99, 102, 103, 104], "psychologi": [9, 25, 27, 47, 80, 82, 90, 95], "neurosci": [9, 25, 27, 47, 72, 80, 82, 92, 95], "lead": [9, 16, 20, 23, 24, 26, 30, 85, 86, 92], "potenti": [9, 11, 19, 83], "harm": [9, 19], "falsifi": 10, "manner": [10, 14, 80], "unfalsifi": 10, "cannot": [10, 13, 92, 99], "guest": [10, 27, 59, 77], "martin": [10, 27, 59, 77], "act": [10, 85, 86, 89], "theori": [10, 13, 24, 25, 27, 51, 62, 78], "empir": [10, 16, 62, 97], "extend": 10, "distinguis": 10, "mechanist": 10, "system": [10, 30, 32, 41, 82, 89, 93, 94, 95, 102], "descript": [10, 22, 27, 32, 35, 37, 39, 43, 80, 92, 99, 101, 102, 105], "latter": [10, 104], "being": [10, 20, 25, 79, 80, 83, 84, 88, 89, 93, 97, 101, 103], "formal": [10, 33, 80, 84, 92, 101], "former": [10, 104], "less": [10, 30, 42, 79, 83, 84, 90, 93, 97], "abstract": 10, "artifici": [10, 59, 80], "neural": [10, 39, 59], "network": [10, 59], "illustr": [10, 19, 87, 88, 92, 99, 103], "work": [10, 12, 26, 29, 31, 35, 37, 38, 41, 42, 45, 76, 79, 80, 82, 84, 87, 92, 95, 97, 98, 99, 100, 105], "togeth": [10, 21, 37, 45, 82, 88, 89, 92, 93, 94, 95, 99, 101], "scientif": [10, 20, 24, 53, 59, 73, 80, 82, 90, 95], "mont": [11, 36, 60], "carlo": [11, 36, 60], "present": [11, 27, 29, 34, 41, 82, 93, 94, 95, 99, 102, 103], "strategi": [11, 57], "determin": [11, 16, 18, 27, 32, 33, 36, 37, 40, 42, 60, 80, 83, 84, 96, 98], "power": [11, 38, 79, 85, 86, 90, 96], "core": [11, 21, 80, 88], "bia": [11, 15, 17, 25, 32, 37, 85, 86, 91, 93, 96, 97, 98, 100], "either": [11, 40, 44, 84, 88, 89, 91, 99, 102, 104], "recov": [11, 38, 88, 92], "paramet": [11, 15, 17, 31, 36, 38, 43, 84, 88, 89, 92, 93, 96, 97, 104], "With": [11, 38, 93, 96, 99, 100], "clearli": [11, 84, 92, 99, 104], "some": [11, 16, 29, 30, 31, 35, 36, 40, 41, 43, 59, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 99, 100, 102, 103, 104, 105], "tradit": [11, 15, 83], "parametr": [11, 21, 97, 100], "mai": [11, 16, 17, 30, 36, 42, 84, 85, 86, 89, 91, 92, 93, 94, 97, 98, 102, 103, 104], "Be": [11, 17], "princip": [12, 88], "compon": [12, 31, 88, 92, 103, 104], "pcr": [12, 37, 94], "partial": 12, "pl": [12, 37, 94], "reduc": [12, 18, 30, 98, 103], "complex": [12, 17, 25, 38, 79, 83, 85, 86, 91, 92, 98, 99, 104], "account": [12, 17, 44, 91, 93, 98, 102], "across": [12, 36, 37, 87, 88, 91, 93, 94, 99, 104, 105], "ridg": [12, 15, 38], "which": [12, 15, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 79, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "also": [12, 29, 30, 36, 43, 45, 79, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105], "structur": [12, 20, 33, 38, 42, 53, 69, 79, 87, 88, 89, 93, 97, 99, 102, 103], "manag": [12, 80, 92, 102], "subset": [12, 17, 29, 34, 38, 41, 42, 46, 84, 85, 86, 88, 89, 94, 96, 97, 99, 103, 104], "stepwis": [12, 17], "select": [12, 17, 37, 38, 42, 61, 64, 82, 85, 86, 88, 93, 94, 95, 96, 97, 100, 102, 104, 105], "scienc": [13, 23, 24, 47, 51, 53, 54, 58, 62, 72, 76, 77, 78, 80, 82, 95], "correct": [13, 29, 80, 82, 84, 85, 86, 92, 95], "learn": [13, 28, 30, 31, 50, 52, 54, 55, 56, 61, 62, 64, 65, 66, 67, 70, 71, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "epistemolog": 13, "basi": 13, "known": [13, 21, 80, 92, 93], "impli": [13, 24], "we": [13, 21, 22, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "know": [13, 29, 31, 45, 80, 84, 88, 89, 90, 92, 99, 101, 102], "scientist": [13, 80], "articl": [14, 28], "limit": [14, 31, 38, 82, 85, 86, 92, 95, 97, 98, 103, 104], "whether": [14, 16, 29, 30, 33, 34, 36, 41, 79, 82, 83, 84, 88, 89, 90, 91, 93, 95, 98, 99, 100, 102, 103, 105], "prescrib": 14, "negat": 14, "all": [14, 22, 27, 29, 30, 31, 32, 36, 37, 39, 40, 41, 42, 43, 44, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105], "four": [14, 87, 94, 98, 99, 100, 103, 104, 105], "common": [14, 29, 34, 80, 92, 94, 99, 100, 102], "poor": [14, 30], "null": [14, 16, 83, 84, 91, 93, 96, 97, 105], "outlin": [14, 93], "problem": [14, 23, 28, 30, 38, 49, 59, 68, 82, 84, 88, 91, 92, 93, 95, 99, 102], "back": [14, 80, 88, 92, 99, 102, 104], "misconcept": 14, "report": [14, 32, 39, 40, 91, 94, 98], "individu": [15, 30, 31, 36, 45, 87, 88, 91, 93, 100, 103], "lasso": 15, "notion": 15, "tradeoff": [15, 32, 37, 91, 96], "number": [15, 17, 30, 31, 34, 35, 37, 38, 40, 41, 80, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 104], "exce": [15, 103], "uniqu": [15, 37, 38, 85, 86, 100, 104], "remov": [15, 32, 34, 35, 37, 39, 43, 80, 84, 88, 103, 104], "resolv": [15, 102], "A": [16, 29, 30, 34, 41, 49, 53, 57, 59, 60, 63, 72, 73, 75, 77, 78, 80, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 100, 102, 104, 105], "sell": 16, "permut": 16, "probabl": [16, 22, 30, 45, 46, 83, 84, 90, 92, 93, 97, 99, 100, 101], "assum": [16, 21, 84, 91, 102, 105], "shape": [16, 88, 89, 96, 98, 99, 100, 103, 104], "accur": [16, 27, 29, 34, 41, 93], "particular": [16, 30, 85, 86, 89, 92, 93, 96, 104, 105], "under": [16, 30, 84, 87, 93, 99, 102, 104], "But": [16, 30, 31, 45, 80, 84, 85, 86, 88, 89, 90, 91, 96, 97, 99, 101, 102, 103, 104, 105], "built": [16, 35, 79, 84, 88, 98, 99, 104, 105], "might": [16, 20, 31, 83, 84, 87, 89, 90, 91, 93, 97, 99, 100, 102], "reli": [16, 80, 88, 97], "resampl": [16, 52, 57, 85, 86, 97], "without": [16, 82, 90, 92, 94, 95, 96, 97, 99, 102, 104, 105], "replac": [16, 31, 89, 93, 96, 97, 99, 102], "bootstrap": [16, 85, 86, 90], "simpl": [16, 36, 45, 69, 72, 80, 84, 88, 90, 91, 93, 94, 96, 97, 101, 102, 104], "confid": [16, 32, 39, 83, 90, 93, 97, 104, 105], "sampl": [16, 35, 38, 60, 83, 85, 86, 88, 90, 94, 96, 97, 99, 100, 103, 105], "full": [17, 32, 37, 39, 43, 83, 84, 85, 86, 88, 93, 94, 98, 99, 102], "featur": [17, 36, 40, 88, 90, 96, 99], "due": [17, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 88, 91, 97, 103], "rel": [17, 74, 79, 82, 83, 85, 86, 90, 93, 95], "lower": [17, 84, 88, 89, 90, 91, 93, 99, 105], "comput": [17, 27, 32, 41, 44, 59, 69, 72, 77, 79, 80, 82, 83, 84, 92, 95, 102], "burden": 17, "dramat": [17, 83], "best": [17, 35, 37, 38, 42, 45, 80, 84, 85, 86, 87, 89, 91, 92, 94, 96, 99, 103, 104], "criterion": [17, 34, 36, 83, 91, 93, 96, 98], "aic": [17, 34, 84, 91, 93], "bic": [17, 40, 83, 93, 98], "meant": [17, 47, 104], "adjust": [17, 40, 42, 82, 83, 85, 86, 88, 90, 91, 95, 98, 105], "good": [17, 21, 31, 80, 88, 93, 94, 100, 102, 103, 104], "aris": [17, 84], "given": [17, 31, 35, 36, 82, 83, 84, 87, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101], "implement": [17, 26, 30, 40, 90, 91, 92, 93, 94, 96, 98, 99, 100, 102, 105], "perfect": [17, 100], "sort": [17, 88, 98, 103], "favor": [17, 83], "think": [17, 27, 33, 42, 45, 80, 84, 89, 90, 91, 92, 94, 100, 101, 102], "fewer": [17, 85, 86, 93, 103], "fundament": [18, 26, 59, 80, 99], "irreduc": [18, 89], "verbal": [18, 22, 80], "describ": [18, 23, 27, 32, 38, 39, 41, 53, 80, 84, 89, 90, 92, 93, 99, 100, 101, 102, 104], "dimension": [18, 37, 38, 88, 94, 98], "ad": [18, 36, 42, 85, 86, 87, 88, 89, 90, 93, 99, 103, 104], "flexibl": [18, 92, 96, 97, 104], "type": [19, 23, 37, 41, 44, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105], "anomali": [19, 41], "semant": [19, 93], "syntact": 19, "coverag": [19, 36, 93], "respons": [19, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 83, 84, 87, 89, 94, 99, 105], "take": [19, 31, 33, 35, 36, 37, 38, 42, 43, 45, 46, 80, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 97, 99, 100, 103, 104, 105], "cleans": 19, "pipelin": [19, 80, 92], "map": [19, 36, 42, 45, 46, 93, 103], "real": [19, 20, 21, 36, 43, 80, 84, 89, 93, 97, 105], "world": [19, 20, 44, 63, 80, 89, 104], "histor": 20, "failur": [20, 24], "import": [20, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 53, 74, 80, 83, 89, 90, 94, 100, 102], "discoveri": [20, 59], "recogn": 20, "get": [20, 29, 30, 31, 33, 36, 38, 39, 41, 43, 44, 45, 80, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 100, 101, 102, 103, 104, 105], "time": [20, 29, 30, 34, 36, 38, 39, 41, 42, 45, 46, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 99, 100, 102, 104], "wa": [20, 36, 84, 85, 86, 87, 90, 91, 93, 96, 98, 99, 100, 101], "made": [20, 25, 35, 44, 91, 96, 101, 102, 103], "central": [20, 102], "principl": [20, 89], "laid": 20, "out": [20, 33, 36, 38, 41, 43, 80, 87, 88, 92, 93, 94, 96, 97, 98, 99, 100, 102, 104], "mensch": 20, "kord": [20, 69], "2017": [20, 69, 72, 80], "ration": 20, "logic": [20, 59, 80, 90, 92, 99], "facilit": [20, 92], "stymi": 20, "knn": [21, 85, 86], "first": [21, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105], "non": [21, 42, 80, 83, 88, 93, 96, 97, 100, 105], "class": [21, 29, 31, 32, 34, 35, 37, 39, 41, 42, 43, 44, 45, 47, 80, 82, 84, 85, 86, 87, 88, 89, 90, 93, 95, 97, 98, 100, 102], "contrast": [21, 84, 88, 90, 96, 99, 102, 104], "befor": [21, 42, 51, 77, 80, 83, 84, 88, 89, 92, 93, 94, 99, 101, 102, 103, 104], "word": [21, 29, 33, 34, 35, 36, 41, 84, 90, 92, 93, 96, 97, 100, 102], "easi": [21, 45, 82, 85, 86, 88, 92, 95, 96, 99, 103, 104], "conceptu": [21, 99], "ideal": [21, 104], "start": [21, 31, 33, 35, 36, 41, 44, 46, 80, 83, 85, 86, 89, 91, 92, 93, 94, 96, 98, 102, 103, 105], "distanc": [21, 42, 84, 100], "closer": [21, 84, 88, 93, 103], "come": [21, 26, 31, 42, 88, 89, 92, 93, 99, 102, 104], "underli": [21, 37, 84, 88, 93], "break": [21, 23, 38, 80, 92, 97], "down": [21, 23, 30, 31, 33, 80, 84, 91, 93, 102, 104], "veri": [22, 30, 42, 79, 80, 84, 85, 86, 87, 88, 92, 93, 96, 99, 100, 102, 103], "plain": [22, 89, 101], "english": [22, 29, 34, 41, 80, 99], "sai": [22, 31, 80, 84, 88, 90, 93, 99, 100, 102], "gone": 22, "three": [22, 23, 34, 41, 83, 89, 91, 92, 93, 94, 99, 100, 101, 105], "metric": [22, 93, 94, 98], "rse": 22, "f": [22, 38, 57, 62, 80, 83, 88, 89, 90, 91, 92, 101, 105], "experi": [23, 33, 36, 53, 80, 91, 93, 97], "reproduc": [23, 72, 82, 95], "breakdown": [23, 93, 104], "open": [23, 44, 80, 82, 83, 92, 95, 99, 102], "propos": [23, 25, 27, 82, 95], "panacea": 23, "sandv": [23, 72], "2013": [23, 28, 50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 78, 84, 85, 86, 88, 94, 96, 97, 98, 100, 105], "hurt": 23, "field": [24, 80, 98], "intelligil": 24, "perfectli": 24, "accept": [24, 79, 84, 93, 105], "broader": 24, "detail": [24, 45, 88, 92, 93, 99, 103, 105], "loss": [24, 91], "theoret": 24, "develop": [24, 33, 80, 82, 92, 95, 102, 104], "contextu": [24, 73, 90], "social": 24, "reliabl": [24, 92], "problemat": [24, 80, 102], "yanai": [25, 75], "lercher": [25, 75], "2020": [25, 27, 75], "narrowli": 25, "focus": [25, 85, 86, 90, 93, 94, 98, 100, 101], "hypothes": [25, 83, 97], "miss": [25, 29, 30, 34, 35, 41, 80, 92, 94, 98, 99, 103], "meaning": [25, 80, 91, 92], "pattern": [25, 37, 39, 79, 80, 97, 99, 104], "reconcil": 25, "driven": [25, 105], "encod": 25, "unstructur": 25, "via": [25, 31, 35, 36, 41, 44, 45, 85, 86, 97, 102], "visual": [25, 26, 41, 45, 46, 53, 80, 82, 83, 88, 90, 93, 94, 95, 99, 100, 101, 103, 105], "knowledg": [25, 26, 62, 80], "extract": [25, 31, 37, 84, 87, 88, 93, 97, 99, 102, 105], "reader": 25, "decod": 25, "paper": [25, 69, 82, 95], "recent": [25, 102], "analyz": [25, 36, 93, 103], "along": [25, 80, 82, 88, 89, 94, 95, 100, 101, 104, 105], "six": [25, 98, 99], "compet": [25, 83], "dimens": [25, 30, 37, 42, 84, 88, 89, 94, 98, 104, 105], "cairo": [25, 26, 75], "intellig": [25, 80], "There": [26, 41, 45, 79, 84, 87, 88, 90, 92, 93, 94, 99, 100, 102, 103, 104], "tension": 26, "most": [26, 42, 79, 80, 84, 89, 90, 92, 93, 94, 98, 99, 100, 101, 102, 104], "constraint": [26, 38], "human": [26, 32, 37, 39, 43], "percept": 26, "franconeri": [26, 76], "conflict": [26, 88, 102], "explicit": [26, 89, 103], "colleagu": [26, 102], "frame": [26, 30, 31, 32, 36, 37, 38, 39, 42, 43, 45, 80, 83, 84, 87, 88, 91, 93, 94, 98, 100, 101, 103, 104, 105], "choic": [26, 40, 91, 93, 98], "highlight": [26, 104], "annot": 26, "scale": [26, 37, 42, 45, 91, 94, 98, 100, 105], "balanc": [26, 31, 80], "plot": [26, 29, 33, 37, 38, 39, 40, 80, 82, 83, 84, 85, 86, 87, 88, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101], "bias": [26, 93], "viewer": 26, "incorrect": [26, 29, 91, 100], "interpet": [26, 88], "pizza": [27, 90], "deal": [27, 89, 90, 98, 99, 102, 103], "scenario": [27, 99], "intuit": [27, 37, 38, 94], "incorrectli": [27, 29, 30, 100], "someth": [27, 32, 41, 80, 84, 88, 92, 99, 101, 104], "van": [27, 51, 77], "rooij": [27, 51, 77], "baggio": [27, 51, 77], "claim": 27, "capac": [27, 37, 88, 90, 103, 105], "definit": [27, 46, 80, 84, 92, 93, 101], "hint": [27, 29, 31, 33, 35, 37, 38, 39, 41, 42, 43, 45, 46], "marr": 27, "analys": [27, 32, 82, 83, 95, 99, 102], "distinct": [28, 104], "h": [28, 29, 34, 41, 53, 68, 73, 89, 101], "learner": [28, 90], "affect": [28, 91, 93, 102], "accord": [28, 40, 84, 88, 98, 101, 103], "pac": 28, "valiant": 28, "1984": 28, "desrib": 28, "fulop": [28, 78], "chater": [28, 78], "learnabl": 28, "below": [28, 29, 30, 31, 33, 35, 36, 38, 40, 42, 43, 44, 45, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 97, 98, 99, 102, 103, 104], "delta": [28, 85, 86, 93], "train": [28, 30, 38, 39, 84, 85, 86, 88, 94, 96, 100, 105], "epsilon": [28, 40, 84, 88, 89, 93], "neq": [28, 101], "precis": [28, 36, 93], "criteron": 28, "evalaut": 28, "homework": [29, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 82, 89, 95, 101], "assign": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 84, 87, 88, 90, 92, 99, 103], "design": [29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 80, 85, 86, 90, 91, 92, 93, 102], "ll": [29, 30, 31, 33, 35, 41, 42, 43, 46, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "try": [29, 31, 38, 39, 42, 43, 45, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 98, 99, 100, 101, 102, 104, 105], "respond": [29, 41, 93], "correctli": [29, 30, 83, 93], "dure": [29, 82, 84, 90, 95, 97, 104], "lexic": [29, 93], "decis": [29, 80, 93], "base": [29, 32, 36, 38, 42, 82, 89, 93, 95, 100, 101, 103, 105], "length": [29, 34, 35, 38, 40, 83, 87, 88, 90, 94, 96, 98, 99, 100, 105], "frequenc": [29, 34, 80, 84], "lexicon": [29, 34, 41], "project": [29, 32, 34, 37, 39, 41, 43, 80, 82, 92, 95, 102], "again": [29, 31, 34, 40, 42, 43, 45, 79, 85, 86, 93, 94, 98, 99, 100, 101, 102, 104], "howev": [29, 36, 45, 80, 84, 89, 92, 93, 94, 97, 98, 99, 100, 102, 103], "our": [29, 30, 31, 35, 36, 38, 40, 42, 45, 46, 84, 85, 86, 88, 89, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "depend": [29, 79, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 103, 105], "lexicaldata_withincorrect": 29, "csv": [29, 32, 34, 37, 39, 41, 43, 80, 102], "includ": [29, 30, 31, 34, 37, 40, 46, 79, 80, 82, 83, 84, 87, 88, 89, 90, 91, 95, 96, 97, 98, 99, 100, 102, 103, 104], "trial": [29, 41], "ones": [29, 43, 89, 97, 100], "item": [29, 34, 85, 86, 92, 93], "found": [29, 83, 92, 99], "lexdat": [29, 32, 34, 41], "folder": [29, 32, 34, 37, 39, 41, 43, 80, 99, 102, 104], "github": [29, 31, 32, 34, 35, 37, 39, 40, 41, 43, 45, 92, 99], "repositori": [29, 31, 32, 34, 35, 37, 39, 41, 43, 44, 45], "databas": [29, 32, 34, 37, 39, 41, 43, 99], "It": [29, 32, 33, 34, 37, 39, 41, 42, 43, 45, 46, 79, 80, 83, 84, 88, 89, 92, 93, 94, 99, 100, 102, 103, 104], "reaction": [29, 34, 41, 83, 91, 93], "millisecond": [29, 34, 41], "mani": [29, 33, 34, 36, 37, 41, 42, 79, 80, 83, 85, 86, 89, 92, 93, 96, 98, 99, 100, 102, 103, 104], "subject": [29, 32, 34, 39, 41, 43, 83, 87, 91, 99], "letter": [29, 34, 41, 92, 102], "string": [29, 34, 41, 92, 93, 102], "decid": [29, 34, 41, 80, 83, 102], "quickli": [29, 34, 41, 102, 104], "possibl": [29, 34, 41, 83, 84, 87, 92, 93, 104], "characterist": [29, 34, 105], "name": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 79, 83, 87, 88, 90, 91, 92, 96, 97, 98, 99, 102, 103, 104, 105], "courtesi": [29, 34, 41, 89], "balota": [29, 34, 41], "d": [29, 34, 36, 38, 41, 50, 52, 53, 54, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 73, 79, 80, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 105], "yap": [29, 34, 41], "m": [29, 34, 35, 41, 58, 62, 72, 75, 76, 80, 88, 89, 90, 91, 93, 94, 99, 102, 103], "j": [29, 34, 38, 41, 49, 51, 53, 57, 68, 72, 76, 89], "cortes": [29, 34, 41], "hutchison": [29, 34, 41], "k": [29, 34, 38, 41, 42, 53, 57, 59, 69, 72, 88], "kessler": [29, 34, 41], "b": [29, 33, 34, 37, 38, 39, 40, 41, 43, 69, 72, 88, 89, 91, 92, 94, 102], "lofti": [29, 34, 41], "neeli": [29, 34, 41], "nelson": [29, 34, 41], "l": [29, 34, 41, 63, 76, 88, 101, 102], "simpson": [29, 34, 41], "treiman": [29, 34, 41], "2007": [29, 34, 41, 49], "behavior": [29, 34, 38, 41, 57, 58, 59, 62, 92, 104], "39": [29, 34, 41, 85, 86, 94, 97], "445": [29, 34, 41], "459": [29, 34, 41], "file": [29, 32, 34, 37, 39, 41, 43, 80, 82, 92, 95], "left_join": [29, 34, 99], "add": [29, 30, 34, 35, 36, 42, 44, 45, 46, 79, 80, 82, 87, 89, 90, 93, 95, 99, 100, 101, 102, 103, 104, 105], "log_freq_h": [29, 34], "lexicaldata": [29, 34], "drop_na": [29, 94], "rid": [29, 41, 94, 96, 99], "ani": [29, 31, 33, 34, 36, 37, 38, 40, 79, 87, 89, 92, 93, 96, 97, 98, 99, 100, 102, 103, 105], "Then": [29, 30, 31, 42, 43, 82, 84, 87, 90, 93, 95, 96, 99, 101, 102], "head": [29, 32, 33, 36, 37, 39, 41, 42, 43, 80, 82, 83, 84, 87, 89, 91, 93, 94, 95, 99, 100, 101, 104], "look": [29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 79, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "few": [29, 30, 31, 32, 37, 39, 41, 42, 43, 45, 88, 89, 92, 93, 96, 98, 99, 100, 101], "row": [29, 30, 31, 32, 37, 39, 41, 42, 43, 45, 80, 83, 84, 87, 88, 89, 92, 93, 96, 97, 98, 100, 103, 104, 105], "note": [29, 30, 34, 35, 36, 38, 39, 40, 42, 43, 44, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105], "re": [29, 30, 33, 34, 36, 41, 43, 45, 80, 82, 83, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104], "just": [29, 30, 31, 33, 36, 38, 42, 46, 80, 84, 87, 88, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 105], "so": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105], "worri": [29, 34, 87, 98, 99, 105], "reformat": 29, "write": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 79, 80, 82, 88, 91, 95, 97, 99, 101, 103], "here": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105], "versu": [29, 42, 90, 99], "term": [29, 31, 33, 34, 36, 39, 42, 87, 88, 90, 91, 92, 93, 96, 98, 101], "log": [29, 30, 34, 101, 102, 103], "doesn": [29, 40, 79, 82, 84, 89, 91, 92, 94, 95, 99, 100, 101, 102, 104], "too": [29, 80, 84, 85, 86, 88, 92, 93, 94, 100, 103], "cumbersom": [29, 99], "chang": [29, 30, 32, 33, 36, 38, 41, 45, 46, 80, 83, 84, 85, 86, 88, 90, 91, 93, 96, 99, 100, 101, 103], "run": [29, 30, 32, 36, 39, 41, 42, 79, 80, 82, 83, 84, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 102], "output": [29, 30, 34, 36, 38, 40, 41, 42, 53, 79, 83, 84, 85, 86, 88, 90, 92, 93, 94, 97, 98, 99, 105], "vrequir": 29, "tidyvers": [29, 30, 32, 33, 37, 38, 39, 42, 43, 46, 83, 85, 86, 87, 88, 90, 92, 93, 94, 98, 100, 101, 103, 104], "packag": [29, 30, 34, 42, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105], "haven": [29, 84, 88, 91, 96, 98], "yet": [29, 84, 98, 99, 102], "fdata": 29, "numer": [29, 41, 84, 87, 88, 92, 99, 101], "cluster": [29, 45, 84, 88, 91, 94, 100, 105], "ggplot": [29, 32, 37, 38, 42, 46, 80, 84, 85, 86, 87, 88, 90, 91, 93, 94, 98, 99, 100, 101, 103, 104, 105], "ae": [29, 45, 46, 80, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 98, 99, 100, 101, 103, 104, 105], "round": [29, 87, 90, 99, 103, 105], "col": [29, 80, 88, 92, 94, 98, 99, 100, 103], "geom_point": [29, 45, 80, 84, 85, 86, 90, 91, 93, 94, 98, 99, 100, 103, 104, 105], "posit": [29, 30, 32, 41, 83, 84, 90, 92, 93, 104, 105], "jitter": 29, "alpha": [29, 36, 45, 84, 96, 103, 104], "theme_light": [29, 94, 98], "repons": 29, "interact": [29, 34, 47, 83, 88, 90], "glm": [29, 85, 86, 88, 96], "its": [29, 38, 46, 79, 80, 82, 83, 84, 89, 92, 93, 95, 99, 101, 105], "summari": [29, 32, 33, 34, 37, 40, 41, 83, 84, 88, 90, 91, 93, 94, 97, 98, 99, 103, 105], "conclud": [29, 32, 36], "brief": [29, 89, 92], "gist": 29, "fine": [29, 102], "final": [29, 30, 31, 36, 42, 82, 92, 94, 95, 96, 99, 101, 102, 104], "threshold": [29, 38, 39, 84, 93, 96], "matrix": [29, 36, 37, 38, 42, 83, 84, 88, 93, 94, 96, 97, 98, 100], "overal": [29, 30, 42, 84, 93, 99, 104], "see": [29, 30, 31, 32, 33, 35, 37, 38, 41, 42, 43, 44, 45, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "tutori": [29, 30, 31, 33, 35, 36, 37, 44], "did": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 80, 84, 85, 86, 93, 96, 99, 100, 102, 104], "mass": [29, 84, 88, 90, 105], "librari": [29, 31, 33, 34, 36, 37, 38, 41, 42, 80, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "ran": 29, "actual": [29, 30, 31, 36, 40, 42, 43, 45, 84, 89, 91, 92, 93, 96, 99, 100, 101, 102, 104, 105], "whole": [29, 84, 94, 99, 101, 103], "5pm": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "est": [29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 93], "march": [29, 30, 34, 39, 42], "11": [29, 35, 83, 87, 88, 89, 90, 94, 98, 99, 100, 102], "2024": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46], "collabor": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 102], "anyon": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 82, 95], "list": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 83, 84, 85, 86, 87, 88, 92, 93, 98, 102, 105], "someon": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46], "techniqu": [30, 40, 90], "fold": [30, 89, 94, 96], "pimaindiansdiabetes2": 30, "dataset": [30, 31, 32, 40, 42, 45, 46, 80, 83, 84, 85, 86, 87, 88, 90, 93, 94, 96, 97, 98, 99, 100, 103, 104], "medic": 30, "pima": 30, "nativ": [30, 82, 95], "american": [30, 63], "women": 30, "diabet": [30, 42], "part": [30, 33, 36, 40, 42, 43, 80, 84, 88, 98, 99, 100, 102, 104], "mlbench": 30, "person": [30, 90, 99, 102, 103], "histori": 30, "been": [30, 84, 88, 89, 93, 101, 102], "diagnos": 30, "load": [30, 33, 36, 38, 40, 42, 43, 45, 46, 80, 83, 84, 85, 86, 88, 91, 93, 94, 96, 97, 98, 99, 101, 103, 104, 105], "boot": [30, 85, 86, 90, 97], "instal": [30, 31, 34, 37, 45, 80, 83, 84, 85, 86, 88, 90, 91, 93, 94, 96, 97, 98, 99, 100, 102, 104, 105], "drop": [30, 31, 37, 85, 86, 91, 93, 99], "insulin": 30, "column": [30, 31, 37, 42, 80, 83, 84, 87, 88, 89, 92, 93, 96, 98, 100, 104, 105], "lot": [30, 80, 82, 88, 92, 93, 95, 98, 99, 100, 101, 102, 103, 104], "na": [30, 32, 35, 36, 37, 38, 39, 42, 43, 88, 93, 96, 97, 98, 99], "rest": [30, 42, 79, 80, 84, 99, 105], "save": [30, 31, 35, 41, 44, 45, 80, 85, 86, 87, 92, 93, 99, 102], "updat": [30, 42, 47, 80, 88], "new": [30, 32, 35, 37, 39, 40, 41, 42, 43, 44, 50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72, 75, 80, 82, 84, 87, 88, 90, 93, 94, 95, 96, 97, 98, 100, 103], "print": [30, 33, 36, 40, 42, 79, 84, 85, 86, 87, 89, 91, 92, 93, 96, 97, 98, 99, 100, 102, 105], "line": [30, 32, 38, 41, 42, 43, 45, 46, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 98, 99, 101, 102, 103, 104, 105], "insert": [30, 31, 32, 41, 42, 45, 46, 79, 103], "pedigre": 30, "refer": [30, 46, 79, 82, 89, 95, 99, 101, 102, 103], "famili": [30, 84, 99], "condit": [30, 83, 93], "higher": [30, 38, 83, 84, 85, 86, 90, 94, 103], "greater": [30, 42, 85, 86, 88, 93], "manual": [30, 80, 83, 93, 98, 99, 102, 103], "past": [30, 40, 84, 85, 86, 92, 99, 100], "let": [30, 31, 37, 38, 41, 42, 43, 45, 46, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105], "dichotom": 30, "modifi": [30, 35, 38, 45, 104], "except": [30, 85, 86, 89, 98], "holdout": 30, "rememb": [30, 31, 38, 84, 88, 91, 92, 94, 96, 97, 99, 100, 101, 102, 103, 105], "odd": 30, "50": [30, 33, 36, 38, 42, 84, 93, 94, 96, 99, 100], "abov": [30, 31, 32, 34, 35, 36, 38, 41, 42, 43, 44, 45, 46, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104], "iter": [30, 39, 84, 88, 89, 96, 97, 99], "loocv": 30, "531": [30, 88], "last": [30, 36, 38, 46, 84, 88, 89, 90, 92, 99, 101, 102], "loop": [30, 36, 38, 85, 86, 88, 92, 93, 97, 99], "through": [30, 88, 89, 90, 92, 100, 101, 102, 103], "thing": [30, 36, 41, 43, 80, 82, 83, 85, 86, 87, 88, 89, 93, 94, 95, 98, 99, 100, 102, 103], "creat": [30, 31, 37, 42, 44, 45, 46, 82, 84, 85, 86, 87, 88, 89, 92, 93, 95, 96, 102, 103, 104, 105], "hold": [30, 90, 96, 99], "true": [30, 37, 83, 85, 86, 87, 88, 90, 92, 93, 94, 96, 97, 98, 99, 100, 104], "classif": [30, 50, 70, 84, 100], "fill": [30, 36, 80, 89, 97, 99, 103, 104], "store": [30, 31, 36, 42, 79, 87, 88, 89, 93, 97, 99, 102], "pull": [30, 31, 36, 99, 100, 101], "remain": [30, 92, 94, 99], "po": [30, 104], "datafram": [30, 32, 37, 39, 42, 43, 87, 93, 96, 99, 100, 103, 105], "after": [30, 43, 82, 83, 85, 86, 88, 91, 93, 94, 95, 99, 101, 102, 103], "initi": [30, 36, 42, 85, 86, 89, 99, 102, 103, 104, 105], "nrow": [30, 36, 38, 84, 85, 86, 88, 89, 93, 94, 96, 97, 99, 100, 103], "dat": [30, 33, 36, 87, 93, 94, 99, 100], "don": [30, 31, 36, 37, 42, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 102, 104, 105], "forget": [30, 37], "proport": [30, 82, 90, 93, 95], "were": [30, 36, 41, 83, 91, 93, 94, 97, 98, 99, 100, 102, 104], "diagnosi": [30, 42], "becaus": [30, 31, 38, 42, 80, 82, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 98, 99, 100, 101, 102, 103], "cost": [30, 42, 85, 86], "argument": [30, 35, 42, 83, 92, 93, 99, 103], "doc": [30, 79], "vector": [30, 31, 35, 36, 38, 40, 82, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98], "specifi": [30, 46, 85, 86, 87, 89, 93, 96, 99, 101, 102, 103, 104], "correspond": [30, 84, 87, 88, 89, 93, 99, 102], "second": [30, 41, 85, 86, 89, 90, 91, 93, 94, 97, 98, 99, 100, 101, 103], "scroll": 30, "bottom": [30, 84, 88, 90, 92, 98, 99, 102], "appropri": [30, 39, 80, 102, 104], "pi": [30, 89, 101], "ab": 30, "5": [30, 35, 38, 44, 49, 52, 65, 72, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105], "technic": [30, 89, 96, 98, 99], "treat": [30, 90, 91, 101, 104], "hood": 30, "thu": [30, 80, 84, 85, 86, 88, 90, 91, 92, 93, 96, 98, 99, 100, 101, 103], "boil": [30, 31, 80, 91, 92, 104], "recal": [30, 38, 99], "drawback": [30, 85, 86], "quit": [30, 91, 93, 94, 99, 100], "10": [30, 31, 33, 35, 36, 38, 40, 53, 72, 80, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 105], "15": [30, 37, 59, 80, 83, 88, 89, 91, 92, 93, 94, 98, 99, 100], "seed": [30, 37, 38, 40, 42, 85, 86, 88, 93, 94, 96, 97, 100], "slightli": [30, 84, 88], "expect": [30, 31, 45, 46, 83, 88, 91, 93, 97], "25": [30, 46, 80, 83, 85, 86, 90, 91, 99, 101, 104], "These": [31, 80, 85, 86, 89, 91, 92, 97, 99, 104, 105], "comfort": [31, 41, 45, 84, 89, 99, 101, 102, 105], "credit": 31, "islr": [31, 84, 85, 86, 88, 94, 96, 97, 98, 100], "simul": [31, 40, 87, 90, 99], "demograph": [31, 100], "000": [31, 40, 42, 103], "custom": [31, 82, 95, 99], "nice": [31, 46, 84, 101], "card": 31, "owner": 31, "rate": [31, 42, 85, 86, 91, 100, 103, 104], "gender": [31, 32, 39, 80], "student": [31, 90, 92], "statu": [31, 93, 102], "cred_lm": 31, "lm": [31, 32, 43, 83, 85, 86, 87, 88, 90, 91, 97, 98, 99, 105], "residu": [31, 83, 84, 87, 88, 90, 91, 99, 105], "sigma": [31, 89, 93, 101], "195": [31, 105], "9": [31, 35, 38, 53, 69, 72, 80, 82, 83, 86, 88, 89, 91, 92, 93, 94, 95, 98, 99, 100, 102, 104, 105], "directli": [31, 79, 80, 83, 84, 98, 99, 102, 103], "sqrt": [31, 35, 99, 101], "sse": 31, "sum": [31, 84, 88, 92, 94, 96, 97, 98, 100, 101], "intercept": [31, 33, 34, 40, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 104, 105], "denomin": [31, 83, 101], "degre": [31, 38, 46, 83, 84, 85, 86, 88, 90, 91, 105], "freedom": [31, 83, 84, 88, 90, 91, 105], "ve": [31, 43, 82, 83, 85, 86, 88, 89, 90, 94, 95, 98, 99, 100, 101, 102], "realli": [31, 88, 92, 96, 99, 102, 103, 104], "oper": [31, 35, 41, 82, 90, 92, 95, 102], "easili": [31, 45, 80, 87, 92, 99, 102, 104, 105], "appli": [31, 37, 80, 83, 89, 94, 99, 101, 103, 104, 105], "element": [31, 40, 45, 89, 92, 93, 103, 104], "combin": [31, 33, 38, 90, 92, 93, 94, 102, 103, 104], "return": [31, 35, 36, 84, 87, 88, 89, 92, 93, 96, 97, 102, 103, 104, 105], "your_funct": 31, "own": [31, 35, 40, 46, 82, 84, 88, 92, 93, 95, 97, 102, 103], "want": [31, 35, 36, 37, 39, 41, 45, 46, 80, 83, 84, 85, 86, 87, 88, 89, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "entir": [31, 79, 88, 90, 100], "u": [31, 41, 42, 43, 45, 84, 85, 86, 88, 89, 90, 93, 94, 99, 101, 103, 105], "mayb": [31, 42, 90], "public": [31, 76, 91], "saw": [31, 99, 100, 103], "str": [31, 83, 87], "won": [31, 33, 36, 38, 40, 85, 86, 89, 90, 99, 105], "That": [31, 41, 80, 87, 89, 99, 101, 102], "itself": [31, 84, 92], "right": [31, 37, 80, 82, 84, 85, 86, 88, 89, 92, 95, 98, 99, 101, 102, 104], "further": [31, 89], "interest": [31, 38, 45, 76, 83, 90, 91, 93, 97, 99, 102], "se": [31, 80, 85, 86, 90, 91, 93, 104, 105], "alter": 31, "minu": [31, 41, 101], "finish": [31, 35, 41, 45, 99, 102], "notebook": [31, 35, 40, 41, 43, 44, 45, 79, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "exercise3": 31, "ipynb": [31, 35, 41, 44, 45, 79], "push": [31, 35, 41, 44, 45, 87, 102], "send": [31, 35, 41, 45, 99], "instructor": [31, 35, 41, 44, 45, 82, 95], "canva": [31, 35, 41, 44, 45], "messag": [31, 35, 80, 88, 92, 93, 102, 103, 104], "click": [31, 35, 43, 102], "inbox": [31, 35], "left": [31, 35, 37, 45, 84, 85, 86, 90, 92, 99, 101, 102, 104], "press": [31, 35], "icon": [31, 35], "pencil": [31, 35], "insid": [31, 35, 79, 89, 92, 101, 102], "feb": [31, 35, 41, 43, 45, 46], "7": [31, 35, 44, 83, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 103, 104], "download": [32, 37, 39, 41, 80, 82, 95, 99, 102, 104], "unrestricted_trimmed_1_7_2020_10_50_44": [32, 37, 39, 43], "hcp_data": [32, 37, 39, 43], "portion": [32, 37, 39, 42, 43, 89], "connectom": [32, 37, 39, 43], "cognit": [32, 37, 39, 43, 72, 78], "brain": [32, 37, 39, 43, 53, 58, 59, 62], "morphologi": [32, 37, 39, 43], "measures": [32, 37, 39], "1206": [32, 37, 39, 43], "particip": [32, 36, 37, 39, 43, 83, 91, 93, 99], "hcp_s1200_datadictionary_april_20_2018": [32, 37, 39, 43], "setwd": [32, 39, 41, 43], "tool": [32, 37, 39, 43, 79, 80, 82, 84, 85, 86, 89, 91, 93, 94, 95, 99, 101, 102, 103, 105], "d1": [32, 37, 39, 43], "inclu": [32, 39, 43], "id": [32, 34, 39, 41, 43, 83, 92, 93, 99, 104], "flanker": [32, 39, 43], "flanker_unadj": [32, 37, 39, 43], "total": [32, 38, 39, 43, 84, 90, 93, 99], "white": [32, 39, 103], "matter": [32, 43, 89, 94, 99, 101], "volum": [32, 37, 39, 43, 84], "fs_tot_wm_vol": [32, 39], "grei": [32, 43], "fs_total_gm_vol": [32, 39, 43], "wet": [32, 41], "workign": [32, 41], "directori": [32, 41, 82, 95, 102], "locat": [32, 41, 45, 88, 90, 92, 99, 105], "harddriv": [32, 41], "uncom": [32, 41, 83, 84, 85, 86, 88, 90, 91, 94, 96, 97, 98, 99, 105], "document": [32, 35, 41, 79, 80, 82, 88, 91, 93, 95, 102], "pittcmu": [32, 41], "g3": [32, 41], "dspn": [32, 41], "datasciencepsychneuro": [32, 41], "colab": [32, 41, 105], "gdown": [32, 41], "1hywrmgdvhbdytrqryl1_bljsq": 32, "t3gjq2": 32, "pair": [32, 83, 87, 97, 105], "pairwis": [32, 84], "scatterplot": [32, 42, 45, 80, 88, 103, 105], "seem": [32, 84, 88, 91, 92, 93, 94, 100, 104], "associ": [32, 39, 40, 79, 82, 88, 91, 93, 95, 97, 99, 104, 105], "y_": [32, 84, 88], "beta_0": [32, 40, 43, 84, 88, 101, 105], "beta_1": [32, 40, 43, 84, 88, 101, 105], "x_": [32, 84, 88, 89, 100], "gm": 32, "coef": [32, 85, 86, 87, 93, 96, 97, 99, 105], "95": [32, 37, 83, 87, 89, 90, 93, 94, 99, 104, 105], "interv": [32, 39, 83, 90, 93, 97, 103, 104, 105], "confint": [32, 105], "significantli": [32, 83, 90, 93], "axi": [32, 39, 45, 46, 80, 103, 104], "regrssion": 32, "qualit": [32, 38, 96, 97, 100], "februari": [32, 90], "26": [32, 91, 94, 99], "instead": [33, 41, 45, 46, 80, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 103, 104], "go": [33, 34, 36, 37, 38, 43, 80, 82, 84, 90, 92, 93, 95, 97, 99, 102, 104, 105], "comprehens": [33, 36, 93, 102, 105], "skill": [33, 36, 90], "older": 33, "children": [33, 36, 104], "tend": [33, 90], "isn": [33, 34, 45, 83, 84, 85, 86, 89, 103], "inher": 33, "gain": [33, 42], "oral": 33, "languag": [33, 79, 87, 89, 90, 92, 99, 101, 102], "execut": [33, 82, 88, 92, 95, 99, 105], "though": [33, 82, 83, 84, 88, 89, 90, 91, 92, 95, 101], "simplifi": [33, 43, 89, 94, 101], "direct": [33, 36, 83, 84, 90, 92, 94], "sinc": [33, 34, 36, 83, 84, 85, 86, 89, 90, 91, 92, 94, 97, 98, 99, 100, 101, 103, 105], "improv": [33, 36, 42, 46, 85, 86, 90, 93, 96, 104], "guarante": 33, "beta_": [33, 84, 93], "xa": 33, "x0": 33, "epsilon_": [33, 93], "c": [33, 35, 36, 37, 38, 40, 43, 53, 68, 80, 82, 83, 84, 85, 86, 88, 89, 90, 92, 93, 95, 98, 99, 100, 101, 102, 104, 105], "ca": 33, "cx": [33, 101], "c0": 33, "epsilon_c": [33, 36], "respect": [33, 43, 85, 86, 93, 94, 99, 101], "formula": [33, 35, 43, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 98, 104, 105], "gaussian": [33, 36], "nois": [33, 36, 40, 87, 88, 93], "simulate_data": [33, 36, 93], "input": [33, 79, 85, 86, 87, 88, 92, 93, 94, 97, 99, 100, 101, 104, 105], "complet": [33, 89], "those": [33, 40, 79, 85, 86, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 103, 105], "runif": [33, 36], "rnorm": [33, 38, 40, 87, 88, 93], "sample_s": [33, 36, 93], "100": [33, 36, 40, 87, 88, 89, 92, 93, 94, 96, 100, 103], "age_lo": [33, 36], "80": [33, 36, 88, 92, 93, 94], "minimum": [33, 36, 37, 93, 98, 101], "month": [33, 36, 92, 104], "age_hi": [33, 36], "200": [33, 36, 93], "maximum": [33, 36, 97, 98, 101, 103], "beta_xa": [33, 36], "beta_x0": [33, 36], "sd_x": [33, 36], "dev": [33, 36, 91, 102], "epsilon_x": [33, 36], "beta_ca": [33, 36], "8": [33, 35, 36, 40, 44, 72, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 98, 99, 100, 101, 102, 103, 104, 105], "score": [33, 36, 37, 83, 84, 91, 92, 98, 105], "everi": [33, 36, 46, 88, 89, 93, 94, 98, 99, 100, 101, 103], "unit": [33, 36, 45, 88, 94, 100, 103, 104], "beta_cx": [33, 36], "beta_c0": [33, 36], "sd_c": [33, 36], "85": [33, 36, 47, 88, 94, 105], "yield": [33, 93, 100], "april": [33, 36, 37, 38, 40], "unlik": 34, "previou": [34, 38, 45, 46, 84, 85, 86, 87, 88, 90, 93, 99, 100, 101, 102, 103, 104], "As": [34, 36, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 99, 100, 101, 104, 105], "comma": [34, 41, 99], "convert": [34, 92, 104], "them": [34, 46, 80, 82, 83, 87, 88, 89, 91, 92, 93, 95, 96, 99, 100, 101, 102, 103, 104, 105], "freq_hal": 34, "issu": [34, 82, 85, 86, 88, 95, 99, 103], "fix": [34, 45, 80, 91, 104, 105], "natur": [34, 80, 82, 88, 95, 99, 101], "transform": [34, 53, 96, 100, 101, 103, 105], "d_rt": [34, 41], "lme4": [34, 58, 88, 91, 93], "sub_id": [34, 41], "shift": [34, 42, 99], "rt": [34, 91, 93], "aikek": 34, "control": [34, 36, 38, 45, 74, 80, 88, 92, 93, 99, 104], "18": [34, 38, 80, 85, 89, 90, 91, 94, 98, 99, 103], "discuss": [35, 44, 84, 88, 89, 90, 93, 94, 100, 101, 102], "deviat": [35, 39, 41, 93, 99], "keep": [35, 42, 87, 88, 97, 102], "short": [35, 92, 99], "snake": [35, 92], "multipl": [35, 57, 83, 87, 90, 91, 93, 101, 102, 103, 105], "command": [35, 79, 82, 84, 87, 89, 93, 95, 99, 102, 103, 105], "v1": 35, "avail": [35, 88, 90, 92, 102, 103, 104, 105], "placehold": 35, "up": [35, 36, 37, 38, 40, 42, 43, 80, 82, 84, 85, 86, 88, 92, 94, 95, 98, 99, 101, 104], "option": [35, 45, 80, 82, 87, 88, 92, 93, 95, 99, 100, 102, 103, 104, 105], "summar": [35, 84, 91, 100, 103, 104], "6": [35, 44, 50, 52, 55, 56, 61, 62, 64, 65, 66, 67, 70, 71, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105], "your_function_nam": 35, "mu": [35, 83, 101], "popul": [35, 45, 46, 80, 88, 93], "size": [35, 40, 60, 80, 85, 86, 87, 88, 90, 98, 99, 100, 103, 104, 105], "ttest_fun": 35, "mind": [35, 38, 92, 97, 102], "suppli": [35, 84, 89, 99, 103], "v2": 35, "12": [35, 41, 60, 83, 87, 88, 89, 91, 92, 94, 96, 98, 100, 104], "exercise2": 35, "conduct": [36, 83, 84, 96], "week": [36, 46], "remind": [36, 38, 83, 93, 100], "bad": [36, 84, 88, 104], "my": [36, 79, 80, 83, 89, 97, 101, 102], "order": [36, 37, 38, 42, 80, 84, 85, 86, 87, 88, 89, 90, 92, 93, 96, 99, 102, 103, 105], "detect": [36, 90, 93], "pretend": [36, 102], "sake": [36, 38, 84], "simplic": [36, 38, 80, 84], "although": [36, 84, 85, 86, 100], "cours": [36, 80, 94], "unusu": [36, 104], "realiti": [36, 103], "contain": [36, 40, 41, 45, 46, 80, 84, 85, 86, 92, 96, 97, 98, 99, 101, 102, 103, 104, 105], "acm": [36, 90], "d0": 36, "z0": 36, "object": [36, 37, 42, 43, 83, 85, 86, 88, 92, 93, 96, 97, 98, 99, 100, 103, 104, 105], "fitm": [36, 90], "previous": [36, 84, 100], "next": [36, 45, 46, 84, 87, 89, 93, 97, 99, 100, 101, 102, 105], "num_simul": 36, "simout": [36, 93], "rep": [36, 42, 83, 84, 85, 86, 87, 88, 93, 98], "ncol": [36, 38, 88, 89, 93, 97, 104], "acme_cov": 36, "IN": 36, "ade_cov": 36, "01": [36, 83, 88, 90, 91, 93, 94, 99, 100, 105], "75": [36, 88, 90, 94, 96, 99], "125": [36, 83, 92, 93], "150": [36, 38, 91, 98, 99, 100], "around": [36, 38, 41, 88, 90, 94, 98, 101, 105], "minut": [36, 42, 85, 86, 88, 90, 93, 100, 104], "per": [36, 45, 46, 85, 86, 88, 90, 91, 92, 93, 97, 99, 104, 105], "harder": 36, "earlier": [37, 92, 99], "low": [37, 83, 84, 88, 90], "memori": 37, "ggplot2": [37, 38, 42, 45, 80, 84, 88, 91, 94, 99, 101, 103, 105], "freesurf": 37, "hemispher": 37, "consist": [37, 88, 93, 99, 103], "zero": [37, 40, 43, 44, 83, 88, 89, 93, 96, 97, 105], "ends_with": [37, 99], "end": [37, 44, 80, 84, 85, 86, 88, 89, 94, 96, 97, 98, 100, 102, 105], "_vol": 37, "fs_": 37, "cor": [37, 84, 88, 94], "call": [37, 38, 79, 83, 84, 87, 88, 89, 90, 91, 92, 93, 97, 98, 99, 102, 103, 104, 105], "fs_cor": 37, "reshape2": 37, "melt": 37, "heatmap": [37, 88, 103], "scale_fill_gradient2": 37, "color": [37, 39, 42, 46, 80, 88, 91, 93, 98, 99, 100, 101, 103, 104], "red": [37, 88, 93, 101, 104], "blue": [37, 88, 100], "cap": 37, "fs_d": 37, "pca": [37, 88], "princomp": [37, 88], "cumul": [37, 94], "begin": [37, 80, 82, 89, 95, 99], "receiv": [37, 83, 92], "flag": 37, "somewher": [37, 80, 88], "validationplot": [37, 94], "msep": [37, 94], "cv": [37, 85, 86, 94, 96], "adj_cv": 37, "funtion": 37, "arrai": [37, 85, 86, 88, 89, 97], "singleton": 37, "origin": [37, 39, 88, 89, 90, 92, 93, 94, 97, 99, 101, 102, 105], "2x1x53": 37, "2x53": 37, "alon": 37, "variat": [37, 79, 91, 93, 99], "properti": [38, 87, 89], "ultra": 38, "happen": [38, 80, 88, 91, 96, 99, 100, 102], "glmnet": [38, 88, 96], "cosin": 38, "121": [38, 84], "sigma_nois": 38, "seq": [38, 42, 80, 84, 87, 88, 89, 96, 101], "co": [38, 101], "20": [38, 40, 42, 83, 84, 85, 86, 88, 92, 93, 96, 98, 101], "sd": [38, 87, 88, 93, 99], "51": [38, 90, 94, 99, 100], "randomli": [38, 42, 85, 86, 88, 97, 103, 105], "expand": [38, 43, 87, 88, 89, 93, 101], "_0": 38, "sum_": [38, 85, 86, 89, 101], "_jx": 38, "poli": [38, 85, 86], "2nd": [38, 85, 86], "help": [38, 41, 42, 44, 45, 80, 82, 84, 88, 89, 91, 92, 93, 94, 95, 98, 99, 101, 103, 104, 105], "stat_smooth": [38, 80, 85, 86], "12th": 38, "wors": [38, 90, 96], "median": [38, 83, 84, 88, 90, 91, 105], "throw": [38, 97], "off": [38, 39, 80, 84, 85, 86, 88], "trade": [38, 84, 85, 86], "setup": [38, 44, 96, 102], "train_rss": [38, 88], "test_rss": [38, 88], "copi": [38, 40, 41, 97, 102], "beyond": [38, 63], "geom_vlin": [38, 101, 104], "draw": [38, 80, 83, 84, 85, 86, 88, 90, 91, 92, 93, 94, 96, 97, 98, 100, 101, 104, 105], "vertic": [38, 91, 104], "clear": [38, 80, 83, 88, 90, 92, 93, 98, 104], "larger": [38, 42, 88, 89, 92, 96, 97, 100, 101, 104], "repeat": [38, 40, 85, 86, 87, 91, 93, 96, 99, 101, 102], "sparsiti": [38, 96], "lambda": [38, 96], "00005": 38, "rm": [38, 88], "shown": [38, 85, 86, 89, 92, 96, 98, 99, 104], "upper": [38, 90, 102, 104, 105], "self": [39, 90], "collect": [39, 90, 93, 99], "intracrani": 39, "fs_intracranial_vol": 39, "scatter": [39, 94, 103], "logis": 39, "signficantli": 39, "histogram": [39, 82, 95, 103], "robust": [39, 100], "1000": [39, 90, 93, 97, 100], "much": [39, 42, 83, 85, 86, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104], "contribut": [39, 94, 104], "unpermut": [39, 97], "ablin": [39, 105], "27": [39, 85, 86, 89, 90, 91, 105], "question": [40, 43, 45, 46, 80, 83, 84, 90, 91, 93, 97, 99, 103], "beta_1x": 40, "beta_2x": 40, "beta_3x": 40, "beta_2": [40, 84], "beta_3": [40, 84], "constant": [40, 88, 89, 90], "regsubset": [40, 98], "view": [40, 82, 88, 95, 99, 101], "otherwis": [40, 83, 84, 88, 93, 101], "delet": [40, 88, 102, 105], "cell": [40, 41, 43, 44, 79, 80, 82, 87, 88, 92, 95, 96, 99, 105], "leav": [40, 99], "blank": 40, "mallow": [40, 98], "cp": [40, 98], "criteria": 40, "explor": [40, 79, 80, 85, 86, 88, 101, 104, 105], "split": [40, 42, 46, 85, 86, 88, 90, 93, 96, 101, 104], "900": 40, "mse": [40, 43, 85, 86, 94, 96, 101], "identifi": [40, 45, 83, 85, 86, 89, 93, 94, 98, 99, 102], "until": [40, 85, 86, 88, 93, 102], "minim": [40, 43, 62, 88], "intermedi": [40, 99], "lexicaldata_toclean": 41, "1wsvrpme5nimuda0t3wqnsgzimlb1una7": 41, "d_word": 41, "useabl": 41, "check": [41, 42, 43, 46, 82, 84, 89, 93, 94, 95, 97, 99, 102, 103, 105], "gsub": 41, "filter": [41, 88, 93, 98, 104], "sure": [41, 83, 91, 93, 96, 97, 100, 101], "action": [41, 88], "address": [41, 42, 85, 86, 89, 102], "m\u00fcller": [41, 68], "third": [41, 90, 99, 101, 103], "plai": [41, 80, 83, 88, 90, 98, 99, 104], "bit": [41, 43, 45, 88, 89, 94, 100, 103, 105], "pipe": [41, 87, 103], "summaris": [41, 103], "mutat": [41, 83, 87, 90, 93, 103, 104], "equal": [41, 83, 84, 89, 92, 99, 100, 101], "exercise4": 41, "diamond": [42, 103], "qualiti": [42, 84, 88, 90, 93], "price": [42, 88, 90, 103, 105], "simpler": [42, 83, 85, 86], "price_bin": 42, "indic": [42, 45, 84, 85, 86, 88, 89, 94, 96, 98, 99, 100, 105], "if_els": [42, 99], "carat": [42, 103], "depth": [42, 83, 105], "aesthet": [42, 45, 104], "belong": 42, "asid": [42, 45, 85, 86, 92, 99, 100, 103], "divid": [42, 84, 89, 93, 94, 97, 101], "30": [42, 83, 84, 91, 93, 94, 99, 100, 101, 103, 104], "allot": 42, "doubl": [42, 43, 46, 92, 102], "divis": [42, 96, 98], "2023": [42, 59, 88], "review": [42, 49, 78, 89, 99, 101, 102], "format": [42, 43, 53, 83, 84, 87, 92, 99, 101, 103], "requir": [42, 80, 83, 84, 88, 91, 92, 93, 94, 96, 99, 100, 101, 102], "rerun": 42, "addit": [42, 92, 94, 99, 102, 103, 104], "didn": [42, 101], "hand": [42, 80, 94, 101, 104], "empti": [42, 93, 98, 102], "knn_fit": 42, "conf_df": 42, "geom_smooth": [42, 45, 80, 90, 91, 103, 104, 105], "layer": [42, 46, 100, 103], "sensit": [42, 85, 86], "magnitud": [42, 91], "even": [42, 82, 83, 88, 89, 90, 91, 92, 93, 95, 99, 100, 101, 102, 103], "optim": [42, 87, 93], "rescal": [42, 105], "deeper": [43, 96], "dive": [43, 87, 96], "math": [43, 89, 101], "behind": [43, 90, 99, 103], "close": [43, 45, 83, 84, 85, 86, 88, 93], "section": [43, 92, 93, 94, 99, 100, 101, 102, 104], "latex": 43, "equat": [43, 80, 85, 86, 101], "page": [43, 79, 82, 95], "mle": 43, "algebra": [43, 103], "ii": 43, "var": [43, 80, 87, 93, 94, 99, 100, 101, 104], "prove": [43, 101], "solv": 43, "plug": [43, 101], "onc": [43, 79, 82, 87, 91, 93, 95, 98, 99, 101, 102], "xy": [43, 101], "28": [43, 94, 99], "assignemnt": 44, "recit": [44, 105], "wiki": 44, "video": [44, 82, 94, 95, 101], "titl": [44, 46, 80, 88], "00": [44, 89, 90, 94, 101], "access": [44, 87, 89, 92, 102], "submit": [44, 82, 95, 102], "materi": [44, 99], "post": 44, "throughout": 44, "semest": [44, 47, 80], "your_last_nam": 44, "_dspn_s25": 44, "user": [44, 80, 102], "coaxlab0": 44, "ta": [44, 89], "larryrj07": 44, "clone": [44, 102], "collaboratori": 44, "rocket": 44, "button": 44, "googl": [44, 92, 104], "drive": [44, 101, 102, 105], "homework1_helloworld": 44, "hello": 44, "comment": [44, 80, 92], "email": [44, 80, 82, 95, 102], "jan": 44, "22": [44, 76, 83, 87, 88, 94], "2025": 44, "gapmind": [45, 46], "life": [45, 46, 89], "capita": [45, 46], "gdp": [45, 46], "countri": [45, 46, 104], "basic": [45, 80, 90, 97, 99, 101, 104, 105], "contin": [45, 46], "trend": [45, 93, 103, 104], "hmm": 45, "weird": [45, 88, 99], "unexpect": 45, "difficult": [45, 99, 103, 104], "caus": [45, 90, 104], "graph": [45, 103, 104], "drawn": [45, 93, 101], "top": [45, 84, 92, 98, 99], "black": [45, 92, 100, 103, 104], "underneath": [45, 104], "attribut": [45, 46, 94, 97, 98, 103], "global": [45, 46, 92, 102], "overlai": 45, "gdppercap": 45, "lifeexp": 45, "squish": 45, "side": [45, 84, 99, 101], "hard": [45, 92, 94], "To": [45, 46, 82, 83, 87, 88, 90, 91, 92, 93, 95, 98, 99, 100, 102, 103, 104, 105], "transpar": [45, 72, 103, 104], "incorpor": [45, 92, 104], "alreadi": [45, 79, 88, 89, 99, 102, 103, 104, 105], "fite": 45, "introduc": [45, 83, 85, 86, 93, 102], "trendlin": 45, "exercise5": 45, "14": [45, 49, 80, 87, 88, 89, 90, 94, 98, 99, 104], "advanc": [46, 87], "altern": [46, 82, 83, 87, 88, 92, 93, 95, 102], "facet": [46, 104], "panel": 46, "america": 46, "facet_wrap": [46, 87, 104], "addition": [46, 93], "easier": [46, 84, 89, 92, 99, 101, 102, 103], "theme": [46, 80, 104], "rotat": [46, 94, 104], "45": [46, 58, 88, 91, 99], "imagin": [46, 87, 89, 99, 102], "publish": 46, "manuscript": 46, "cleaner": [46, 99, 104], "label": [46, 80, 84, 87, 89, 99, 100, 103, 105], "lab": [46, 80, 82, 83, 84, 85, 86, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "legend": 46, "90": [46, 88, 90, 94, 99], "vari": [46, 85, 86, 90, 91, 94, 104], "five": 46, "boxplot": [46, 103], "repres": [46, 87, 88, 89, 90, 91, 98, 103, 104], "year": [46, 84, 90, 96, 98, 100, 104], "element_blank": [46, 80], "readabl": [46, 92, 99], "ink": [46, 104], "edit": [46, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105], "19": [46, 60, 63, 80, 85, 86, 88, 94, 98], "welcom": [47, 82, 83, 95], "jupyt": [47, 79, 80, 105], "book": [47, 79, 82, 85, 86, 95, 103], "cmu": [47, 82, 95, 102], "432": 47, "732": 47, "supplement": [47, 53, 72, 83], "standalon": 47, "content": [47, 79, 80, 88, 102, 105], "sourc": [47, 80, 82, 95, 99, 102], "continu": [47, 85, 86, 88, 102, 103, 104], "throughtout": 47, "pleas": [47, 83], "refresh": 47, "wagenmak": 49, "pervas": 49, "psychonom": 49, "bulletin": 49, "779": 49, "804": 49, "chapter": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 75, 84, 85, 86, 88, 90, 91, 94, 96, 97, 98, 100, 104, 105], "jame": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 84, 85, 86, 88, 94, 96, 97, 98, 100, 105], "witten": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 84, 85, 86, 88, 94, 96, 97, 98, 100, 105], "hasti": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 84, 85, 86, 88, 94, 96, 97, 98, 100, 105], "tibshirani": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 84, 85, 86, 88, 94, 96, 97, 98, 100, 105], "introduct": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 75, 83, 84, 85, 86, 88, 89, 94, 96, 97, 98, 99, 100, 102, 103, 105], "applic": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 84, 85, 86, 88, 94, 96, 97, 98, 100, 102, 105], "vol": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71], "york": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71, 72], "springer": [50, 52, 55, 56, 61, 64, 65, 66, 67, 70, 71], "2021": [51, 76, 77, 102], "build": [51, 77, 79, 80, 92, 105], "verisimilitud": [51, 77], "explanatori": [51, 77], "psycholog": [51, 76, 77], "perspect": [51, 77], "platt": 51, "1964": 51, "strong": [51, 90, 93, 96], "146": [51, 93], "3642": 51, "347": [51, 94], "353": [51, 94], "wickham": 53, "2014": [53, 60, 91], "journal": 53, "softwar": [53, 82, 89, 92, 95, 104], "59": [53, 85, 86, 88, 98], "1": [53, 59, 60, 62, 63, 67, 72, 73, 75, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105], "23": [53, 85, 86, 87, 90, 91, 94, 99], "gorgolewski": 53, "auer": 53, "calhoun": 53, "v": [53, 80, 89, 105], "craddock": 53, "da": [53, 89], "duff": 53, "handwerk": 53, "2016": [53, 72], "imag": [53, 84, 89, 102, 104], "organ": [53, 87, 92], "neuroimag": 53, "grolemund": 53, "o": [53, 59, 72, 77, 82, 95, 100], "reilli": 53, "media": 53, "inc": 53, "1997": 54, "virtu": 54, "necess": 54, "philosophi": 54, "64": [54, 83, 88], "s4": [54, 91], "s195": 54, "s212": 54, "preacher": 57, "hay": 57, "2008": 57, "asymptot": 57, "assess": [57, 60, 93], "indirect": [57, 90], "40": [57, 80, 89, 90, 93, 94, 99, 100, 101], "879": 57, "891": 57, "bate": [58, 91], "dougla": 58, "2010": [58, 104], "470": 58, "474": 58, "2022": 58, "crisi": 58, "e1": 58, "survei": 59, "1959": 59, "routledg": 59, "On": [59, 91, 92, 104], "behaviour": 59, "beaujean": [60, 93], "regular": [61, 66, 79, 91], "dretsk": 62, "1983": 62, "pr\u00e9ci": 62, "flow": [62, 92], "55": [62, 83, 88, 89, 94, 97, 99, 100], "63": [62, 88, 94, 99, 100], "vlastelica": 62, "schirm": 63, "lazar": 63, "move": [63, 84, 85, 86, 90, 94, 101], "05": [63, 80, 83, 84, 88, 90, 91, 93, 94, 99, 105], "statistician": 63, "73": [63, 83, 90, 94, 99, 100], "s1": 63, "freytag": 68, "2003": [68, 84], "challeng": 68, "berlin": 68, "hub": 68, "ib": 68, "164": 68, "mensh": 69, "ten": [69, 72], "rule": [69, 72, 89, 92, 104], "plo": [69, 72], "biol": [69, 72], "13": [69, 83, 87, 88, 90, 91, 93, 94, 98, 99, 100, 104, 105], "e1005619": 69, "goodman": 72, "fanelli": 72, "ioannidi": 72, "translat": [72, 80, 89, 92], "medicin": 72, "341": [72, 83, 94], "341ps12": 72, "nekrutenko": 72, "taylor": 72, "hovig": 72, "e1003285": 72, "gilmor": 72, "diaz": 72, "wybl": 72, "progress": [72, 93, 102], "annal": 72, "academi": 72, "1396": 72, "de": 73, "regt": 73, "w": 73, "diek": 73, "2005": [73, 84], "synthes": 73, "144": [73, 93], "137": 73, "170": 73, "ipython": 74, "displai": [74, 79, 82, 88, 93, 95, 99, 103, 105], "html": 74, "youtub": 74, "ifram": 74, "width": [74, 80, 87, 88, 90, 93, 94, 99, 100, 103, 105], "560": [74, 93], "height": [74, 87, 93, 100, 103, 104, 105], "315": 74, "src": 74, "http": [74, 80, 82, 88, 95, 99, 102], "www": 74, "com": [74, 80, 83, 102], "emb": 74, "s_f2qv2_u00": 74, "amp": 74, "showinfo": 74, "framebord": 74, "allowfullscreen": 74, "2012": 75, "art": 75, "rider": 75, "liabil": 75, "genom": 75, "biologi": 75, "21": [75, 83, 87, 90, 94, 99, 100, 105], "padilla": 76, "shah": 76, "zack": 76, "hullman": 76, "110": [76, 88, 91], "161": [76, 88, 93], "16": [77, 83, 85, 86, 88, 89, 90, 91, 94, 97, 98, 99, 101, 105], "682": 77, "697": 77, "forc": [77, 88, 98, 104], "789": 77, "802": [77, 88], "wilei": 78, "interdisciplinari": 78, "299": 78, "306": [78, 99], "md": [79, 92], "flavor": 79, "stand": [79, 100], "markedli": 79, "slight": 79, "commonmark": 79, "small": [79, 93, 96, 101], "syntax": [79, 84], "extens": [79, 104], "sphinx": 79, "ecosystem": 79, "kind": [79, 97, 101], "written": [79, 82, 89, 92, 93, 95, 99], "markup": 79, "serv": [79, 80, 99, 103, 104], "purpos": [79, 80, 82, 88, 93, 95, 96, 97, 101, 102, 103, 104], "wherea": [79, 99], "span": [79, 96, 104], "At": [79, 84, 101, 102], "simplest": [79, 102, 103], "mydirectivenam": 79, "exist": [79, 88, 92, 93, 97, 102], "pre": [79, 80, 84, 92, 99, 100], "box": [79, 92, 102, 103], "rolenam": 79, "path": [79, 82, 95, 102], "intro": 79, "cite": 79, "bibtex": 79, "holdgraf_evidence_2014": 79, "render": 79, "moreoev": 79, "bibliographi": 79, "must": [79, 82, 84, 89, 90, 95, 96, 97, 103], "properli": 79, "bib": 79, "jupytext": 79, "metadata": 79, "init": [79, 102], "block": [79, 92], "default": [79, 85, 86, 90, 92, 96, 98, 99, 103, 104], "kernel": [79, 92, 103], "nb": 79, "abl": [80, 82, 95, 99, 103], "discov": 80, "stori": [80, 104], "sit": 80, "intersect": 80, "machin": [80, 93], "aim": [80, 104], "holist": 80, "share": [80, 82, 84, 95, 102], "effici": [80, 90, 92, 93, 99], "borrow": 80, "dataconomi": 80, "07": [80, 87, 88, 90, 91, 94], "insight": 80, "internet": 80, "peopl": [80, 82, 92, 93, 95, 99, 100, 102], "clever": 80, "program": [80, 92, 99], "cool": 80, "big": [80, 91, 101], "journei": 80, "messi": [80, 99], "dead": 80, "everyth": [80, 85, 86, 92, 102, 103], "reason": [80, 89, 90, 94, 99, 101, 102], "markdown": 80, "integr": [80, 92], "scipen": 80, "999": [80, 93], "notat": [80, 89], "1e": [80, 87, 96, 105], "48": [80, 94], "theme_set": 80, "theme_bw": [80, 104], "bw": 80, "midwest": 80, "goo": 80, "gl": 80, "g1k41k": 80, "bkup": 80, "gg": 80, "area": 80, "poptot": 80, "popdens": 80, "loess": [80, 104], "xlim": 80, "ylim": [80, 104], "500000": 80, "subtitl": 80, "caption": 80, "warn": [80, 88, 93, 103, 104, 105], "finit": 80, "hook": 80, "script": [80, 99], "record": [80, 84, 100, 102, 103, 105], "thought": [80, 89, 90, 92], "els": [80, 88, 89], "version": [80, 82, 87, 88, 89, 91, 92, 95, 97, 99, 104, 105], "recommend": [80, 94, 99, 102], "later": [80, 87, 88, 89, 90, 99, 102], "goe": [80, 90, 92, 99, 102], "inlin": 80, "ye": [80, 88, 93], "syllabu": 80, "rhetor": 80, "alwai": [80, 85, 86, 91, 92, 99, 101, 102, 103], "2018": 80, "03": [80, 90, 94, 99, 100], "server": [80, 102], "rooki": 80, "mistak": [80, 99], "enter": 80, "NOT": [80, 89], "violat": [80, 90, 91], "manipul": [80, 83, 87, 93, 98, 99, 101, 103], "aren": [80, 84, 98, 103], "excel": [80, 82, 92, 95, 99], "habit": 80, "raw": [80, 85, 86, 99, 103], "untouch": 80, "reflect": [80, 89, 98, 101], "got": [80, 82, 94, 95, 100, 101], "preprocess": [80, 99], "fun": [80, 87, 88, 92, 93, 99, 103], "stuff": [80, 92], "ggtheme": [80, 104], "email_campaign_funnel": 80, "githubusercont": 80, "selva86": 80, "master": [80, 92, 102, 104], "brk": 80, "15000000": 80, "5000000": [80, 89], "lbl": 80, "paste0": [80, 87], "charact": [80, 92, 99], "stage": [80, 102], "geom_bar": [80, 103, 104], "stat": [80, 82, 88, 95, 105], "ident": [80, 84, 91, 93], "bar": [80, 89, 91, 101, 103, 104], "scale_y_continu": [80, 93], "coord_flip": [80, 104], "flip": 80, "ax": [80, 103, 104], "campaign": 80, "funnel": 80, "theme_tuft": [80, 104], "tuft": 80, "ggfortifi": [80, 105], "element_text": 80, "hjust": 80, "tick": [80, 103], "centr": 80, "scale_fill_brew": 80, "palett": [80, 103], "dark2": 80, "hn": 80, "77llg_f95zlg9ftwmt7m88hr0000gp": 80, "rtmppu5vnf": 80, "downloaded_packag": [80, 99, 104], "brillianc": 80, "routin": 80, "pretti": [80, 88, 93, 94, 100, 102], "pictur": [80, 101], "game": 80, "plan": [80, 102], "whiteboard": 80, "chalkboard": 80, "crayon": 80, "wall": 80, "Or": [80, 88, 92, 93, 102], "whatev": [80, 97, 102], "Being": 80, "fly": 80, "troubl": 80, "never": [80, 92, 102], "sometim": [80, 84, 92, 100, 101, 102], "modifyng": 80, "sparingli": 80, "spend": [80, 90], "stress": [80, 90], "long": [80, 85, 86, 87, 90, 92, 93, 94, 96, 101, 102, 103, 104], "heart": 80, "tricki": 80, "__simplicity__": 80, "__accuracy__": 80, "__maxim": 80, "convey__": 80, "convei": [80, 103], "prep": 80, "freqtabl": 80, "mpg": [80, 85, 86, 88, 90, 97, 105], "manufactur": [80, 90, 105], "df": [80, 83, 84, 87, 88, 90, 91, 98, 99, 101, 105], "var1": [80, 99], "freq": 80, "audi": 80, "chevrolet": 80, "dodg": 80, "37": [80, 91, 94, 99, 105], "ford": 80, "honda": 80, "hyundai": 80, "theme_class": [80, 93, 99, 104], "tomato2": 80, "chart": [80, 103, 104], "vehicl": [80, 90], "angl": [80, 88], "65": [80, 88, 90, 94, 99, 100], "vjust": 80, "var1freq": 80, "chevrolet19": 80, "lose": [80, 94], "errorbar": 80, "hide": 80, "captur": [80, 84, 90, 94, 105], "nuanc": 80, "violin": [80, 103], "cty": 80, "geom_violin": [80, 103], "citi": [80, 88, 90, 104, 105], "mileag": [80, 90], "talk": [80, 84, 88, 89, 99, 100, 101, 102], "wrong": [80, 100], "impress": [80, 100], "tale": 80, "free": [82, 89, 95], "latest": [82, 95], "current": [82, 84, 95, 99, 102], "lib": [82, 83, 84, 85, 88, 93, 95, 96, 97, 105], "edu": [82, 95, 102], "cran": [82, 95], "mac": [82, 92, 95, 99, 102], "etc": [82, 87, 93, 95, 99, 102, 103], "faq": [82, 95], "great": [82, 95], "littl": [82, 88, 89, 91, 95, 100, 101, 105], "nicer": [82, 95, 101], "instruct": [82, 95, 102, 103], "hist": [82, 95, 97], "varieti": [82, 95], "audienc": [82, 95, 104], "weav": [82, 95], "narr": [82, 95], "aspect": [82, 87, 95, 98, 103, 105], "ground": [82, 95], "modular": [82, 95], "conveni": [82, 95], "snippet": [82, 95], "teach": [82, 95, 104], "platform": [82, 95, 102], "licens": [82, 95], "clean": [82, 92, 95, 98, 99], "novel": [82, 95], "revamp": [82, 95], "academ": [82, 95, 102], "anaconda": [82, 95], "choos": [82, 85, 86, 93, 95, 99, 102], "prerequisit": [82, 95], "environ": [82, 87, 92, 95, 99, 105], "launch": [82, 95], "termin": [82, 95, 102], "consol": [82, 95, 102], "stick": [82, 83, 90, 95], "browser": [82, 95], "invok": [82, 92, 95, 102], "within": [82, 83, 87, 89, 92, 93, 95, 99, 100, 104], "irkernel": [82, 95], "installspec": [82, 95], "regist": [82, 95], "prompt": [82, 95, 102], "cloud": [82, 95], "mirror": [82, 95, 100], "session": [82, 95, 102], "simpli": [82, 89, 92, 95, 101, 102, 104, 105], "linux": [82, 95, 102], "desktop": [82, 95], "author": [82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "ven": [82, 84, 85, 86, 87, 88, 91, 93, 95, 96, 97, 98, 99, 102, 103, 105], "popov": [82, 84, 85, 86, 87, 88, 91, 93, 95, 96, 97, 98, 99, 102, 103, 105], "krista": [82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 102, 103, 105], "bond": [82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 102, 103, 105], "charl": [82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 102, 103, 105], "wu": [82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 102, 103, 105], "patienc": [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105], "steven": [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105], "ami": [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "senti": [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "approxim": [83, 88], "belief": 83, "uncertainti": [83, 97, 105], "am": 83, "absolut": 83, "anyth": [83, 84, 89, 100, 102], "richard": 83, "feynman": 83, "bayesfactor": 83, "quantifi": [83, 84, 97, 98], "fulli": 83, "support": [83, 104], "reject": [83, 93, 97, 105], "altogeth": 83, "morei": 83, "analyt": [83, 93], "strength": [83, 103], "weight": [83, 86, 88, 90, 97, 104, 105], "express": [83, 89, 91, 99, 101], "bf": [83, 89, 100], "h_1": 83, "h_0": [83, 97], "penal": 83, "treatment": 83, "usr": [83, 84, 85, 88, 93, 96, 97, 105], "site": [83, 84, 85, 88, 93, 96, 97, 102, 105], "unspecifi": [83, 84, 85, 88, 93, 96, 97, 105], "ellipt": 83, "contfrac": 83, "desolv": 83, "coda": 83, "pbappli": 83, "mvtnorm": [83, 88], "gtool": [83, 88], "matrixmodel": [83, 88], "hypergeo": 83, "rcppeigen": [83, 88, 93], "regresss": 83, "lsf": 83, "contact": 83, "richarddmorei": 83, "gmail": 83, "bfmanual": 83, "sleep": [83, 91], "depriv": [83, 91], "extragroupid": 83, "lt": [83, 87, 91, 92, 93, 94, 99, 100, 104, 105], "dbl": [83, 84, 87, 88, 89, 91, 92, 93, 94, 97, 99, 100, 104, 105], "gt": [83, 87, 91, 92, 93, 94, 97, 99, 100, 104, 105], "fct": [83, 91, 94, 99, 100, 104], "711": 83, "612": [83, 91], "213": [83, 88], "214": 83, "115": 83, "416": 83, "717": [83, 88], "818": 83, "019": 83, "0110": 83, "921": 83, "822": 83, "123": 83, "124": 83, "426": [83, 87], "527": 83, "628": [83, 91], "629": 83, "4210": 83, "acertain": 83, "drug": 83, "extra": [83, 85, 86], "hour": [83, 91, 93], "spread": [83, 87, 99], "group1": [83, 93], "group2": [83, 93], "reset": [83, 85, 86, 93, 104, 105], "avoid": [83, 89, 92, 102], "integ": 83, "sleep_wd": 83, "wide": [83, 87, 94], "diffscor": 83, "idgroup1group2diffscor": 83, "33": [83, 87, 88, 99], "44": [83, 87, 88, 90, 94, 99, 100], "66": [83, 88, 94], "0621": 83, "002833": 83, "percent": [83, 84], "4598858": 83, "7001142": 83, "58": [83, 88, 90, 94], "06": [83, 87, 88, 90, 99], "005": [83, 93], "smaller": [83, 85, 86, 92, 93, 96, 99, 103, 104], "ttestbf": 83, "nonzero": 83, "alt": [83, 92], "707": 83, "17": [83, 85, 86, 87, 88, 94, 98, 99], "25888": 83, "bfonesampl": 83, "jz": 83, "gotten": [83, 93], "05794119": 83, "707106781186548": 83, "nullinterv": 83, "rang": [83, 85, 86, 87, 88, 93, 96, 97, 99, 103, 104], "inf": 83, "bfinterv": 83, "34": [83, 87, 94, 99, 100], "41694": 83, "1008246": 83, "evalau": 83, "tha": 83, "strongli": [83, 93], "42": [83, 88, 94], "achiev": [83, 93], "bfneg": 83, "3547": 83, "And": [83, 88, 89, 90, 93, 98, 99, 103], "invers": [83, 93], "bfposit": 83, "miniscul": 83, "002929504": 83, "allbf": 83, "ahhhh": 83, "love": 83, "hierarch": 83, "toothgrowth": 83, "len": 83, "tooth": 83, "independ": [83, 88, 90, 91, 93, 94, 102], "supp": 83, "took": [83, 85, 86, 101], "vitamin": [83, 90], "orang": [83, 93], "juic": 83, "dose": 83, "log10": 83, "classic": [83, 88, 102], "lmtoothgrowth": 83, "lensuppdos": 83, "2vc0": 83, "211": 83, "5vc0": 83, "3vc0": 83, "8vc0": 83, "4vc0": 83, "610": [83, 91], "0vc0": 83, "min": [83, 84, 88, 90, 91, 96, 98, 101, 104, 105], "1q": [83, 84, 88, 90, 91, 105], "3q": [83, 84, 88, 90, 91, 105], "max": [83, 84, 88, 90, 91, 98, 104, 105], "5433": 83, "4921": 83, "5033": 83, "7117": 83, "8567": 83, "pr": [83, 84, 88, 90, 91, 105], "6633": 83, "6791": 83, "425": 83, "2e": [83, 88, 90, 91, 101, 105], "suppvc": 83, "7000": 83, "9605": 83, "852": 83, "000303": 83, "3102": 83, "7631": 83, "712": 83, "3e": 83, "8529": 83, "9076": 83, "266": [83, 88], "027366": 83, "signif": [83, 88, 90, 91, 105], "001": [83, 88, 90, 91, 93, 105], "72": [83, 89, 94, 99], "56": [83, 84, 88, 94, 99], "7755": 83, "7635": 83, "growth": 83, "lmbf": 83, "nointeract": 83, "onlydos": 83, "onlysupp": 83, "651389e": 83, "54362e": 83, "769593e": 83, "198757": 83, "bflinearmodel": 83, "02911": 83, "literatur": [83, 93], "suggest": [83, 85, 86, 99, 105], "role": [83, 91], "lean": 83, "configur": [84, 98], "variou": [84, 93, 98, 99, 102, 103, 105], "discrimin": [84, 103], "exponenti": [84, 101], "far": [84, 85, 86, 88, 105], "fall": [84, 94, 97, 100], "umbrella": 84, "exercis": [84, 85, 86], "daili": [84, 104], "1250": 84, "500": [84, 88], "index": [84, 88, 97], "2001": 84, "lag1": 84, "percentag": [84, 93, 94], "dai": [84, 91, 104], "lag2": 84, "lag3": 84, "lag4": 84, "lag5": 84, "billion": 84, "todai": [84, 101], "had": [84, 88, 89, 91, 93, 99, 100], "guess": [84, 93, 100], "smarket": 84, "922000": 84, "1st": [84, 89], "qu": 84, "2002": 84, "639500": 84, "640000": 84, "039000": 84, "038500": 84, "003834": 84, "003919": 84, "001716": 84, "3rd": [84, 85, 86], "2004": 84, "596750": 84, "733000": 84, "92200": 84, "3561": 84, "64000": 84, "2574": 84, "03850": 84, "4229": 84, "001636": 84, "00561": 84, "4783": 84, "003138": 84, "59700": 84, "6417": 84, "73300": 84, "1525": 84, "602": 84, "648": 84, "glimps": 84, "among": [84, 88, 91, 98, 99, 100, 104], "cxy": 84, "traceback": [84, 92], "stop": 84, "upupdownupupup": 84, "colnam": [84, 105], "yearlag1lag2lag3lag4lag5volumetodai": 84, "year1": 84, "00000000": 84, "029699649": 84, "030596422": 84, "033194581": 84, "035688718": 84, "029787995": 84, "53900647": 84, "030095229": 84, "lag10": 84, "02969965": 84, "000000000": 84, "026294328": 84, "010803402": 84, "002985911": 84, "005674606": 84, "04090991": 84, "026155045": 84, "lag20": 84, "03059642": 84, "025896670": 84, "010853533": 84, "003557949": 84, "04338321": 84, "010250033": 84, "lag30": 84, "03319458": 84, "024051036": 84, "018808338": 84, "04182369": 84, "002447647": 84, "lag40": 84, "03568872": 84, "027083641": 84, "04841425": 84, "006899527": 84, "lag50": 84, "02978799": 84, "02200231": 84, "034860083": 84, "volume0": 84, "040909908": 84, "043383215": 84, "041823686": 84, "048414246": 84, "022002315": 84, "014591823": 84, "today0": 84, "03009523": 84, "01459182": 84, "appear": [84, 90], "539": 84, "weakli": 84, "beta_4": 84, "beta_5": 84, "tri": [84, 89, 93, 99], "binomi": 84, "devianc": 84, "446": [84, 104], "203": 84, "065": 84, "145": 84, "326": 84, "z": [84, 88, 103, 105], "126000": 84, "240736": 84, "523": 84, "601": 84, "073074": 84, "050167": 84, "457": 84, "042301": 84, "050086": 84, "845": 84, "398": 84, "011085": 84, "049939": 84, "222": [84, 88], "824": 84, "009359": 84, "049974": 84, "187": [84, 97], "851": [84, 93], "010313": 84, "049511": 84, "208": 84, "835": 84, "135441": 84, "158360": 84, "855": 84, "392": [84, 85, 86, 97], "dispers": 84, "taken": [84, 99], "1731": 84, "1249": [84, 91], "1727": 84, "1243": 84, "1741": 84, "fisher": 84, "signific": [84, 85, 86, 88, 90, 91, 93, 99, 103, 105], "themselv": [84, 105], "par": [84, 93], "mfrow": 84, "glm_prob_df": 84, "predicted_prob": 84, "num_observ": 84, "prob": 84, "xlab": [84, 85, 86, 88, 96, 97, 104, 105], "ylab": [84, 85, 86, 88, 96, 104, 105], "notic": [84, 85, 86, 88, 90, 91, 93, 96, 97, 98, 99, 101, 103, 105], "sigmoid": [84, 87], "rather": [84, 87, 91, 93, 99, 102, 103], "down0": 84, "up1": 84, "binar": [84, 88], "predicted_binari": 84, "cast": 84, "confusion_df": [84, 100], "141": [84, 93], "507": 84, "diagon": [84, 88, 89, 104], "averag": [84, 85, 86, 88, 91, 93, 99, 101, 103, 104], "match": [84, 92, 96, 99, 101], "matric": [84, 91, 96], "caret": 84, "fourfoldplot": 84, "count": [84, 88, 94, 103], "5216": 84, "52": [84, 94, 99], "glanc": 84, "chanc": [84, 93, 97, 100], "futur": [84, 92, 99, 104], "isol": 84, "entri": [84, 85, 86, 96, 99], "train_idx": 84, "2005_test": 84, "occupi": 84, "dim": [84, 96, 98], "2529": 84, "peform": 84, "pred": [84, 94, 96, 100], "252": 84, "35": [84, 91, 99], "76": [84, 87, 94], "106": [84, 88, 99], "55952380952381": 84, "replic": [84, 99, 102], "491984": 84, "508016": 84, "04279022": 84, "03389409": 84, "03954635": 84, "03132544": 84, "ld1": 84, "6420190": 84, "5135293": 84, "49": [84, 90, 94], "boundari": 84, "w_1": 84, "w_2": 84, "decreas": [84, 85, 86, 88, 93, 94, 96, 101], "posterior": 84, "probabiltii": 84, "otherword": 84, "analog": [84, 99], "downup": 84, "9990": 84, "49017920": 84, "5098208": 84, "10000": [84, 89, 93], "47921850": 84, "5207815": 84, "10010": 84, "46681850": 84, "5331815": 84, "10020": 84, "47400110": 84, "5259989": 84, "10030": 84, "49278770": 84, "5072123": 84, "10040": 84, "49385620": 84, "5061438": 84, "distinguish": [84, 91, 99], "somewhat": [84, 92], "lag": [84, 88, 93, 99], "lag1_posterior_df": 84, "lag1_return": 84, "down_posterior_prob": 84, "ago": 84, "special": [84, 88, 89, 92], "facet_grid": [84, 90, 93, 101, 104], "covari": [84, 101], "0278734923872115": 84, "0392480610374496": 84, "fair": 84, "overlap": [84, 92, 93, 96, 97, 100], "mu_": 84, "main": [84, 89, 91, 93, 99, 101, 102, 103, 104], "sigma_k": 84, "81": [84, 87, 94, 97, 99, 101], "599206349206349": 84, "60": [84, 93, 94, 100, 101], "benefit": [85, 86, 103], "refin": [85, 86], "demo": [85, 86, 93], "chosen": [85, 86], "remaind": [85, 86], "highli": [85, 86, 94], "overestim": [85, 86], "partit": [85, 86], "auto": [85, 86, 97], "acknowledg": [85, 86], "196": [85, 86], "horsepow": [85, 86, 88, 90, 97, 105], "cubic": [85, 86], "fit2": [85, 86, 91], "fit3": [85, 86], "2660086465003": [85, 86], "1601734630785": [85, 86], "5946481598143": [85, 86], "quadrat": [85, 86], "exact": [85, 86], "subsampl": [85, 86], "7265106448139": [85, 86], "3090205440697": [85, 86], "616933858347": [85, 86], "demonstr": [85, 86, 89, 93, 100, 101], "figur": [85, 86, 87, 92, 102, 103], "substanti": [85, 86, 91], "repeatedli": [85, 86, 93], "9358610211705horsepow": [85, 86, 97], "157844733353654": [85, 86, 97], "cv_": [85, 86], "mse_i": [85, 86], "err": [85, 86], "24": [85, 86, 87, 88, 91, 94, 97, 99, 100], "231513517929224": [85, 86], "2311440937561": 85, "equival": [85, 86, 102], "2315135179292": 85, "foreshadow": [85, 86], "lesson": [85, 86], "compens": [85, 86], "textbook": [85, 86, 98], "superior": [85, 86], "sy": [85, 86], "loo": [85, 86], "crossval": [85, 86], "lootim": [85, 86], "46528": 85, "sec": [85, 86], "modest": [85, 86], "worth": [85, 86], "upgrad": [85, 86], "polynom": [85, 86], "bend": [85, 86], "curv": [85, 86, 104], "trust": [85, 86, 88, 89], "fals": [85, 86, 90, 91, 92, 93, 98, 99, 100, 104, 105], "loovc": [85, 86], "kfoldtim": [85, 86], "6577539": 85, "runtim": [85, 86], "4652769565582": 85, "657753944396973": 85, "quicker": [85, 86], "fiona": [85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102], "horner": [85, 86, 87, 88, 89, 91, 92, 99, 100, 101, 102], "2311440937562": 86, "253145": 86, "25314497947693": 86, "246827840805054": 86, "gather": [87, 93, 99, 101], "timepoint": 87, "long_data": 87, "subjecttimepointobserv": 87, "int": [87, 89, 93, 99, 104], "09": [87, 90, 94], "84": [87, 94, 99], "31": [87, 88, 90, 94, 99], "32": [87, 88, 92, 99, 105], "62": [87, 88, 94, 99], "subjecttime1time2time3time4": 87, "130": 87, "620": 87, "whenev": [87, 102], "handi": [87, 89, 92, 94, 99, 102], "referenc": 87, "x1": [87, 88], "x2": [87, 88], "grid": [87, 93, 104], "exp": [87, 94], "x1x2y": 87, "3820138": 87, "3706878": 87, "3525741": 87, "3241418": 87, "2807971": 87, "2175745": 87, "repr": [87, 93, 100, 103, 105], "aboug": 87, "stat_summari": [87, 99, 103], "geom": [87, 99], "wrap": [87, 92, 104], "y_ob": 87, "model_fit": [87, 99, 103], "num": [87, 94, 99], "4996": 87, "1507": 87, "0999": 87, "attr": 87, "chr": [87, 92, 93, 99], "289": 87, "0767": 87, "1405": 87, "0611": 87, "0984": 87, "0678": 87, "4925": 87, "2743": 87, "1608": 87, "1134": 87, "0814": 87, "rank": [87, 88, 104], "503": 87, "427": 87, "352": [87, 94], "277": 87, "201": 87, "qr": 87, "0588": 87, "dimnam": 87, "qraux": 87, "08": [87, 94, 105], "pivot": 87, "tol": 87, "286": 87, "xlevel": 87, "r_globalenv": 87, "predvar": 87, "dataclass": 87, "ob": [87, 91, 100], "287": [87, 105], "291": 87, "375": 87, "269": 87, "499559922079091x10": 87, "150675486478537x20": 87, "0999191218958173": 87, "namevalu": 87, "49955992": 87, "x1x1": 87, "15067549": 87, "x2x2": 87, "09991912": 87, "x1x2yy_obsfit": 87, "4261378": 87, "5028185": 87, "2869985": 87, "4274808": 87, "2910417": 87, "3521430": 87, "3752198": 87, "2768053": 87, "2692938": 87, "2014675": 87, "2070880": 87, "1261298": 87, "new_data": 87, "newdata": [87, 88], "745373708644577": 87, "front": 88, "libari": 88, "matrixstat": 88, "denois": 88, "gplot": 88, "rcolorbrew": 88, "plot3d": 88, "car": [88, 90, 105], "foreach": [88, 96], "rcpp": 88, "sparsem": 88, "minqa": [88, 93], "nloptr": [88, 93], "lazyev": 88, "cardata": 88, "abind": 88, "pbkrtest": 88, "quantreg": 88, "htmlwidget": 88, "httpuv": 88, "crosstalk": 88, "promis": 88, "numderiv": 88, "dt": 88, "ellips": 88, "emmean": 88, "flashclust": 88, "leap": [88, 98], "multcompview": 88, "scatterplot3d": 88, "ggrepel": 88, "irlba": 88, "factomin": 88, "bitop": 88, "catool": 88, "misc3d": 88, "1mattach": [88, 93, 99], "22m": [88, 91, 93, 99], "32m": [88, 93, 99], "39m": [88, 93, 99], "34mdplyr": [88, 93, 99], "34mreadr": [88, 93, 99], "34mforcat": [88, 93, 99], "34mstringr": [88, 93, 99], "34mggplot2": [88, 93, 99], "34mtibbl": [88, 93, 99], "34mlubrid": 88, "34mtidyr": [88, 93, 99], "34mpurrr": [88, 93, 99], "1mconflict": [88, 93, 99], "tidyverse_conflict": [88, 93, 99], "31m": [88, 93, 99], "32mexpand": [88, 93], "mask": [88, 93, 99], "34mmatrix": [88, 93], "32mfilter": [88, 93, 99], "34mstat": [88, 93, 99], "32mlag": [88, 93, 99], "32mpack": [88, 93], "pack": [88, 93], "32mselect": 88, "34mmass": 88, "32munpack": [88, 93], "unpack": [88, 93], "36m\u2139": 88, "3m": [88, 99], "34m": 88, "org": 88, "23m": [88, 99], "becom": [88, 89, 92, 93, 96, 99, 101, 102, 103], "attach": [88, 105], "dplyr": [88, 99, 104], "lowess": 88, "tk": 88, "everytim": [88, 99], "medv": 88, "lstat": [88, 105], "cars93": [88, 90, 105], "scatter3d": 88, "phi": 88, "tilt": 88, "zlab": 88, "footbal": 88, "confirm": 88, "546": [88, 91], "194": 88, "89": [88, 89, 90, 94, 105], "189": 88, "579": 88, "5999": 88, "519": 88, "540": 88, "622": 88, "097": 88, "102": 88, "156": 88, "281": 88, "692": 88, "75e": 88, "836": 88, "437": 88, "153": 88, "0022": 88, "274": 88, "7889": 88, "7842": 88, "168": 88, "symbol": [88, 89, 92], "num_col": 88, "unlist": 88, "lappli": [88, 99], "220": 88, "402": 88, "70": [88, 94, 99, 100, 104], "076": 88, "002": [88, 105], "69": [88, 94], "825": [88, 91], "764": 88, "140": [88, 99], "05133": 88, "658": 88, "01561": 88, "83213": 88, "165": [88, 100, 105], "31369": 88, "93918": 88, "619": 88, "53792": 88, "324": 88, "39700": 88, "532": 88, "71044": 88, "609": 88, "54471": 88, "71716": 88, "15830": 88, "608": 88, "54560": 88, "59419": 88, "31530": 88, "923": 88, "35969": 88, "highwai": [88, 90, 105], "22139": 88, "05965": 88, "232": 88, "02912": 88, "engines": [88, 90, 105], "54": [88, 94, 103, 105], "32469": 88, "99456": 88, "905": 88, "36860": 88, "32739": 88, "90113": 88, "82e": 88, "rpm": [88, 90, 105], "11785": 88, "05006": 88, "354": [88, 94], "02165": 88, "rev": [88, 90, 105], "mile": [88, 90, 97, 105], "11059": 88, "05473": 88, "021": 88, "04751": 88, "fuel": [88, 90, 105], "tank": [88, 90, 105], "58016": 88, "17775": 88, "00629": 88, "passeng": [88, 90, 105], "18737": 88, "37579": 88, "365": 88, "71620": 88, "60418": 88, "67397": 88, "096": 88, "04006": 88, "wheelbas": [88, 90, 105], "97271": 88, "32881": 88, "524": 88, "01410": 88, "81074": 88, "88571": 88, "166": 88, "86841": 88, "circl": [88, 90, 100, 105], "29436": 88, "03511": 88, "032": 88, "30583": 88, "rear": [88, 90, 105], "seat": [88, 90, 105], "room": [88, 90, 105], "53080": 88, "04313": 88, "059": 88, "95338": 88, "luggag": [88, 90, 105], "06806": 88, "94515": 88, "44783": 88, "114": 88, "missing": 88, "9674": 88, "9588": 88, "111": 88, "queri": [88, 98], "exclud": [88, 98, 99], "tild": 88, "fit_new": 88, "237": 88, "809": 88, "68": [88, 90, 94, 105], "733": [88, 90], "621": 88, "685": 88, "227": [88, 105], "473": 88, "147": [88, 93], "72555": 88, "651": 88, "85150": 88, "82142": 88, "96356": 88, "249": 88, "11030": 88, "305": 88, "76137": 88, "95766": 88, "497": 88, "76892": 88, "297": [88, 105], "76722": 88, "74": [88, 93], "20151": 88, "248": [88, 98], "91613": 88, "298": 88, "76656": 88, "03821": 88, "10838": 88, "773": 88, "44245": 88, "32891": 88, "75157": 88, "209": 88, "03068": 88, "86820": 88, "69431": 88, "571": [88, 105], "02e": 88, "08711": 88, "03597": 88, "422": 88, "01819": 88, "09151": 88, "05010": 88, "826": 88, "07232": 88, "29": [88, 94], "29317": 88, "63264": 88, "755": 88, "00758": 88, "43428": 88, "61187": 88, "081": 88, "04135": 88, "52055": 88, "25976": 88, "479": 88, "01572": 88, "16370": 88, "61106": 88, "015": 88, "98774": 88, "52630": 88, "96200": 88, "071": 88, "28813": 88, "78306": 88, "61133": 88, "62082": 88, "43697": 88, "79114": 88, "698": 88, "48773": 88, "9669": 88, "9594": 88, "128": [88, 89], "swap": [88, 104], "mostli": [88, 90, 102], "carseat": 88, "workspac": 88, "sale": 88, "comppric": 88, "incom": 88, "advertis": 88, "shelveloc": 88, "educ": [88, 93], "urban": 88, "400": 88, "thousand": [88, 93, 100], "charg": 88, "competitor": 88, "dollar": [88, 100], "budget": 88, "compani": 88, "region": 88, "medium": 88, "shelv": 88, "No": [88, 100, 101, 103], "rural": 88, "pai": 88, "attent": 88, "9208": 88, "7503": 88, "0177": 88, "6754": 88, "3413": 88, "5755654": 88, "0087470": 88, "22e": 88, "0929371": 88, "0041183": 88, "567": 88, "0108940": 88, "0026044": 88, "183": 88, "57e": 88, "0702462": 88, "0226091": 88, "107": 88, "002030": 88, "0001592": 88, "0003679": 88, "433": 88, "665330": 88, "1008064": 88, "0074399": 88, "549": 88, "shelvelocgood": 88, "8486762": 88, "1528378": 88, "724": 88, "shelvelocmedium": 88, "9532620": 88, "1257682": 88, "0579466": 88, "0159506": 88, "633": 88, "000318": 88, "0208525": 88, "0196131": 88, "063": 88, "288361": 88, "urbany": 88, "1401597": 88, "1124019": 88, "247": 88, "213171": 88, "usy": 88, "1575571": 88, "1489234": 88, "058": [88, 90], "290729": 88, "0007510": 88, "0002784": 88, "007290": 88, "0001068": 88, "0001333": 88, "801": 88, "423812": 88, "011": 88, "386": 88, "8761": 88, "8719": 88, "210": 88, "automat": [88, 92, 96, 99, 102, 103, 104], "recod": 88, "goodmedium": 88, "bad00": 88, "good10": 88, "medium01": 88, "therefor": [88, 92, 93, 104], "bump": 88, "held": 88, "complic": [88, 89, 102], "longer": [88, 90, 92, 98, 99, 102], "watch": [88, 89], "carefulli": 88, "redefin": 88, "componenet": 88, "essenti": [88, 104], "linearli": 88, "lrsim": 88, "signal": 88, "singular": [88, 89], "decomposit": 88, "svd": 88, "moment": [88, 99, 102], "intercorrel": 88, "make_data": 88, "otheriws": 88, "degree_diff": 88, "space": [88, 92, 96, 104], "strongest": 88, "okai": [88, 102], "78569": 88, "62726": 88, "07531": 88, "59695": 88, "57939": 88, "03523": 88, "04533": 88, "777": 88, "4375": 88, "41500": 88, "61": [88, 94, 99, 100], "86812": 88, "395": 88, "6933": 88, "17653": 88, "10736": 88, "321": 88, "7480": 88, "x3": 88, "62072": 88, "67": [88, 99], "64961": 88, "260": 88, "7946": 88, "x4": 88, "45193": 88, "71": [88, 90, 91, 94, 99], "72453": 88, "1242": 88, "x5": 88, "11625": 88, "66273": 88, "588": 88, "5571": 88, "x6": 88, "133": 88, "22155": 88, "01748": 88, "018": 88, "0442": 88, "x7": 88, "86": [88, 90, 93, 94, 100, 104], "10253": 88, "68913": 88, "1227": 88, "x8": 88, "116": [88, 89], "70388": 88, "10784": 88, "739": 88, "0827": 88, "x9": 88, "108": 88, "78295": 88, "26610": 88, "1170": 88, "x10": 88, "71434": 88, "53488": 88, "4734": 88, "x11": 88, "51462": 88, "53258": 88, "064": 88, "2880": 88, "x12": 88, "94582": 88, "68294": 88, "793": 88, "4284": 88, "x13": 88, "71852": 88, "98526": 88, "171": 88, "8647": 88, "x14": 88, "02868": 88, "56074": 88, "055": 88, "9566": 88, "x15": 88, "80215": 88, "89896": 88, "906": 88, "3654": 88, "x16": 88, "39623": 88, "93919": 88, "638": 88, "1020": 88, "x17": 88, "76793": 88, "71295": 88, "686": 88, "4930": 88, "x18": 88, "36": [88, 90, 91, 94, 99], "66511": 88, "41676": 88, "552": 88, "5812": 88, "x19": 88, "25835": 88, "65191": 88, "244": 88, "8071": 88, "x20": 88, "65573": 88, "36835": 88, "2693": 88, "003": 88, "1889": 88, "155": 88, "577": 88, "266e": 88, "linkag": 88, "brewer": 88, "pal": 88, "rdbu": 88, "trace": 88, "none": 88, "rich": 88, "focu": [88, 90, 92, 94, 101, 104], "half": [88, 89, 90], "bv_lm": 88, "p_max": 88, "set_id": 88, "yhat_train": 88, "yhat_test": 88, "rss": [88, 98], "bv_df": 88, "geom_lin": [88, 93, 101, 103, 104], "darkr": 88, "noisi": [88, 93, 100], "skyrocket": 88, "squint": [88, 98], "clearer": [88, 93, 103], "n_iter": 88, "2000": 88, "aggreg": 88, "run_df": 88, "rowmean": 88, "strain": 88, "rowsd": 88, "stest": 88, "steelblu": 88, "linetyp": [88, 101, 103], "twodash": 88, "dash": [88, 92, 101, 103], "tim": 88, "verstynen": 88, "walk": [89, 92, 96, 98, 102, 103], "feel": [89, 90, 103], "skim": 89, "everyon": [89, 100], "wikipedia": 89, "seri": [89, 91, 99], "arrang": [89, 93, 104], "data_point": 89, "vector_1": 89, "vector_2": 89, "bmatrix": 89, "e_i": 89, "y_i": [89, 101], "bold": 89, "e_1": 89, "e_2": 89, "e_3": 89, "y_1": 89, "y_2": 89, "y_3": 89, "_1": 89, "_2": 89, "_3": 89, "summat": [89, 101], "x_i": [89, 101], "x_n": 89, "x_2": [89, 101], "x_3": 89, "nest": [89, 92, 93], "occasion": 89, "colsum": 89, "multipli": [89, 101], "prod_": [89, 101], "cover": [89, 99], "foil": [89, 101], "6x_i": 89, "care": [89, 91], "commut": 89, "6x_1": 89, "6x_2": 89, "6x_3": 89, "lastli": 89, "bring": [89, 103], "outsid": [89, 97, 101, 103, 104], "ok": [89, 99], "rectangular": 89, "a_": 89, "th": 89, "sample_matrix_by_col": 89, "byrow": 89, "sample_matrix_by_row": 89, "1357": 89, "246810": 89, "1234": 89, "678910": 89, "specifii": 89, "extent": 89, "square_matrix_4": 89, "square_matrix_10": 89, "913": 89, "261014": 89, "371115": 89, "481216": 89, "11121314151617181": 89, "91": [89, 90, 94, 99, 100, 104, 105], "21222324252627282": 89, "92": [89, 94, 99], "31323334353637383": 89, "93": [89, 90, 94, 99, 100], "41424344454647484": 89, "94": [89, 91, 94, 100], "51525354555657585": 89, "61626364656667686": 89, "96": [89, 94, 104, 105], "71727374757677787": 89, "97": [89, 94, 105], "81828384858687888": 89, "98": [89, 94], "91929394959697989": 89, "99": [89, 91, 93, 94, 104], "102030405060708090100": 89, "touch": 89, "transpos": 89, "symmetric_matrix": 89, "triangular": 89, "61014": 89, "9101115": 89, "13141516": 89, "lgl": [89, 98, 100], "truetruetruetru": 89, "everywher": 89, "mat": 89, "diag": 89, "01000": 89, "00100": 89, "00010": 89, "00001": 89, "row_index": 89, "column_index": 89, "6th": 89, "5th": 89, "135": [89, 90, 93, 96], "246": [89, 90], "mat_1": 89, "mat_2": 89, "wise": [89, 92], "importantli": [89, 102], "denot": [89, 98, 99], "switch": [89, 99, 102], "transposed_mat_2": 89, "tranpos": 89, "mention": [89, 103], "2x2": 89, "bg": 89, "af": 89, "bh": 89, "ce": [89, 101], "dg": [89, 101], "cf": [89, 101], "dh": 89, "1428571": 89, "3333333": 89, "4545455": 89, "2500000": 89, "4000000": 89, "reciproc": 89, "usual": [89, 91, 92], "bc": 89, "776357e": 89, "000000e": 89, "det": 89, "bigger": [89, 90, 103], "invert": 89, "unassoci": 89, "obtain": [89, 93], "grad": [90, 92], "univers": 90, "illinoi": 90, "chicago": [90, 104], "reiter": 90, "m_e": 90, "put": [90, 91, 92, 93, 94, 99, 101], "rightarrow": 90, "coupl": [90, 101], "spanish": 90, "who": [90, 91, 92], "spain": [90, 104], "abil": 90, "speak": 90, "comprehend": 90, "listen": 90, "attend": 90, "mood": 90, "attende": 90, "m_o": 90, "perhap": 90, "stronger": [90, 93, 97], "regard": 90, "deem": 90, "anxieti": 90, "efficaci": 90, "unimport": 90, "exam": 90, "defici": 90, "boston": 90, "peak": 90, "punta": 90, "arena": 90, "chile": 90, "septemb": 90, "sunni": 90, "florida": 90, "weak": 90, "nonexist": 90, "airbag": [90, 105], "drivetrain": [90, 105], "cylind": [90, 105], "man": [90, 105], "tran": [90, 105], "carri": [90, 91], "gallon": [90, 97], "fitstart": 90, "4720": 90, "2919": 90, "5052": 90, "7081": 90, "3147": 90, "41": [90, 94, 99, 100], "2587": 90, "4697": 90, "3934": 90, "4759": 90, "46e": 90, "742": 90, "2175": 90, "2089": 90, "456e": 90, "heavier": 90, "air": [90, 104], "resist": 90, "ga": 90, "maintain": [90, 92, 97, 99], "speed": [90, 91, 93], "lighter": 90, "compact": 90, "awai": [90, 100], "iv": 90, "fiti": 90, "dv": 90, "1036": 90, "381": 90, "308": 90, "1276": 90, "1475": 90, "257": 90, "27e": 90, "314": 90, "336": [90, 94], "85e": 90, "494": 90, "3061": 90, "2985": 90, "7134": 90, "8418": 90, "0271": 90, "8858": 90, "5668": 90, "8777927": 90, "9165318": 90, "069": 90, "0071983": 90, "0006692": 90, "756": 90, "1321634": 90, "3799662": 90, "348": [90, 94], "729": 90, "154": [90, 93], "6576": 90, "quasi": 90, "ci": 90, "857": 90, "382": 90, "371": [90, 91], "43": [90, 94, 99, 100], "prop": [90, 99], "942": [90, 93], "688": 90, "establish": [90, 96, 102], "opposit": [90, 101], "ouput": 90, "amd": 90, "engin": [90, 92], "fitmod": 90, "6537": 90, "9269": 90, "2388": 90, "9899": 90, "6858": 90, "551e": 90, "537e": 90, "440": 90, "347e": 90, "955e": 90, "02": [90, 91, 99], "406": [90, 99], "000991": 90, "132e": 90, "493e": 90, "585": 90, "06e": 90, "822e": 90, "377": 90, "001088": 90, "984": 90, "6969": 90, "6867": 90, "medh": 90, "vi": 90, "highhorsepow": 90, "ifels": 90, "oop": 90, "delv": 91, "lmer": [91, 93], "maechler": 91, "bolker": 91, "walker": 91, "eigen": 91, "classroom": 91, "sleepstudi": 91, "reactiondayssubject": 91, "56000308": 91, "2258": 91, "70471308": 91, "3250": 91, "80062308": 91, "4321": 91, "43983308": 91, "5356": 91, "85194308": 91, "6414": 91, "69015308": 91, "night": 91, "restrict": [91, 97], "180": [91, 105], "consecut": 91, "iid": 91, "1m": [91, 99], "baselin": [91, 93], "tangent": 91, "knew": 91, "gui": [91, 102], "335": 91, "he": 91, "thrive": 91, "fe": 91, "848": 91, "483": 91, "142": 91, "139": 91, "953": 91, "251": 91, "405": 91, "38": [91, 94, 96, 100], "033": 91, "467": 91, "238": 91, "454": 91, "89e": 91, "47": [91, 94], "178": [91, 93], "2865": 91, "2825": 91, "46": [91, 94, 99], "894e": 91, "ignor": [91, 101], "usag": [91, 92, 99], "analyst": 91, "me": 91, "fit1": 91, "reml": [91, 93], "lmermod": 91, "converg": [91, 93, 96, 97], "1743": 91, "9536": 91, "4634": 91, "0231": 91, "1793": 91, "corr": 91, "741": 91, "922": 91, "654": 91, "592": 91, "838": 91, "771": 91, "intr": 91, "138": 91, "1786": 91, "2257": 91, "5529": 91, "0109": 91, "5188": 91, "2506": 91, "1378": 91, "960": 91, "4051": 91, "7467": 91, "79": [91, 94], "4673": 91, "8042": 91, "77": [91, 94], "conserv": [91, 93], "domain": 91, "bound": [91, 105], "lmertest": 91, "quanitifi": 91, "lost": [91, 103], "unexplain": 91, "akaik": 91, "ic": 91, "diff": [91, 93], "dfaic": 91, "fit31906": 91, "293": 91, "fit161755": 91, "fit241794": 91, "465": 91, "66478439641238": 91, "8368134349694": 91, "lowest": [91, 94, 96, 98], "carpentri": [92, 102], "style": [92, 99], "handbook": 92, "41018": 92, "avar": 92, "bvar": 92, "cvar": 92, "avarbvarcvar": 92, "14one": 92, "25two": 92, "36three": 92, "456": 92, "114one": 92, "bracket": 92, "construct": [92, 97], "testabl": 92, "perfom": 92, "elmin": 92, "redund": [92, 94, 104], "repetit": [92, 97], "discret": [92, 103], "certain": [92, 93, 99, 101, 102, 103], "statement": [92, 103], "temperatur": 92, "fanrenheit": 92, "celsiu": 92, "fahrenheit_to_celsiu": 92, "temp_f": 92, "bodi": 92, "convers": 92, "curli": 92, "brace": 92, "temp_c": 92, "especi": [92, 101], "phase": [92, 96], "explicitli": [92, 102], "freez": 92, "water": 92, "212": 92, "function_nam": 92, "input_1": 92, "my_sum": 92, "input_2": 92, "patrick": 92, "mineault": 92, "phd": 92, "particularli": [92, 104], "postdoc": 92, "whose": 92, "gem": 92, "punctuat": 92, "butitsuremakesthingseasiertoread": 92, "deriv": [92, 93, 97], "arbitrari": [92, 104], "underscor": 92, "fit_model": 92, "utility_funct": 92, "foo": 92, "prefix": 92, "similarli": [92, 93, 101, 102], "lowercas": 92, "day_on": 92, "day_1": 92, "dayon": 92, "camel": 92, "handl": 92, "subsequ": [92, 93], "do_something_very_compl": 92, "indent": [92, 99], "long_function_nam": 92, "arrow": 92, "convent": 92, "surfac": 92, "interchang": 92, "eval": 92, "expr": 92, "envir": 92, "enclo": 92, "12345678910": 92, "instanc": 92, "fact": [92, 93, 103], "rare": 92, "annoi": [92, 99], "shortcut": [92, 99, 105], "pc": [92, 94, 99], "dfine": 92, "shorten": 92, "consider": 92, "liter": 92, "necessit": 92, "rigid": 92, "disciplin": 92, "One": [92, 93, 98, 99, 102, 103], "tip": [92, 99, 104], "ensur": [92, 104], "restart": 92, "commit": 92, "git": 92, "broadli": 92, "rstudio": [92, 105], "accumul": 92, "phenomenon": 92, "hate": 92, "Not": 92, "enorm": 92, "wast": 92, "wade": 92, "burner": 92, "old": [92, 105], "static": 92, "occur": [92, 93, 99, 102, 104], "unchang": 92, "greatli": 92, "debug": 92, "troubleshoot": 92, "small_fun1": 92, "small_fun2": 92, "big_fun": 92, "pitfal": 92, "mysteri": 92, "info": [92, 99], "magic": [92, 99], "duplic": [92, 99], "unwieldi": [92, 102], "io": [92, 99], "ifs": 92, "familiar": [92, 99, 102], "albeit": 92, "meta": 92, "inde": [92, 103, 104], "multi": 92, "docstr": 92, "readm": [92, 102], "elsewher": 92, "desir": [93, 100, 102], "accomplish": [93, 104], "offer": [93, 102], "plausibl": 93, "procedur": 93, "hors": 93, "taller": 93, "zebra": 93, "mu_h": 93, "163": 93, "cm": 93, "mu_z": 93, "sigma_h": 93, "15cm": 93, "sigma_z": 93, "7cm": 93, "compactli": 93, "height_h": 93, "mathcal": 93, "height_z": 93, "group1_mu": 93, "group1_sd": 93, "group2_mu": 93, "group2_sd": 93, "obs_group1": 93, "obs_group2": 93, "040819": 93, "4690": 93, "149": 93, "8151": 93, "4244": 93, "1182": 93, "3596": 93, "8281": 93, "2860": 93, "143": 93, "7526": 93, "0626": 93, "136": 93, "3627": 93, "run_analysi": 93, "stderr": 93, "0743144889811368": 93, "repeat_analysi": 93, "n_simul": 93, "cvg": 93, "successfulli": 93, "theta_bia": 93, "sigma_bia": 93, "sig": 93, "0208046123467318": 93, "0451000217137926": 93, "anim": 93, "stai": [93, 101], "law": 93, "00173086593671076": 93, "0370144165042127": 93, "18546": 93, "811": 93, "00493198128999189": 93, "0319896690283605": 93, "results_n5": 93, "results_n10": 93, "power_df": 93, "cbind": [93, 100, 105], "n5": 93, "n10": 93, "n_sampl": 93, "geom_histogram": [93, 103], "stat_bin": [93, 103, 104], "bin": [93, 103, 104], "pick": [93, 94, 96, 103, 104], "binwidth": [93, 103, 104], "nearli": 93, "wider": 93, "autom": [93, 103], "revisit": 93, "architectur": 93, "unnest": [93, 99], "imposs": 93, "combo": [93, 99], "neatli": 93, "tibbl": [93, 99], "idsample_sizealphapow": 93, "120": 93, "050": 93, "230": 93, "451": 93, "340": [93, 94], "704": 93, "450": [93, 104], "847": 93, "670": 93, "982": 93, "geom_hlin": [93, 104], "yintercept": 93, "drew": [93, 94], "tradition": 93, "scale_color_discret": 93, "scale_x_continu": [93, 103], "reach": [93, 94, 101, 102], "strict": 93, "beauti": 93, "prime": 93, "faster": 93, "congruent": 93, "incongru": 93, "rod": 93, "psycholinguist": 93, "_intercept": 93, "_slope": 93, "refram": 93, "plu": [93, 96, 101, 103], "center": [93, 99, 101, 103], "_differ": 93, "700": 93, "drastic": 93, "adapt": 93, "wrote": 93, "statmod": 93, "timedatectl": 93, "intern": 93, "n_subject": 93, "n_trial": 93, "intercept_sd": 93, "slope_sd": 93, "trial_sd": 93, "subject_intercept": 93, "subject_slop": 93, "slower": 93, "ungroup": [93, 99, 104], "m0": 93, "lmercontrol": 93, "calc": 93, "m1": 93, "fixef": 93, "m_bic": 93, "04082020": 93, "deprec": 93, "tidyr": [93, 99], "preserv": [93, 97], "90mthi": 93, "90mcall": 93, "lifecycl": 93, "last_warn": 93, "subjectinterceptslopeprimert": 93, "1658": 93, "1670116": 93, "9944congruent": 93, "637": 93, "7850": 93, "355": [93, 94], "5954": 93, "312": 93, "3804": 93, "683": 93, "2322": 93, "641": 93, "0751": 93, "6410": 93, "541": 93, "0341": 93, "597": 93, "7813": 93, "9944congruent1001": 93, "2272": 93, "9944congruent1019": 93, "9264": 93, "2807": 93, "1596": 93, "3634congruent": 93, "630": 93, "8723": 93, "666": 93, "1075": 93, "765": 93, "4990": 93, "715": 93, "1133": 93, "515": 93, "6113": 93, "663": 93, "6446": 93, "676": 93, "5442": 93, "850": 93, "1468": 93, "564": 93, "6080": 93, "603": 93, "1024": 93, "concern": 93, "primeincongruent32": 93, "8173297042845226": 93, "406419691669633": 93, "75975221724593": 93, "rafteri": 93, "kass": 93, "1995": [93, 104], "optwrap": 93, "devfun": 93, "opt": 93, "rho": 93, "nloptwrap": 93, "nlopt_roundoff_limit": 93, "roundoff": 93, "led": 93, "newuoa": 93, "toler": 93, "idn_subjectsn_trialspowertheta_biassigma_bia": 93, "120200": 93, "006": [93, 99], "00641936810": 93, "07373782": 93, "230200": 93, "042": 93, "00052660410": 93, "05806434": 93, "340200": 93, "00844010880": 93, "02913024": 93, "420400": 93, "084": 93, "01147605220": 93, "03539564": 93, "530400": 93, "379": 93, "00188869910": 93, "08232914": 93, "640400": 93, "747": 93, "00208821350": 93, "05321679": 93, "720600": 93, "374": 93, "00420983240": 93, "05045607": 93, "830600": 93, "810": 93, "00679313510": 93, "05428755": 93, "940600": 93, "974": 93, "00296774270": 93, "02187785": 93, "pass": [93, 96, 97, 99, 103, 104], "neither": 93, "suffici": [93, 96], "008": 93, "inflat": 93, "takeawai": 93, "wtih": 93, "homogen": 93, "yourself": [93, 101], "plsr": 94, "physic": 94, "reduct": 94, "statquest": 94, "quick": [94, 101], "iri": [94, 99, 100], "petal": [94, 99, 100], "sepal": [94, 99, 100], "subspeci": 94, "flower": [94, 99, 100], "lengthsep": [94, 99, 100], "widthpet": [94, 99, 100], "lengthpet": [94, 99, 100], "widthspeci": [94, 99, 100], "2setosa": [94, 99, 100], "4setosa": [94, 99, 100], "convinc": 94, "ourselv": 94, "0000000": 94, "1175698": 94, "8717538": 94, "8179411": 94, "4284401": 94, "3661259": 94, "9628654": 94, "speci": [94, 99], "enough": [94, 100], "prcomp": 94, "sdev": 94, "root": 94, "eigenvalu": 94, "pc1pc2pc3pc4": 94, "5210659": 94, "37741762": 94, "7195664": 94, "2612863": 94, "2693474": 94, "92329566": 94, "2443818": 94, "1235096": 94, "5804131": 94, "02449161": 94, "1421264": 94, "8014492": 94, "5648565": 94, "06694199": 94, "6342727": 94, "5235971": 94, "pc1": 94, "almost": [94, 103], "evenli": 94, "pc2": 94, "heavili": 94, "coordin": 94, "257141": 94, "4784238": 94, "12727962": 94, "024087508": 94, "074013": 94, "6718827": 94, "23382552": 94, "102662845": 94, "356335": 94, "3407664": 94, "04405390": 94, "028282305": 94, "291707": 94, "5953999": 94, "09098530": 94, "065735340": 94, "381863": 94, "6446757": 94, "01568565": 94, "035802870": 94, "068701": 94, "4842053": 94, "02687825": 94, "006586116": 94, "job": 94, "firmer": 94, "grasp": [94, 104], "hitter": [94, 96, 98], "hit": [94, 96, 98], "salari": [94, 96, 98, 100], "trigger": 94, "263": 94, "svdpc": 94, "rmsep": 94, "segment": 94, "comp": 94, "452": 94, "351": 94, "343": 94, "adjcv": 94, "342": 94, "345": 94, "349": 94, "358": 94, "344": 94, "346": 94, "350": [94, 105], "356": 94, "339": 94, "338": 94, "337": 94, "88": [94, 96], "82": [94, 99], "53": [94, 99, 105], "unless": [94, 102], "val": 94, "ncomp": 94, "142811": 94, "810376319": 94, "131": 94, "kernelpl": 94, "428": 94, "325": 94, "329": 94, "328": 94, "327": 94, "78": 94, "57": [94, 96], "interestingli": 94, "rmse": 94, "151995": 94, "259555806": 94, "maxim": [94, 96, 101], "roberto": 95, "varga": 95, "tehcniqu": 96, "hyperparamet": 96, "basebal": [96, 98], "atbat": [96, 98], "hmrun": [96, 98], "rbi": [96, 98], "catbat": [96, 98], "chit": [96, 98], "chmrun": [96, 98], "crun": [96, 98], "crbi": [96, 98], "cwalk": [96, 98], "leagu": [96, 98], "putout": [96, 98], "assist": [96, 98], "newleagu": [96, 98], "lar": 96, "tune": 96, "l2": 96, "norm": 96, "l1": 96, "pressur": 96, "search": [96, 104, 105], "lambda_search_spac": 96, "extrem": [96, 105], "spars": 96, "lenient": 96, "elast": 96, "net": 96, "algorithm": [96, 98], "pure": 96, "mod": 96, "20100": 96, "11497": 96, "50th": 96, "coeff": [96, 97], "lamba": 96, "5699539774": 96, "retain": [96, 99], "5722367659": 96, "35022": 96, "11498": 96, "thresh": 96, "1e10": 96, "newx": 96, "ol": 96, "224669": 96, "833069663": 96, "142199": 96, "150722761": 96, "167789": 96, "778381119": 96, "upon": 96, "henc": 96, "util": 96, "contamin": 96, "train_hyperparamet": 96, "train_glm": 96, "test_hyperparamet": 96, "test_glm": 96, "bestlam": 96, "145590162423": 96, "390": 96, "119507": 96, "530651601": 96, "refit": 96, "dedic": 96, "win": 96, "812546181": 96, "007535828": 96, "517425980": 96, "090339763": 96, "407753980": 96, "037274878": 96, "172859070": 96, "143396736": 96, "014712552": 96, "109118248": 96, "leaguen": [96, 98], "177487099": 96, "183558581": 96, "171052370": 96, "023204448": 96, "742320818": 96, "divisionw": [96, 98], "newleaguen": [96, 98], "771290300": 96, "234770575": 96, "035088669": 96, "551198110": 96, "358141646": 96, "reus": 97, "varaibl": 97, "shuffl": 97, "target": [97, 102], "con": 97, "major": [97, 100], "wild": 97, "fn": 97, "9358610": 97, "1578447": 97, "saniti": 97, "boot_obj": 97, "t1": 97, "t2": 97, "nonparametr": 97, "0337235546": 97, "869718268": 97, "0003595084": 97, "007482048": 97, "t0": 97, "stype": 97, "strata": 97, "boot_typ": 97, "_": [97, 99], "estimatestd": 97, "errort": 97, "valuepr": 97, "93586100": 97, "717498656": 97, "659841": 97, "220362e": 97, "15784470": 97, "006445501": 97, "48914": 97, "031989e": 97, "1578": 97, "By": [97, 104], "nil": 97, "permauto": 97, "smake": 97, "perm": 97, "scrambl": 97, "eyebal": 97, "intact": 97, "tour": 98, "26320": 98, "omit": 98, "annual": 98, "regfit": 98, "asterisk": 98, "exhaust": 98, "quot": 98, "colum": 98, "nvmax": 98, "reg": 98, "rsq": 98, "adjr2": 98, "outmat": 98, "obj": 98, "atbathitshmrunrunsrbiwalksyearscatbatchitschmruncrunscrbicwalksleaguendivisionwputoutsassistserrorsnewleaguen": 98, "1truefalsefalsefalsefalsefalsefalsefalsefalsefalsefalsefals": 98, "truefalsefalsefalsefalsefalsefalsefals": 98, "2truefals": 98, "truefalsefalsefalsefalsefalsefalsefalsefalsefals": 98, "3truefals": 98, "truefalsefalsefals": 98, "4truefals": 98, "truefalsefals": 98, "5true": 98, "6true": 98, "truefalsefalsefalsefalsefals": 98, "7truefals": 98, "truefals": 98, "truefalsefalsefalsefals": 98, "8true": 98, "9true": 98, "10true": 98, "11true": 98, "12true": 98, "13true": 98, "14true": 98, "15true": 98, "16true": 98, "17true": 98, "18true": 98, "19true": 98, "numvar": 98, "sequenc": [98, 99], "allfals": 98, "mark": [98, 100], "minrss": 98, "maxadjr2": 98, "adj": 98, "mincp": 98, "minbic": 98, "discrep": 98, "pg": 98, "250": 98, "rope": 99, "instinct": 99, "consequ": 99, "yg": 99, "xzc1rwm52nxc0l8mlvk8dkjw0000gp": 99, "rtmpotbuza": 99, "popular": [99, 104], "var2": 99, "streamlin": 99, "straight": [99, 105], "becuas": 99, "05733333333333": 99, "digit": [99, 103], "temporari": 99, "tmp": 99, "obs_mean": 99, "smoothli": 99, "decim": 99, "track": 99, "inner": 99, "outward": 99, "clutter": 99, "intermediari": 99, "keyboard": 99, "purrr": 99, "formerli": 99, "subtract": 99, "reassign": 99, "centered_seplen": 99, "widthspeciescentered_seplen": 99, "7433333": 99, "9433333": 99, "1433333": 99, "2433333": 99, "8433333": 99, "4433333": 99, "zscore": 99, "petlen_zscor": 99, "n_flower": 99, "widthspeciescentered_seplenpetlen_zscoresn_flow": 99, "335752150": 99, "392399150": 99, "279104150": 99, "165809150": 99, "smry": 99, "shortsepal_prop": 99, "setosa_prop": 99, "setosa": [99, 100], "seplen_mean": 99, "seplen_sd": 99, "seplen_s": 99, "n_flowersshortsepal_propsetosa_propseplen_meanseplen_sdseplen_s": 99, "1500": 99, "53333330": 99, "33333335": 99, "8433330": 99, "82806610": 99, "06761132": 99, "collaps": 99, "cleaned_dat": 99, "versi": 99, "versicolor": [99, 100], "virgi": 99, "virginica": [99, 100], "4versicolor": 99, "15666670": 99, "5336209150": 99, "5versicolor": 99, "55666670": 99, "4203256150": 99, "05666670": 99, "6469162150": 99, "3versicolor": 99, "34333330": 99, "1370873150": 99, "65666670": 99, "4769732150": 99, "14333330": 99, "5virginica": 99, "456666671": 99, "2700404150": 99, "9virginica": 99, "043333330": 99, "7602115150": 99, "1virginica": 99, "256666671": 99, "2133927150": 99, "8virginica": 99, "0434497150": 99, "2virginica": 99, "656666671": 99, "1567451150": 99, "756666671": 99, "6099263150": 99, "chain": [99, 103], "seplen_meanseplen_sd": 99, "9360": 99, "5161711": 99, "5880": 99, "6358796": 99, "irrelev": 99, "speciespet": 99, "1setosa1": 99, "2setosa1": 99, "3setosa1": 99, "4setosa1": 99, "5setosa1": 99, "6setosa1": 99, "sign": [99, 102, 103], "5setosa": 99, "0setosa": 99, "1setosa": 99, "6setosa": 99, "9setosa": 99, "inclus": 99, "batch": 99, "starts_with": 99, "helper": 99, "num_rang": 99, "tidyselect": 99, "ascend": 99, "descend": 99, "surround": 99, "desc": 99, "83": 99, "0433333": 99, "052513150": 99, "3setosa": 99, "revers": 99, "petaltyp": 99, "widthspeciescentered_seplenpetlen_zscoresn_flowerspetaltyp": 99, "335752150short": 99, "392399150short": 99, "279104150short": 99, "165809150short": 99, "new_var": 99, "input1": 99, "input2": 99, "combined_var": 99, "widthcombined_varspeciescentered_seplenpetlen_zscoresn_flowerspetaltyp": 99, "2setosa_shortsetosa": 99, "4setosa_shortsetosa": 99, "species1": 99, "petaltype1": 99, "widthspecies1petaltype1speciescentered_seplenpetlen_zscoresn_flowerspetaltyp": 99, "2setosashortsetosa": 99, "4setosashortsetosa": 99, "ineffici": 99, "join": 99, "afterward": 99, "90m": 99, "\u00b9": 99, "\u00b2": 99, "\u00b3": 99, "\u2074": 99, "\u2075": 99, "cent": 99, "\u2076": 99, "petl": 99, "\u2077": 99, "31m0": 99, "31m743": 99, "31m1": 99, "31m34": 99, "31m943": 99, "31m14": 99, "31m39": 99, "31m24": 99, "31m28": 99, "31m843": 99, "31m443": 99, "31m17": 99, "31m44": 99, "90m10": 99, "abbrevi": [99, 104], "implicit": 99, "sepwid_mean": 99, "sepwid_sd": 99, "overrid": 99, "grouped_df": 99, "speciespetaltypeseplen_meanseplen_sdsepwid_meansepwid_sd": 99, "short5": 99, "0060000": 99, "35248973": 99, "4280000": 99, "3524897": 99, "versicolorlong": 99, "0465120": 99, "45374052": 99, "8232560": 99, "4537405": 99, "versicolorshort5": 99, "2571430": 99, "33094382": 99, "4428570": 99, "3309438": 99, "5880000": 99, "63587962": 99, "9740000": 99, "scene": 99, "dat_cent": 99, "seplen_centered_overal": 99, "seplen_centered_byspeci": 99, "speciesseplen_centered_overallseplen_centered_byspeci": 99, "094": 99, "394": 99, "seplen_centering_byspeci": 99, "meanwhil": 99, "seplen_centering_overal": 99, "regardless": 99, "widthspeciespetaltyp": 99, "2setosashort": 99, "4setosashort": 99, "90m1": 99, "90m2": 99, "90m3": 99, "becam": 99, "widthpetaltyp": 99, "2short": 99, "4short": 99, "wait": 99, "90m4": 99, "fanci": 99, "sappli": 99, "subgroup": 99, "nested_lm": 99, "nest_df": 99, "21316822303424petal": 99, "length0": 99, "542292597103803": 99, "1276221410204282": 99, "07237785897956363": 99, "2181485992691844": 99, "42660711868994550": 99, "02762214102043660": 99, "2649343618892957": 99, "3723778589795648": 99, "02660711868994449": 99, "57237785897956410": 99, "126607118689944110": 99, "37339288131005612": 99, "28083637840032513": 99, "17237785897956414": 99, "509690079848423150": 99, "936080660441196160": 99, "673392881310056170": 99, "481851400730817180": 99, "127622141020436190": 99, "564934361889295200": 99, "0733928813100553210": 99, "264934361889295220": 99, "073392881310055323": 99, "15546082013804324": 99, "035065638110705325": 99, "44352415753146626": 99, "080836378400324727": 99, "0808363784003247280": 99, "173392881310056290": 99, "22762214102043630": 99, "38083637840032431": 99, "280836378400325320": 99, "373392881310056330": 99, "173392881310056340": 99, "52762214102043635": 99, "126607118689944360": 99, "136080660441197370": 99, "58185140073081638": 99, "072377858979563739": 99, "518148599269183400": 99, "0733928813100553410": 99, "081851400730816242": 99, "41814859926918443": 99, "51814859926918344": 99, "080836378400324745": 99, "14352415753146646": 99, "172377858979564470": 99, "019163621599674948": 99, "372377858979564490": 99, "273392881310055500": 99, "027622141020436": 99, "super": 99, "ugli": 99, "542": 99, "858": 99, "90m5": 99, "90m6": 99, "865": 99, "90m7": 99, "90m8": 99, "996": 99, "omayma": 99, "climate_change_expanalysi": 99, "aslo": 99, "newdat": 99, "widthspeciesflow": 99, "2setosa2": 99, "2setosa3": 99, "2setosa4": 99, "2setosa5": 99, "4setosa6": 99, "names_to": 99, "values_to": 99, "concaten": 99, "iris_attribut": 99, "speciesflow": 99, "numiris_attributevalu": 99, "setosa1sep": 99, "length5": 99, "setosa1pet": 99, "length1": 99, "setosa2sep": 99, "length4": 99, "tidier": 99, "names_from": 99, "values_from": 99, "numsep": 99, "setosa15": 99, "setosa24": 99, "setosa34": 99, "setosa44": 99, "setosa55": 99, "setosa65": 99, "inner_join": 99, "right_join": 99, "full_join": 99, "p01": 99, "p02": 99, "p03": 99, "firstlang": 99, "chines": 99, "nameagefirstlang": 99, "1p0118english": 99, "2p0221chines": 99, "3p0323english": 99, "namerespons": 99, "1p010": 99, "2p011": 99, "3p021": 99, "4p020": 99, "nameagefirstlangrespons": 99, "2p0118english": 99, "3p0221chines": 99, "4p0221chines": 99, "5p0323englishna": 99, "1p0118english0": 99, "2p0118english1": 99, "3p0221chinese1": 99, "4p0221chinese0": 99, "straightforward": 100, "bunch": 100, "closest": 100, "whichev": 100, "ind": 100, "widthspeciesi": 100, "testspecies_predknn_correct": 100, "2setosafalsesetosatru": 100, "4setosafalsesetosatru": 100, "spec": 100, "versicolorvirginicasetosasetosaversicolorversicolorsetosavirginicavirginicasetosa": 100, "species_pr": 100, "knn_correct": 100, "ggtitl": [100, 105], "solid": [100, 103], "edg": 100, "green": 100, "866666666666667": 100, "mislabel": 100, "viginica": 100, "species_predk1": 100, "species_predk100": 100, "misclassifi": 100, "border": [100, 103], "strai": 100, "notabl": 100, "farther": 100, "verginica": 100, "suffer": 100, "caravan": 100, "bought": 100, "insur": 100, "purchas": 100, "abystand": 100, "mostypemaanthuimgemomvmgemleefmoshoofdpurchas": 100, "133132": 100, "8no": 100, "237122": 100, "337122": 100, "9133": 100, "3no": 100, "54014210no": 100, "623121": 100, "5no": 100, "vastli": 100, "037847395189": 100, "164707781931954": 100, "proper": 100, "soon": 100, "1001": 100, "purch": 100, "941": 100, "bui": 100, "fluke": 100, "paul": 101, "dx": 101, "lim_": 101, "satisfi": [101, 102], "connect": [101, 102, 103], "2x": 101, "df_dx": 101, "x_dat": 101, "func": 101, "relevel": 101, "010": 101, "040": 101, "090": 101, "160": 101, "sin": 101, "x_min": 101, "xintercept": 101, "steep": 101, "dot": [101, 103], "dmse": 101, "flat": [101, 105], "nx": 101, "3x": 101, "q": [101, 105], "rewritten": 101, "1x": 101, "4x": 101, "8x": 101, "dx_1": 101, "dx_2": 101, "2x_1": 101, "4x_1x_2": 101, "4x_2": 101, "4x_1": 101, "2x_2": 101, "trickier": 101, "jump": 101, "log_": 101, "rais": 101, "ln": 101, "relatedli": 101, "monoton": 101, "log_f": 101, "flatter": 101, "beta_1x_i": 101, "pain": 101, "fourth": 101, "cy": 101, "2cxy": 101, "2y": 101, "2ce": 101, "2c": 101, "2var": 101, "folk": 101, "fear": 101, "mental": 102, "earli": 102, "request": 102, "advisor": 102, "suddenli": 102, "surprisingli": 102, "backup": 102, "forth": 102, "interfac": 102, "paragraph": 102, "gitkraken": 102, "versatil": 102, "app": 102, "complementari": 102, "servic": 102, "host": 102, "onlin": 102, "sync": 102, "scm": 102, "privat": [102, 104], "memor": 102, "config": 102, "andrew": 102, "usernam": 102, "password": 102, "token": 102, "proceed": 102, "corner": 102, "lieu": 102, "login": 102, "repo": 102, "permiss": 102, "unix": 102, "shell": 102, "navig": 102, "cd": 102, "foldernam": 102, "ever": [102, 103], "pwd": 102, "dir": 102, "hassl": 102, "readi": [102, 104], "coaxlab": 102, "datasciencepsychneuro_cmu85732": 102, "mkdir": 102, "pathnam": 102, "data_sci": 102, "my_awesome_project": 102, "colon": 102, "yournam": 102, "remot": 102, "myusernam": 102, "nameofrepositori": 102, "laptop": 102, "period": 102, "filenam": 102, "script1": 102, "script2": 102, "draft": 102, "experiment": 102, "stimuli": 102, "gitignor": 102, "spent": 102, "revis": 102, "briefli": 102, "hasn": 102, "tree": 102, "protect": 102, "checkout": 102, "nameofnewbranch": 102, "creation": 102, "branchnam": 102, "simultan": 102, "newer": 102, "devot": 102, "weirdtestbranch": 102, "pan": 102, "wish": 102, "discard": 102, "filetokeep": 102, "unsur": 102, "3a": 102, "myproject": 102, "3b": 102, "scratch": 102, "possibli": 102, "upstream": 102, "happi": [102, 104], "specialbranchfornewfeatur": 102, "rins": 102, "fortun": 102, "ton": 102, "jenni": 102, "bryan": 102, "bookdown": 102, "ey": 102, "workshop": 102, "regularli": 102, "sheet": 103, "cheat": 103, "geometr": 103, "dissect": 103, "aesteth": 103, "x_axi": 103, "readibl": 103, "clariti": 103, "overplot": 103, "dsmall": 103, "ordin": 103, "n_shape": 103, "advis": 103, "AND": 103, "broad": 103, "densiti": 103, "datapoint": [103, 104], "geom_col": 103, "geom_til": 103, "geom_dens": 103, "bandwidth": 103, "selector": 103, "summarising_funct": 103, "typeofplot": 103, "mean_s": 103, "stat_summary_2d": 103, "geom_boxplot": 103, "pointrang": 103, "geom_seg": [103, 104], "expens": 103, "scarciti": 103, "highgest": 103, "logarithm": 103, "squash": 103, "tail": [103, 105], "skew": 103, "linerang": 103, "log_carat": 103, "log_pric": 103, "paranoid": 103, "geom_dotplot": 103, "binaxi": 103, "stackdir": 103, "stat_bindot": 103, "ggalli": 104, "guidelin": 104, "ggpair": 104, "suppress": [104, 105], "suppressmessag": 104, "piec": 104, "sj": 104, "v1s3b78s07z2w0md4brp2kmm0000gn": 104, "rtmpkw4pdx": 104, "nepali": 104, "farawai": 104, "health": 104, "nepales": 104, "rtmpfbuygz": 104, "sex": 104, "child": 104, "wt": 104, "ht": 104, "male": 104, "femal": 104, "keep_al": 104, "idsexwthtag": 104, "1120011male": 104, "241": 104, "2120012female14": 104, "9103": 104, "957": 104, "3120021femal": 104, "4120022female12": 104, "435": 104, "5120023male": 104, "449": 104, "6120031male": 104, "broken": 104, "worldcup": 104, "player": 104, "soccer": 104, "cup": 104, "chicagonmmap": 104, "dlnm": 104, "nation": 104, "morbid": 104, "mortal": 104, "pollut": 104, "nmmap": 104, "chic": 104, "chic_juli": 104, "juli": 104, "thumb": 104, "showcas": 104, "extran": 104, "theme_linedraw": 104, "theme_minim": 104, "theme_void": 104, "theme_dark": 104, "heatwav": 104, "chicago_plot": 104, "date": 104, "death": 104, "geom_area": 104, "theme_excel": 104, "excess": 104, "background": 104, "eas": 104, "orient": 104, "abrevi": 104, "messier": 104, "forcat": 104, "wc_example_data": 104, "renam": 104, "fct_recod": 104, "dc": 104, "defend": 104, "fw": 104, "forward": 104, "gk": 104, "goalkeep": 104, "mf": 104, "midfield": 104, "elimin": 104, "spell": 104, "lightgrai": 104, "advic": 104, "obviou": 104, "headspac": 104, "shade": [104, 105], "horizont": 104, "smooth": 104, "shot": 104, "theme_few": 104, "cue": 104, "wiggli": 104, "geom_ablin": [104, 105], "geom_polygon": 104, "polygon": 104, "geom_path": 104, "unfil": 104, "guidanc": 104, "obscur": 104, "ultim": 104, "overwhelm": 104, "theabov": 104, "holland": 104, "finalist": 104, "team": 104, "netherland": 104, "categori": 104, "alphabet": 104, "group_bi": 104, "mean_tim": 104, "ave_tim": 104, "min_tim": 104, "max_tim": 104, "xend": 104, "yend": 104, "grai": 104, "cookbook": 104, "websit": 104, "cheatsheet": 104, "namespac": 105, "1993": 105, "libarari": 105, "qq": 105, "dist": 105, "rougli": 105, "safe": 105, "preliminari": 105, "joint": 105, "543": 105, "87": 105, "176": 105, "899": 105, "2894": 105, "460": 105, "376": 105, "505": 105, "6501": 105, "6462": 105, "169": 105, "star": 105, "grab": 105, "29710281562": 105, "5712895035716": 105, "confit": 105, "3808": 105, "77815": 105, "1979": 105, "81606": 105, "59531": 105, "54727": 105, "inch": 105, "length_input_valu": 105, "prediction_t": 105, "pred_input_t": 105, "bind": 105, "length_input": 105, "lower_ci_bound": 105, "upper_ci_bound": 105, "length_inputpredict": 105, "fitlower_ci_boundupper_ci_bound": 105, "11652479": 105, "972364": 105, "082595": 105, "21802968": 105, "542894": 105, "533042": 105, "31953457": 105, "103364": 105, "003550": 105, "lb": 105, "3042": 105, "diagnost": 105, "suppresswarn": 105, "autoplot": 105, "reveal": 105, "strictli": 105, "rstudent": 105, "hatvalu": 105}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"fiona": 0, "test": [0, 35, 36, 39, 40, 42, 96, 97, 100, 106], "md": 0, "discuss": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "question": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "exercis": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "9": 29, "classif": 29, "1": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 80, 89, 101, 106], "load": [29, 31, 32, 34, 37, 39, 41], "format": [29, 34], "data": [29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 46, 47, 48, 53, 68, 69, 80, 85, 86, 87, 92, 93, 99, 100, 104], "point": [29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46], "2": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 80, 89, 101], "visual": [29, 32, 33, 38, 39, 75, 76, 104], "3": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 46, 80, 89, 101], "logist": [29, 39, 84], "regress": [29, 32, 38, 43, 55, 64, 84, 88, 89, 94, 96, 105], "fit": [29, 34, 38, 105], "model": [29, 31, 32, 34, 38, 40, 43, 56, 58, 59, 66, 83, 87, 88, 90, 91, 93, 96, 98, 100, 105], "4": [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 80, 101], "interpret": 29, "predict": [29, 84, 100, 105], "from": [29, 102], "5": [29, 31, 32, 33, 36, 37, 39, 45, 80, 101], "qda": [29, 84], "12": 30, "cross": [30, 52, 85, 86], "valid": [30, 52, 85, 86, 96], "pt": [30, 31, 35, 36, 42, 46], "leav": [30, 85, 86], "one": [30, 85, 86, 99], "out": [30, 82, 85, 86, 89, 95, 101], "compar": 30, "cv": 30, "glm": [30, 84], "adjust": 30, "k": [30, 85, 86, 100], "reflect": [30, 32, 33, 34, 36, 37, 38, 39], "object": [31, 53, 87], "packag": 31, "replic": 31, "summari": [31, 35, 89], "output": 31, "tabl": 31, "index": [31, 89, 92], "7": [32, 46], "linear": [32, 43, 55, 56, 88, 89, 91, 105], "initi": 32, "plot": [32, 41, 42, 45, 46, 103, 104, 105], "14": 33, "mediat": [33, 57, 90], "simul": [33, 36, 38, 60, 88, 93], "analysi": [33, 37, 60, 75, 93, 94], "10": 34, "mix": [34, 58, 83, 91, 93], "effect": [34, 39, 58, 83, 91], "assess": [34, 100], "code": [35, 79, 92], "habit": [35, 92], "function": [35, 36, 92, 93, 99, 101], "statist": [35, 45, 80], "t": 35, "set": [35, 42, 85, 86, 96, 102], "default": 35, "valu": [35, 63, 72, 101], "15": 36, "power": [36, 60, 93, 101], "analys": [36, 93], "run_analysi": 36, "repeat_analysi": 36, "differ": [36, 90, 97, 102], "sampl": [36, 93], "size": [36, 93], "18": 37, "princip": [37, 61, 94], "compon": [37, 61, 94], "method": [37, 39, 61, 65], "correl": [37, 103], "structur": [37, 92], "associ": 37, "flanker": 37, "task": 37, "peform": 37, "17": 38, "regular": [38, 64], "bia": [38, 67, 88], "varianc": [38, 67, 88, 93], "tradeoff": [38, 67, 88], "polynomi": 38, "appli": 38, "bonu": 38, "extra": 38, "credit": 38, "13": 39, "resampl": [39, 65], "classifi": [39, 50, 84, 100], "bootstrap": [39, 97], "accuraci": 39, "permut": [39, 97], "grei": 39, "matter": [39, 80], "16": 40, "select": [40, 66, 98, 99], "best": [40, 66, 98], "subset": [40, 98], "forward": 40, "backward": 40, "stepwis": 40, "train": [40, 42], "error": [40, 54], "cleans": [41, 68, 99], "manipul": [41, 89], "tidyvers": [41, 99], "11": 42, "The": [42, 67, 70, 71, 72, 80, 90, 101], "beauti": [42, 70], "knn": [42, 70, 100], "v": 42, "loop": 42, "standard": [42, 99, 100], "predictor": [42, 88, 105], "8": 43, "continu": 43, "deriv": [43, 101], "maximum": 43, "likelihood": 43, "estim": [43, 83], "simpl": [43, 83, 85, 86, 105], "6": [43, 45, 46], "connect": 43, "github": [44, 102], "jupyt": [44, 82, 92, 95], "us": [45, 79, 82, 85, 86, 89, 92, 95, 100, 101, 102], "ggplot": 45, "color": 45, "type": 45, "layer": 45, "ad": [45, 79, 101, 102], "more": [46, 88, 93, 104], "option": 46, "multipanel": 46, "figur": 46, "increas": 46, "densiti": [46, 104], "explor": 47, "art": [48, 80], "investig": 48, "lectur": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "bay": [49, 83], "factor": [49, 83], "requir": [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "read": [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78], "video": [49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 106], "slide": [49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77], "pdf": [49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77], "construct": [51, 73], "testabl": [51, 59], "hypothesi": 51, "architectur": 53, "infer": [54, 105], "limit": 55, "variat": 55, "moder": [57, 90], "hypothes": 59, "via": 60, "quantit": 62, "epsitemologi": 62, "reconsid": 63, "p": 63, "techniqu": 68, "tell": 69, "your": [69, 79, 80, 93, 104], "stori": 69, "ordinari": 71, "least": [71, 94, 101], "squar": [71, 89, 94, 101], "solut": 71, "open": 72, "theori": [73, 77], "social": 73, "through": 76, "human": 76, "ey": 76, "what": [77, 78, 79, 83, 89, 93, 101, 102], "i": [77, 78, 79, 80, 83, 89, 93, 101], "learnabl": 78, "markdown": 79, "file": [79, 102], "myst": 79, "ar": [79, 101, 102], "role": 79, "direct": 79, "citat": 79, "execut": 79, "poetri": 80, "rule": [80, 101], "track": [80, 102], "chronicl": 80, "preserv": 80, "subrul": 80, "everi": 80, "detail": 80, "autom": 80, "much": 80, "you": 80, "can": 80, "proactiv": 80, "reactiv": 80, "see": 80, "languag": 80, "magic": 80, "tutori": [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "get": [82, 88, 95, 99], "start": [82, 88, 95, 99], "goal": [82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], "instal": [82, 95], "r": [82, 87, 90, 92, 95], "rstudio": [82, 95], "try": [82, 95], "julia": [82, 95], "python": [82, 95], "notebook": [82, 92, 95], "why": [82, 85, 86, 95, 101, 102], "kernel": [82, 95], "implement": [83, 85, 86], "exampl": [83, 93, 101, 102], "calcul": [83, 101], "comparison": 83, "candid": 83, "basic": [84, 89, 92, 93, 94, 96, 102, 103], "stock": 84, "market": 84, "lda": 84, "approach": [85, 86, 94], "loocv": [85, 86], "fold": [85, 86], "tidi": [87, 92], "interact": 87, "multipl": [88, 89, 99, 104], "work": [88, 89, 101, 102], "categor": 88, "qualit": 88, "refresh": [89, 101], "matric": 89, "vector": [89, 92, 99], "sum": 89, "product": [89, 101], "equat": 89, "trick": 89, "pull": [89, 102], "term": 89, "split": [89, 99], "up": [89, 102], "coeffici": 89, "matrix": 89, "kind": 89, "symmetr": 89, "ident": 89, "oper": [89, 99], "addit": 89, "subtract": 89, "transposit": 89, "divis": 89, "invers": 89, "determin": [89, 93], "solv": [89, 101], "problem": 89, "hand": 89, "run": [90, 91, 93, 100], "between": [90, 97], "introduct": 92, "good": 92, "command": 92, "arithmet": 92, "frame": [92, 99], "how": 92, "write": [92, 93], "research": 92, "practic": 92, "keep": [92, 99], "consist": 92, "delet": 92, "dead": 92, "pure": 92, "bad": 92, "thing": 92, "do": 92, "document": 92, "algorithm": 93, "sourc": 93, "artifici": 93, "conduct": 93, "intend": 93, "vari": [93, 100], "alpha": 93, "level": 93, "extend": [93, 104], "complic": 93, "But": 93, "import": [93, 96], "number": 93, "subject": 93, "trial": 93, "pca": 94, "big": 94, "pictur": 94, "partial": 94, "ridg": 96, "lasso": 96, "an": [96, 100], "note": 96, "about": 96, "boostrap": 97, "A": [97, 99, 101], "remind": 97, "grammar": 99, "pipe": 99, "transform": 99, "mutat": 99, "exist": 99, "variabl": [99, 101], "creat": 99, "new": [99, 102], "summaris": 99, "summar": 99, "filter": 99, "row": 99, "base": 99, "condit": 99, "column": 99, "remov": 99, "arrang": 99, "sort": 99, "unit": 99, "combin": 99, "two": [99, 101], "separ": 99, "group_bi": 99, "implicitli": 99, "group": 99, "nest": 99, "explicitli": 99, "map": 99, "perform": [99, 100], "same": 99, "each": 99, "element": 99, "list": 99, "restructur": 99, "long": 99, "wide": 99, "merg": [99, 102], "pivot_long": 99, "pivot_wid": 99, "_join": 99, "nearest": 100, "neighbor": 100, "intro": 100, "iris": 100, "identifi": 100, "item": 100, "speci": 100, "oridinari": 101, "tip": 101, "constant": 101, "take": 101, "find": 101, "minim": 101, "logarithm": 101, "e": 101, "quotient": 101, "expon": 101, "we": 101, "thi": 101, "class": 101, "expect": 101, "repositori": 102, "version": 102, "control": 102, "git": 102, "configur": 102, "updat": 102, "authent": 102, "process": 102, "bash": 102, "script": 102, "chang": 102, "commit": 102, "branch": 102, "onli": 102, "specif": 102, "put": 102, "all": 102, "togeth": 102, "workflow": 102, "distribut": 103, "first": 103, "aesthet": 103, "geom": 103, "advanc": 104, "ggplot2": 104, "custom": 104, "high": 104, "meaning": 104, "label": 104, "refer": 104, "small": 104, "order": 104, "resourc": 104, "singl": 105}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Fiona Test MD": [[0, "fiona-test-md"]], "Discussion questions": [[1, "discussion-questions"], [2, "discussion-questions"], [3, "discussion-questions"], [4, "discussion-questions"], [5, "discussion-questions"], [6, "discussion-questions"], [7, "discussion-questions"], [8, "discussion-questions"], [9, "discussion-questions"], [10, "discussion-questions"], [11, "discussion-questions"], [12, "discussion-questions"], [13, "discussion-questions"], [14, "discussion-questions"], [15, "discussion-questions"], [16, "discussion-questions"], [17, "discussion-questions"], [18, "discussion-questions"], [19, "discussion-questions"], [20, "discussion-questions"], [21, "discussion-questions"], [22, "discussion-questions"], [23, "discussion-questions"], [24, "discussion-questions"], [25, "discussion-questions"], [26, "discussion-questions"], [27, "discussion-questions"], [28, "discussion-questions"]], "Exercise 9: Classification": [[29, "exercise-9-classification"]], "1. Loading and formatting the data (1 point)": [[29, "loading-and-formatting-the-data-1-point"], [34, "loading-and-formatting-the-data-1-point"]], "2. Visualizing the data (1 point)": [[29, "visualizing-the-data-1-point"]], "3. Logistic Regression: Fitting the model (2 points)": [[29, "logistic-regression-fitting-the-model-2-points"]], "4. Interpreting predictions from the model (3 points)": [[29, "interpreting-predictions-from-the-model-3-points"]], "5. QDA (3 points)": [[29, "qda-3-points"]], "Exercise 12: Cross validation": [[30, "exercise-12-cross-validation"]], "1: Data (1 pts)": [[30, "data-1-pts"]], "2. Leave-one-out Cross Validation (4 pts)": [[30, "leave-one-out-cross-validation-4-pts"]], "3. Compare to cv.glm (3 pts)": [[30, "compare-to-cv-glm-3-pts"]], "4. Adjusting K and Reflection (2 pts)": [[30, "adjusting-k-and-reflection-2-pts"]], "Reflection": [[30, "reflection"]], "Exercise 3: Data objects": [[31, "exercise-3-data-objects"]], "1. Load packages, data, model (1 point)": [[31, "load-packages-data-model-1-point"]], "2. Replicating summary outputs (5 pts)": [[31, "replicating-summary-outputs-5-pts"]], "2. Summary table and indexing (4 pts)": [[31, "summary-table-and-indexing-4-pts"]], "Exercise 7:  Linear models": [[32, "exercise-7-linear-models"]], "1. Loading the Data (1 point)": [[32, "loading-the-data-1-point"], [41, "loading-the-data-1-point"]], "2. Initial data visualization (2 point)": [[32, "initial-data-visualization-2-point"]], "3. Linear regression (4 points)": [[32, "linear-regression-4-points"]], "4. Plotting (2 points)": [[32, "plotting-2-points"]], "5. Reflection (1 point)": [[32, "reflection-1-point"], [33, "reflection-1-point"], [39, "reflection-1-point"]], "Exercise 14: Mediation": [[33, "exercise-14-mediation"]], "1. Simulating data (3 points)": [[33, "simulating-data-3-points"]], "2. Visualizing Data (2 point)": [[33, "visualizing-data-2-point"]], "3. Mediation Analysis (4 points)": [[33, "mediation-analysis-4-points"]], "Exercise 10: Mixed effects": [[34, "exercise-10-mixed-effects"]], "2. Model fitting (4 points)": [[34, "model-fitting-4-points"]], "3. Model assessment (4 points)": [[34, "model-assessment-4-points"]], "4. Reflection (1 point)": [[34, "reflection-1-point"]], "Exercise 2: Coding Habits & Functions": [[35, "exercise-2-coding-habits-functions"]], "1. Summary statistics (4 pts)": [[35, "summary-statistics-4-pts"]], "2. T-test function (4 pts)": [[35, "t-test-function-4-pts"]], "3. Setting default values (2 pts)": [[35, "setting-default-values-2-pts"]], "Exercise 15: Power analyses": [[36, "exercise-15-power-analyses"]], "1. Simulating data (1 points)": [[36, "simulating-data-1-points"]], "2. run_analysis() function (2 pts)": [[36, "run-analysis-function-2-pts"]], "3. repeat_analysis() function (3 pts)": [[36, "repeat-analysis-function-3-pts"]], "4. Testing different sample sizes (2 pts)": [[36, "testing-different-sample-sizes-2-pts"]], "5. Reflection (2 pts)": [[36, "reflection-2-pts"]], "Exercise 18: Principal component methods": [[37, "exercise-18-principal-component-methods"]], "1. Loading data (1 point)": [[37, "loading-data-1-point"]], "2. Correlational structure (4 points)": [[37, "correlational-structure-4-points"]], "3. Principal component analysis (3 points)": [[37, "principal-component-analysis-3-points"]], "4. Associating with Flanker task peformance (4 points)": [[37, "associating-with-flanker-task-peformance-4-points"]], "5. Reflection (2 points)": [[37, "reflection-2-points"]], "Exercise 17: Regularized regression": [[38, "exercise-17-regularized-regression"]], "1. Simulating & visualizing data (2 points)": [[38, "simulating-visualizing-data-2-points"]], "2. Bias-variance tradeoff: polynomial regression (4 points)": [[38, "bias-variance-tradeoff-polynomial-regression-4-points"]], "3. Applying regularization to the model fits (2 points)": [[38, "applying-regularization-to-the-model-fits-2-points"]], "4. Reflection (2 points)": [[38, "reflection-2-points"]], "Bonus (1 extra credit point)": [[38, "bonus-1-extra-credit-point"]], "Exercise 13:  Resampling methods": [[39, "exercise-13-resampling-methods"]], "1. Loading & Visualizing the Data (1 point)": [[39, "loading-visualizing-the-data-1-point"]], "2. Logistic classifier (2 points)": [[39, "logistic-classifier-2-points"]], "3. Bootstrapped accuracy (3 points)": [[39, "bootstrapped-accuracy-3-points"]], "4. Permutation test for grey matter effects (3 points)": [[39, "permutation-test-for-grey-matter-effects-3-points"]], "Exercise 16: Model selection": [[40, "exercise-16-model-selection"]], "1. Best subset selection (4 points)": [[40, "best-subset-selection-4-points"]], "2. Forward and backwards stepwise selection (3 points)": [[40, "forward-and-backwards-stepwise-selection-3-points"]], "3. Training and test error (3 points)": [[40, "training-and-test-error-3-points"]], "Exercise 4: Data cleansing": [[41, "exercise-4-data-cleansing"]], "2. Data Cleansing (4 points)": [[41, "data-cleansing-4-points"]], "3. Data Manipulation with Tidyverse (4 points)": [[41, "data-manipulation-with-tidyverse-4-points"]], "4. Plotting Data (1 point)": [[41, "plotting-data-1-point"]], "Exercise 11: The beauty of kNN": [[42, "exercise-11-the-beauty-of-knn"]], "1. Data, Plotting, and Train/Test Sets (2 pts)": [[42, "data-plotting-and-train-test-sets-2-pts"]], "Plot": [[42, "plot"]], "Test vs Train": [[42, "test-vs-train"]], "2: KNN (3 points)": [[42, "knn-3-points"]], "3: for loop (3 points)": [[42, "for-loop-3-points"]], "4: Standardizing predictors (2)": [[42, "standardizing-predictors-2"]], "Exercise 8:  Linear models, continued": [[43, "exercise-8-linear-models-continued"]], "1. Deriving the Maximum Likelihood Estimate for Simple Linear Regression (6 points)": [[43, "deriving-the-maximum-likelihood-estimate-for-simple-linear-regression-6-points"]], "2. Connecting to data (4 points)": [[43, "connecting-to-data-4-points"]], "Exercise 1: Github & Jupyter": [[44, "exercise-1-github-jupyter"]], "Exercise 5: Using ggplot": [[45, "exercise-5-using-ggplot"]], "1. Color, plot type and layers (6 points)": [[45, "color-plot-type-and-layers-6-points"]], "2. Adding statistics (4 points)": [[45, "adding-statistics-4-points"]], "Exercise 6: More plotting options": [[46, "exercise-6-more-plotting-options"]], "1. Multipanel figures (7 points)": [[46, "multipanel-figures-7-points"]], "2. Increasing data density (3 pts)": [[46, "increasing-data-density-3-pts"]], "Data explorations": [[47, "data-explorations"]], "Art of data investigations": [[48, "art-of-data-investigations"]], "Lecture": [[48, "lecture"], [51, "lecture"], [78, "lecture"]], "Bayes factor": [[49, "bayes-factor"]], "Required readings": [[49, "required-readings"], [50, "required-readings"], [51, "required-readings"], [52, "required-readings"], [53, "required-readings"], [54, "required-readings"], [55, "required-readings"], [56, "required-readings"], [57, "required-readings"], [58, "required-readings"], [59, "required-readings"], [60, "required-readings"], [61, "required-readings"], [62, "required-readings"], [63, "required-readings"], [64, "required-readings"], [65, "required-readings"], [66, "required-readings"], [67, "required-readings"], [68, "required-readings"], [69, "required-readings"], [70, "required-readings"], [71, "required-readings"], [72, "required-readings"], [73, "required-readings"], [75, "required-readings"], [76, "required-readings"], [77, "required-readings"], [78, "required-readings"]], "Lecture (Video)": [[49, "lecture-video"], [50, "lecture-video"], [52, "lecture-video"], [53, "lecture-video"], [54, "lecture-video"], [55, "lecture-video"], [56, "lecture-video"], [57, "lecture-video"], [58, "lecture-video"], [59, "lecture-video"], [60, "lecture-video"], [61, "lecture-video"], [62, "lecture-video"], [63, "lecture-video"], [64, "lecture-video"], [65, "lecture-video"], [66, "lecture-video"], [67, "lecture-video"], [68, "lecture-video"], [69, "lecture-video"], [70, "lecture-video"], [71, "lecture-video"], [72, "lecture-video"], [73, "lecture-video"], [75, "lecture-video"], [76, "lecture-video"], [77, "lecture-video"]], "Slides (PDF)": [[49, "slides-pdf"], [50, "slides-pdf"], [52, "slides-pdf"], [53, "slides-pdf"], [54, "slides-pdf"], [55, "slides-pdf"], [56, "slides-pdf"], [57, "slides-pdf"], [58, "slides-pdf"], [59, "slides-pdf"], [60, "slides-pdf"], [61, "slides-pdf"], [62, "slides-pdf"], [63, "slides-pdf"], [64, "slides-pdf"], [65, "slides-pdf"], [66, "slides-pdf"], [67, "slides-pdf"], [68, "slides-pdf"], [69, "slides-pdf"], [70, "slides-pdf"], [71, "slides-pdf"], [72, "slides-pdf"], [73, "slides-pdf"], [75, "slides-pdf"], [76, "slides-pdf"], [77, "slides-pdf"]], "Classifiers": [[50, "classifiers"]], "Constructing a testable hypothesis": [[51, "constructing-a-testable-hypothesis"]], "Cross validation": [[52, "cross-validation"]], "Data as objects and architectures": [[53, "data-as-objects-and-architectures"]], "Errors and inferences": [[54, "errors-and-inferences"]], "Limits and variations of linear regression": [[55, "limits-and-variations-of-linear-regression"]], "Linear models": [[56, "linear-models"]], "Mediation and moderation": [[57, "mediation-and-moderation"]], "Mixed effects models": [[58, "mixed-effects-models"]], "Models as testable hypotheses": [[59, "models-as-testable-hypotheses"]], "Power analysis via simulations": [[60, "power-analysis-via-simulations"]], "Principal component methods": [[61, "principal-component-methods"]], "Quantitative epsitemology": [[62, "quantitative-epsitemology"]], "Reconsidering the p-value": [[63, "reconsidering-the-p-value"]], "Regularized regression": [[64, "regularized-regression"]], "Resampling methods": [[65, "resampling-methods"]], "Selecting the best model": [[66, "selecting-the-best-model"]], "The bias-variance tradeoff": [[67, "the-bias-variance-tradeoff"]], "Techniques for data cleansing": [[68, "techniques-for-data-cleansing"]], "Telling your data story": [[69, "telling-your-data-story"]], "The beauty of kNN": [[70, "the-beauty-of-knn"]], "The ordinary least squares solution": [[71, "the-ordinary-least-squares-solution"]], "The value of openness": [[72, "the-value-of-openness"]], "Theories as social constructs": [[73, "theories-as-social-constructs"]], "Visualization as analysis": [[75, "visualization-as-analysis"]], "Visualization through human eyes": [[76, "visualization-through-human-eyes"]], "What is a theory?": [[77, "what-is-a-theory"]], "What is learnable?": [[78, "what-is-learnable"]], "Markdown Files": [[79, "markdown-files"]], "What is MyST?": [[79, "what-is-myst"]], "What are roles and directives?": [[79, "what-are-roles-and-directives"]], "Using a directive": [[79, "using-a-directive"]], "Using a role": [[79, "using-a-role"]], "Adding a citation": [[79, "adding-a-citation"]], "Executing code in your markdown files": [[79, "executing-code-in-your-markdown-files"]], "The art of \u201cdata poetry\u201d": [[80, "the-art-of-data-poetry"]], "Rule 1: Track, chronicle, & preserve": [[80, "rule-1-track-chronicle-preserve"]], "Subrule 1.1: Every detail matters": [[80, "subrule-1-1-every-detail-matters"]], "Rule 2: Automate as much as you can": [[80, "rule-2-automate-as-much-as-you-can"]], "Rule 3: Proactive > reactive": [[80, "rule-3-proactive-reactive"]], "Rule 4: See your data": [[80, "rule-4-see-your-data"]], "Rule 5: Statistics is a language, not magic": [[80, "rule-5-statistics-is-a-language-not-magic"]], "Tutorial: Getting started": [[82, "tutorial-getting-started"], [95, "tutorial-getting-started"]], "Goals:": [[82, "goals"], [83, "goals"], [84, "goals"], [85, "goals"], [86, "goals"], [87, "goals"], [88, "goals"], [89, "goals"], [90, "goals"], [91, "goals"], [92, "goals"], [93, "goals"], [94, "goals"], [95, "goals"], [96, "goals"], [97, "goals"], [98, "goals"], [99, "goals"], [100, "goals"], [101, "goals"], [102, "goals"], [103, "goals"], [104, "goals"], [105, "goals"]], "Installing R and RStudio": [[82, "installing-r-and-rstudio"], [95, "installing-r-and-rstudio"]], "Trying it out": [[82, "trying-it-out"], [95, "trying-it-out"]], "Jupyter [Julia, Python, and R] Notebooks": [[82, "jupyter-julia-python-and-r-notebooks"], [95, "jupyter-julia-python-and-r-notebooks"]], "Why use Jupyter notebooks?": [[82, "why-use-jupyter-notebooks"], [95, "why-use-jupyter-notebooks"]], "Installation": [[82, "installation"], [95, "installation"]], "Installing the R kernel for Jupyter notebooks": [[82, "installing-the-r-kernel-for-jupyter-notebooks"], [95, "installing-the-r-kernel-for-jupyter-notebooks"]], "Tutorial: Estimating Bayes factors": [[83, "tutorial-estimating-bayes-factors"]], "What is a Bayes factor?": [[83, "what-is-a-bayes-factor"]], "Implementing the Bayes factor with a simple example": [[83, "implementing-the-bayes-factor-with-a-simple-example"]], "Calculating the Bayes Factor for comparison of candidate mixed effect models": [[83, "calculating-the-bayes-factor-for-comparison-of-candidate-mixed-effect-models"]], "Tutorial: Basics classifiers": [[84, "tutorial-basics-classifiers"]], "Logistic regression with glm": [[84, "logistic-regression-with-glm"]], "Predicting the stock market": [[84, "predicting-the-stock-market"]], "LDA": [[84, "lda"]], "QDA": [[84, "qda"]], "Tutorial: Implementing cross validation": [[85, "tutorial-implementing-cross-validation"], [86, "tutorial-implementing-cross-validation"]], "Why not use the simple validation set approach?": [[85, "why-not-use-the-simple-validation-set-approach"], [86, "why-not-use-the-simple-validation-set-approach"]], "Validation data sets": [[85, "validation-data-sets"], [86, "validation-data-sets"]], "Leave-one-out cross-validation (LOOCV)": [[85, "leave-one-out-cross-validation-loocv"], [86, "leave-one-out-cross-validation-loocv"]], "K-fold cross validation": [[85, "k-fold-cross-validation"], [86, "k-fold-cross-validation"]], "Tutorial: Data as Objects and Tidy Data": [[87, "tutorial-data-as-objects-and-tidy-data"]], "Tidy Data": [[87, "tidy-data"]], "Interacting with model objects in R": [[87, "interacting-with-model-objects-in-r"]], "Tutorial: More on linear models": [[88, "tutorial-more-on-linear-models"]], "Getting started": [[88, "getting-started"], [99, "getting-started"]], "Regression with multiple predictors": [[88, "regression-with-multiple-predictors"]], "Working with categorical (qualitative) predictors": [[88, "working-with-categorical-qualitative-predictors"]], "Simulating the bias-variance tradeoff": [[88, "simulating-the-bias-variance-tradeoff"]], "Tutorial: Refresher on working with matrices": [[89, "tutorial-refresher-on-working-with-matrices"]], "Vectors": [[89, "vectors"], [92, "vectors"]], "Working with Sums and Products in Equations": [[89, "working-with-sums-and-products-in-equations"]], "Trick 1: Pulling terms out of a sum": [[89, "trick-1-pulling-terms-out-of-a-sum"]], "Trick 2: Splitting up a sum": [[89, "trick-2-splitting-up-a-sum"]], "Trick 3: Pulling coefficients out of a sum": [[89, "trick-3-pulling-coefficients-out-of-a-sum"]], "What is a matrix?": [[89, "what-is-a-matrix"]], "Basic kinds of matrices": [[89, "basic-kinds-of-matrices"]], "Square": [[89, "square"]], "Symmetric": [[89, "symmetric"]], "Identity": [[89, "identity"]], "Summary": [[89, "summary"]], "Matrix manipulation": [[89, "matrix-manipulation"]], "Basic indexing": [[89, "basic-indexing"]], "Basic matrix operations": [[89, "basic-matrix-operations"]], "Addition and subtraction": [[89, "addition-and-subtraction"]], "Transposition": [[89, "transposition"]], "Multiplication": [[89, "multiplication"]], "Division": [[89, "division"]], "Inversion": [[89, "inversion"]], "Determinant": [[89, "determinant"]], "Use matrix manipulation to solve a linear regression problem \u201cby hand\u201d": [[89, "use-matrix-manipulation-to-solve-a-linear-regression-problem-by-hand"]], "Tutorial: Running mediation and moderation models": [[90, "tutorial-running-mediation-and-moderation-models"]], "The difference between mediation and moderation": [[90, "the-difference-between-mediation-and-moderation"]], "Mediation in R": [[90, "mediation-in-r"]], "Moderation in R": [[90, "moderation-in-r"]], "Tutorial: Running linear mixed effects models": [[91, "tutorial-running-linear-mixed-effects-models"]], "Linear mixed-effects models": [[91, "linear-mixed-effects-models"]], "Tutorial: Introduction to R, functions, and good coding habits": [[92, "tutorial-introduction-to-r-functions-and-good-coding-habits"]], "Basic R Commands": [[92, "basic-r-commands"]], "Arithmetic": [[92, "arithmetic"]], "Data structures": [[92, "data-structures"]], "Data frames": [[92, "data-frames"]], "Indexing": [[92, "indexing"]], "How to write a function in R": [[92, "how-to-write-a-function-in-r"]], "Good research code practices": [[92, "good-research-code-practices"]], "Keep code consistent": [[92, "keep-code-consistent"]], "Keep jupyter notebooks tidy": [[92, "keep-jupyter-notebooks-tidy"]], "Delete dead code": [[92, "delete-dead-code"]], "Use pure functions": [[92, "use-pure-functions"]], "Bad code: things not to do": [[92, "bad-code-things-not-to-do"]], "Documenting": [[92, "documenting"]], "Tutorial: Running basic power analyses": [[93, "tutorial-running-basic-power-analyses"]], "Simulating power": [[93, "simulating-power"]], "Basic algorithm": [[93, "basic-algorithm"]], "Determine the sources of variance": [[93, "determine-the-sources-of-variance"]], "Write a function to simulate artificial data": [[93, "write-a-function-to-simulate-artificial-data"]], "Write a function to conduct your intended analysis": [[93, "write-a-function-to-conduct-your-intended-analysis"]], "Vary the sample size and alpha levels": [[93, "vary-the-sample-size-and-alpha-levels"]], "Extending to more complicated analyses: example with mixed-models": [[93, "extending-to-more-complicated-analyses-example-with-mixed-models"]], "But what is more important, number of subjects or number of trials?": [[93, "but-what-is-more-important-number-of-subjects-or-number-of-trials"]], "Tutorial: Basic PCA approaches": [[94, "tutorial-basic-pca-approaches"]], "Principal component analysis: the big picture": [[94, "principal-component-analysis-the-big-picture"]], "Principal component regression": [[94, "principal-component-regression"]], "Partial least squares": [[94, "partial-least-squares"]], "Tutorial: Basic ridge and LASSO models": [[96, "tutorial-basic-ridge-and-lasso-models"]], "Ridge Regression": [[96, "ridge-regression"]], "An important note about validation and test sets": [[96, "an-important-note-about-validation-and-test-sets"]], "LASSO": [[96, "lasso"]], "Tutorial: Boostrap and permutation tests": [[97, "tutorial-boostrap-and-permutation-tests"]], "A reminder of the difference between bootstrapping and permutation testing": [[97, "a-reminder-of-the-difference-between-bootstrapping-and-permutation-testing"]], "Bootstrapping": [[97, "bootstrapping"]], "Permutation tests": [[97, "permutation-tests"]], "Tutorial: Model selection": [[98, "tutorial-model-selection"]], "Best subset selection": [[98, "best-subset-selection"]], "Tutorial: Data Cleansing and the Tidyverse": [[99, "tutorial-data-cleansing-and-the-tidyverse"]], "Data": [[99, "data"]], "A standardized grammar": [[99, "a-standardized-grammar"]], "Pipes: the %>% operator": [[99, "pipes-the-operator"]], "Transforming data with tidyverse functions": [[99, "transforming-data-with-tidyverse-functions"]], "mutate(): Transform existing variables and create new variables": [[99, "mutate-transform-existing-variables-and-create-new-variables"]], "summarise(): Summarize variables": [[99, "summarise-summarize-variables"]], "filter(): Filter rows based on a condition": [[99, "filter-filter-rows-based-on-a-condition"]], "select(): Select columns to keep/remove": [[99, "select-select-columns-to-keep-remove"]], "arrange(): Sort by columns": [[99, "arrange-sort-by-columns"]], "unite(): Combine two columns into one": [[99, "unite-combine-two-columns-into-one"]], "separate(): Split one column into multiple columns": [[99, "separate-split-one-column-into-multiple-columns"]], "group_by(): Implicitly group data": [[99, "group-by-implicitly-group-data"]], "nest(): Explicitly group data": [[99, "nest-explicitly-group-data"]], "map(): Perform same function on each element of list or vector": [[99, "map-perform-same-function-on-each-element-of-list-or-vector"]], "Restructuring data.frames: long to wide, wide to long, and merging": [[99, "restructuring-data-frames-long-to-wide-wide-to-long-and-merging"]], "pivot_longer()": [[99, "pivot-longer"]], "pivot_wider()": [[99, "pivot-wider"]], "*_join()": [[99, "join"]], "Tutorial: Running kNN models": [[100, "tutorial-running-knn-models"]], "K-Nearest Neighbors: an intro": [[100, "k-nearest-neighbors-an-intro"]], "Classifying irises": [[100, "classifying-irises"]], "Identifying test items": [[100, "identifying-test-items"]], "Predicting the species using kNN": [[100, "predicting-the-species-using-knn"]], "Assessing kNN performance": [[100, "assessing-knn-performance"]], "Varying k": [[100, "varying-k"]], "Standardizing data": [[100, "standardizing-data"]], "Tutorial: Refresher for solving oridinary least squares": [[101, "tutorial-refresher-for-solving-oridinary-least-squares"]], "Derivatives": [[101, "derivatives"]], "What is a derivative?": [[101, "what-is-a-derivative"]], "Examples": [[101, "examples"]], "Tips on calculating the derivative": [[101, "tips-on-calculating-the-derivative"]], "1. A constant function": [[101, "a-constant-function"]], "2. The Power Rule": [[101, "the-power-rule"]], "3. Taking out a constant": [[101, "taking-out-a-constant"]], "4. Added functions": [[101, "added-functions"]], "5. Functions with two variables": [[101, "functions-with-two-variables"]], "Using the derivative to find minimizing values: 2 worked examples": [[101, "using-the-derivative-to-find-minimizing-values-2-worked-examples"]], "Logarithms": [[101, "logarithms"]], "What is a logarithm?": [[101, "what-is-a-logarithm"]], "Working with logarithms": [[101, "working-with-logarithms"]], "1. e": [[101, "e"]], "2. Product": [[101, "product"]], "3. Quotient": [[101, "quotient"]], "4. Exponents": [[101, "exponents"]], "5. Derivative": [[101, "derivative"]], "Why are we using logarithms in this class?": [[101, "why-are-we-using-logarithms-in-this-class"]], "Expected values": [[101, "expected-values"]], "Tutorial: Repositories and version control": [[102, "tutorial-repositories-and-version-control"]], "Why version control?": [[102, "why-version-control"]], "What are git and GitHub?": [[102, "what-are-git-and-github"]], "Use Git and GitHub": [[102, "use-git-and-github"]], "Configuration": [[102, "configuration"]], "Updated Authentication Process": [[102, "updated-authentication-process"]], "Basic Bash scripting": [[102, "basic-bash-scripting"]], "Set up a new repository": [[102, "set-up-a-new-repository"]], "Pulling changes": [[102, "pulling-changes"]], "Adding files to be tracked": [[102, "adding-files-to-be-tracked"]], "Committing changes": [[102, "committing-changes"]], "Working on a different branch": [[102, "working-on-a-different-branch"]], "Merging branches": [[102, "merging-branches"]], "Merge only a specific file from a branch": [[102, "merge-only-a-specific-file-from-a-branch"]], "Putting it all together - example workflow": [[102, "putting-it-all-together-example-workflow"]], "Tutorial: Basics of plotting": [[103, "tutorial-basics-of-plotting"]], "Plotting & distributions": [[103, "plotting-distributions"]], "Basics first": [[103, "basics-first"]], "Aesthetics": [[103, "aesthetics"]], "Geoms": [[103, "geoms"]], "Correlation": [[103, "correlation"]], "Distribution": [[103, "distribution"]], "Tutorial: More advanced plotting": [[104, "tutorial-more-advanced-plotting"]], "Extending ggplot2": [[104, "extending-ggplot2"]], "Customizing your visualizations": [[104, "customizing-your-visualizations"]], "High data density": [[104, "high-data-density"]], "Meaningful labels": [[104, "meaningful-labels"]], "References": [[104, "references"]], "Small multiples": [[104, "small-multiples"]], "Order": [[104, "order"]], "More resources": [[104, "more-resources"]], "Tutorial: Fitting and prediction": [[105, "tutorial-fitting-and-prediction"]], "Simple linear regression with a single predictor": [[105, "simple-linear-regression-with-a-single-predictor"]], "Model fitting": [[105, "model-fitting"]], "Inference": [[105, "inference"]], "Prediction": [[105, "prediction"]], "Plotting": [[105, "plotting"]], "Video test 1": [[106, "video-test-1"]]}, "indexentries": {}})