# Discussion questions

1.	Verbally describe why increasing the dimensionality of your model (by adding more variables) can increase the variance/flexibility of the model. What should factor into your choice of increasing or decreasing model complexity (i.e., increasing or decreasing the number of dimensions/variables/parameters)?

2.	Is finding the “optimal” point between where minimizing error and maximizing generalizability always the goal (i.e., finding the inflection point where delta-MSE between training and test are minimized)? Are there cases where you want a more generalizable but noisier model or, conversely, a model that is overfit to a training data? Give some examples

